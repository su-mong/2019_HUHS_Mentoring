{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-study-02.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "C7dJHc6BpD5E",
        "VK6c7gTbDenU",
        "MEFcGk6KNI-J",
        "TVNSM6fZXrVL",
        "uGHvfaUtjsh_"
      ],
      "authorship_tag": "ABX9TyPeh57pJFOXZGOFLhnoWF6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Candykick/2019_HUHS_Mentoring/blob/master/tensorflow_study_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dJHc6BpD5E"
      },
      "source": [
        "### Lab 09-1: Neural Net for XOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lekt5IXyo6s3",
        "outputId": "11c247b2-173e-4d58-cd78-70f1703ef74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "\n",
        "# random seed 설정\n",
        "# 이는 매 실행 때마다 같은 값을 얻기 위함.\n",
        "tf.random.set_seed(777)\n",
        "\n",
        "# 원본 데이터셋\n",
        "# XOR 문제를 풀기 위한 데이터이므로, 같은 값이면 0, 다른 값이면 1을 출력해야 한다.\n",
        "x_data = [[0, 0],[0, 1],[1, 0],[1, 1]]\n",
        "y_data = [[0],[1],[1],[0]]\n",
        "\n",
        "# Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))\n",
        "\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 2), (None, 1)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuLnUd2d2H9H"
      },
      "source": [
        "# preprocess function으로 features, labels는 실재 학습에 쓰일 Data 연산을 위해 Type를 맞춰준다.\n",
        "# Int -> Flaot32로 Casting\n",
        "def preprocess_data(features, labels):\n",
        "  features = tf.cast(features, tf.float32)\n",
        "  labels = tf.cast(labels, tf.float32)\n",
        "  return features, labels\n",
        "\n",
        "# Weight, bias 초기값 지정\n",
        "W1 = tf.Variable(tf.random.normal([2, 1]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.normal([1]), name='bias1')\n",
        "\n",
        "W2 = tf.Variable(tf.random.normal([2, 1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.normal([1]), name='bias2')\n",
        "\n",
        "W3 = tf.Variable(tf.random.normal([2, 1]), name='weight3')\n",
        "b3 = tf.Variable(tf.random.normal([1]), name='bias3')\n",
        "\n",
        "# 3개의 Logistic Regression Unit을 합친 Neural Net 함수.\n",
        "# Layer 1을 Vector로 합치지 않은 버전.\n",
        "def neural_net(features):\n",
        "  layer1 = tf.sigmoid(tf.matmul(features, W1)+b1)\n",
        "  layer2 = tf.sigmoid(tf.matmul(features, W2)+b2)\n",
        "  layer3 = tf.concat([layer1, layer2], -1)\n",
        "  layer3 = tf.reshape(layer3, shape = [-1, 2])\n",
        "  hypothesis = tf.sigmoid(tf.matmul(layer3, W3)+b3)\n",
        "  return hypothesis\n",
        "\n",
        "# Loss function\n",
        "def loss_fn(hypothesis, labels):\n",
        "  cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1-labels)*tf.math.log(1-hypothesis))\n",
        "  return cost\n",
        "\n",
        "# Gradient Descent Optimizert Setting\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Measure Accuracy Function\n",
        "def accuracy_fn(hypothesis, labels):\n",
        "  predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "  accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "# Gradient Descent Function\n",
        "def grad(features, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss_fn(neural_net(features), labels)\n",
        "  return tape.gradient(loss_value, [W1, W2, W3, b1, b2, b3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvbS_0pK6j_p",
        "outputId": "3e6097e1-b4d4-403d-9344-40f82a0a73b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Repeat Count\n",
        "EPOCHS = 50000\n",
        "\n",
        "# Do Gradient Descent\n",
        "for step in range(EPOCHS):\n",
        "  for features, labels in dataset:\n",
        "    features, labels = preprocess_data(features, labels)\n",
        "    grads = grad(features, labels)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W1, W2, W3, b1, b2, b3]))\n",
        "    if step % 5000 == 0:\n",
        "      print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(neural_net(features), labels)))\n",
        "    \n",
        "# Measure Accuracy of the Neural_Net\n",
        "x_data, y_data = preprocess_data(x_data, y_data)\n",
        "test_acc = accuracy_fn(neural_net(x_data), y_data)\n",
        "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter: 0, Loss: 0.8487\n",
            "Iter: 5000, Loss: 0.6847\n",
            "Iter: 10000, Loss: 0.6610\n",
            "Iter: 15000, Loss: 0.6154\n",
            "Iter: 20000, Loss: 0.5722\n",
            "Iter: 25000, Loss: 0.5433\n",
            "Iter: 30000, Loss: 0.5211\n",
            "Iter: 35000, Loss: 0.4911\n",
            "Iter: 40000, Loss: 0.4416\n",
            "Iter: 45000, Loss: 0.3313\n",
            "Testset Accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18FQc1krDXQM"
      },
      "source": [
        "### Lab 09-2: Tensorboard (Neural Net for XOR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6c7gTbDenU"
      },
      "source": [
        "### Lab 10-1: Sigmoid 보다 ReLU가 더 좋아"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPFx0oONSszG"
      },
      "source": [
        "어떤 프로젝트인가 : mnist 데이터셋을 이용해서 숫자 필기체 이미지를 받아온 뒤, 이를 Activation Function을 바꿔가면서 학습, 정확도를 비교한다.\n",
        "<br><br>\n",
        "참고 자료 : https://tensorflow.blog/케라스-딥러닝/2-시작하기-전에-신경망의-수학적-구성-요소/\n",
        "<br><br>\n",
        "※ Tensorboard 추가하는 것도 알아봤는데, 현 구조 자체가 콜백 함수를 적용하기에 적절하지 않아서(정확히는 어디다가 넣어야 할지를 몰라서) 추가하지 않았다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFTDZ8o_DfSe"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist # fasion_mnist, cifar10, cifar100과 같은 다양한 데이터셋이 있다.\n",
        "\n",
        "# mnist 데이터셋을 받아온 뒤 전처리.\n",
        "def load_mnist():\n",
        "  # train은 6만 장, test는 1만 장.\n",
        "  (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  # expand_dims : 채널 정보를 추가해서 input의 shape 변경.\n",
        "  # tensorflow가 input으로 받는 shape는 [batch_size, height, width, channel]과 같은 형식이어야 한다.\n",
        "  # numpy.expand_dims(array, axis) : Expand the shape of an array. \n",
        "  #                                  Insert a new axis that will appear at the axis position in the expanded array shape.\n",
        "  #                                  axis로 지정된 차원을 추가한다. axis=-1인 경우, 마지막에 차원을 추가한다.\n",
        "  train_data = np.expand_dims(train_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "  test_data = np.expand_dims(test_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "\n",
        "  # 이미지들의 숫자값을 0~1사이의 값으로 정규화.\n",
        "  train_data, test_data = normalize(train_data, test_data) # 범위는 0~255 -> 0~1\n",
        "\n",
        "  # labels 전처리\n",
        "  # 10 : 데이터셋의 라벨 갯수(여기서는 0~9까지의 숫자 갯수이므로 10개.)\n",
        "  # to_categorical(): One-Hot Incoding을 제공하는 함수. 여기서는 labels 값들을 One-hot Incoding된 값으로 변환해 준다.\n",
        "  train_labels = to_categorical(train_labels, 10)\n",
        "  test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "# 정규화 함수.\n",
        "# 범위가 255까지이므로 255로 나눠 주면 된다.\n",
        "# float32로 형변환 필수.\n",
        "def normalize(train_data, test_data):\n",
        "  train_data = train_data.astype(np.float32) / 255.0\n",
        "  test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "  return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYVnrAaeUeb9"
      },
      "source": [
        "# shape를 펼쳐주는 함수\n",
        "# 다차원 배열을 1차원으로 만드는 레이어를 추가한다고 보면 된다.\n",
        "def flatten():\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "# Dense Layer(Flip Connected Layer) 사용, 케라스 레이어에 Dense 추가\n",
        "def dense(channel, weight_init):\n",
        "  # units = output으로 나가는 채널 갯수, use_bias = bias 사용 여부\n",
        "  return tf.keras.layers.Dense(units=channel, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "# Relu Activation Function\n",
        "def relu():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.sigmoid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtCkgtlZm7Qe"
      },
      "source": [
        "model에서 레이어 배치 순서는 다음과 같다.\n",
        "\n",
        "가장 많이 사용하는 순서는<br>\n",
        "layer<br>\n",
        "normalization<br>\n",
        "activation\n",
        "\n",
        "혹은\n",
        "\n",
        "normalization<br>\n",
        "activation<br>\n",
        "layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X4qZjyqU0yC"
      },
      "source": [
        "# Class type의 모델.\n",
        "class create_model(tf.keras.Model): # tf.keras.Model을 상속받아야 한다.\n",
        "  def __init__(self, label_dim): # label_dim : 몇 개의 output을 낼 것인지를 알려준다. 여기서는 10.\n",
        "    super(create_model, self).__init__()\n",
        "\n",
        "    weight_init = tf.keras.initializers.RandomNormal() # weight_init을 랜덤하게 생성. (평균이 0, 분산이 1인 가우시안 분포)\n",
        "    self.model = tf.keras.Sequential() # 리스트 자료구조 타입으로, 네트워크 구조의 레이어들을 담고 있다고 보면 되나?\n",
        "\n",
        "    # model에 flatten 레이어 추가. 이미지 shape를 펼쳐 준다.\n",
        "    self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "    for i in range(2):\n",
        "      # [N, 784] -> [N, 256] -> [N, 256]\n",
        "      self.model.add(dense(256, weight_init)) # flip-connected function * 2\n",
        "      self.model.add(relu()) # relu function * 2\n",
        "\n",
        "    # 네트워크의 logits를 구함. 10개의 output으로 출력.\n",
        "    self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        " \n",
        " # 위에서 만든 model을 실제로 호출하는 함수.\n",
        "  def call(self, x, training=None, mask=None):\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jIwWMjgvY7_"
      },
      "source": [
        "# loss 값 구하는 함수.\n",
        "def loss_fn(model, images, labels):\n",
        "  logits = model(images, training=True) # images의 숫자를 추출.\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)) # softmax로 loss 구함.\n",
        "  return loss\n",
        "\n",
        "# 정확도 측정 함수.\n",
        "# argmax : 가장 큰 숫자값의 위치를 찾는 함수. 여기서는 마지막(-1번째) 차원을 제거한다.\n",
        "def accuracy_fn(model, images, labels):\n",
        "  logits = model(images, training=False)\n",
        "  prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32)) # prediction은 Boolean 이기 때문에, 이를 숫자값으로 변경.\n",
        "  return accuracy\n",
        "\n",
        "# Gradient Descent 함수.\n",
        "def grad(model, images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model, images, labels)\n",
        "  return tape.gradient(loss, model.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zIj37kKwgbM"
      },
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128 # 이미지를 한 번에 학습시킬 갯수.\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x)\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "# 데이터셋 API를 이용해서 각각의 이미지/labels들을 네트워크에 넣는 것 구현.\n",
        "# 한 번에 다 넣으면 메모리에 부담이 되므로, batch_size만큼만 넣는다.\n",
        "# shuffle : 데이터셋을 잘 섞으라는 의미. 여기서 buffer_size는 input data보다 갯수가 많은 값이면 된다.\n",
        "# prefetch : 네트워크가 batch_size만큼 학습중일 때, 미리 메모리에 다음 batch_size만큼 학습데이터를 올려둔다.\n",
        "# batch : batch를 batch_size만큼 진행, 네트워크에 자료를 넣는다.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=batch_size).\\\n",
        "  batch(batch_size, drop_remainder=True)\n",
        "  #repeat() #이를 계속 반복.\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=len(test_x)).\\\n",
        "  batch(len(test_x))\n",
        "  #repeat()\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "# 어떤 Optimizer를 써서 loss값을 최소화할 것인가 : 여기서는 AdamOptimizer를 사용.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19G0N1CByILs",
        "outputId": "bca62052-fb3d-492e-aaf6-8535f4da5685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 여기선 체크포인트 구현은 생략했다. (핵심도 아니고, 귀찮고, 코랩 쓰고 있다보니.......)\n",
        "start_epoch = 0\n",
        "start_iteration = 0\n",
        "\n",
        "for epoch in range(start_epoch, training_epochs):\n",
        "  for idx, (train_input, train_label) in enumerate(train_dataset): #epoch, iteration 2개에 대해 반복 수행.\n",
        "    # gradient 구한 후 적용, 네트워크를 학습시킨다.\n",
        "    grads = grad(network, train_input, train_label)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "    # loss, 정확도를 구한다.\n",
        "    train_loss = loss_fn(network, train_input, train_label)\n",
        "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "    # test dataset을 불러오고, 정확도를 구한다.\n",
        "    for test_input, test_label in test_dataset:\n",
        "      test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    # 그 결과값을 출력한다.\n",
        "    print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" %(epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 0] [    0/60000], train_loss: 2.02356291, train_accuracy: 0.4297, test_Accuracy: 0.4792\n",
            "Epoch: [ 0] [    1/60000], train_loss: 1.96166503, train_accuracy: 0.5391, test_Accuracy: 0.5927\n",
            "Epoch: [ 0] [    2/60000], train_loss: 1.83400893, train_accuracy: 0.6484, test_Accuracy: 0.6899\n",
            "Epoch: [ 0] [    3/60000], train_loss: 1.75676799, train_accuracy: 0.7188, test_Accuracy: 0.7443\n",
            "Epoch: [ 0] [    4/60000], train_loss: 1.66362655, train_accuracy: 0.7422, test_Accuracy: 0.7710\n",
            "Epoch: [ 0] [    5/60000], train_loss: 1.56959581, train_accuracy: 0.7734, test_Accuracy: 0.7648\n",
            "Epoch: [ 0] [    6/60000], train_loss: 1.44071627, train_accuracy: 0.7891, test_Accuracy: 0.7513\n",
            "Epoch: [ 0] [    7/60000], train_loss: 1.38239574, train_accuracy: 0.7188, test_Accuracy: 0.7619\n",
            "Epoch: [ 0] [    8/60000], train_loss: 1.24083471, train_accuracy: 0.7969, test_Accuracy: 0.7776\n",
            "Epoch: [ 0] [    9/60000], train_loss: 1.19959927, train_accuracy: 0.7109, test_Accuracy: 0.7843\n",
            "Epoch: [ 0] [   10/60000], train_loss: 1.10610604, train_accuracy: 0.7812, test_Accuracy: 0.7800\n",
            "Epoch: [ 0] [   11/60000], train_loss: 1.12134647, train_accuracy: 0.7109, test_Accuracy: 0.7695\n",
            "Epoch: [ 0] [   12/60000], train_loss: 0.90458071, train_accuracy: 0.7812, test_Accuracy: 0.7675\n",
            "Epoch: [ 0] [   13/60000], train_loss: 1.08439600, train_accuracy: 0.7109, test_Accuracy: 0.7768\n",
            "Epoch: [ 0] [   14/60000], train_loss: 0.82884723, train_accuracy: 0.7969, test_Accuracy: 0.8031\n",
            "Epoch: [ 0] [   15/60000], train_loss: 0.63851142, train_accuracy: 0.8828, test_Accuracy: 0.8161\n",
            "Epoch: [ 0] [   16/60000], train_loss: 0.71032405, train_accuracy: 0.8203, test_Accuracy: 0.8193\n",
            "Epoch: [ 0] [   17/60000], train_loss: 0.74475604, train_accuracy: 0.7422, test_Accuracy: 0.8278\n",
            "Epoch: [ 0] [   18/60000], train_loss: 0.58267188, train_accuracy: 0.8594, test_Accuracy: 0.8333\n",
            "Epoch: [ 0] [   19/60000], train_loss: 0.51307547, train_accuracy: 0.8594, test_Accuracy: 0.8386\n",
            "Epoch: [ 0] [   20/60000], train_loss: 0.56121027, train_accuracy: 0.8594, test_Accuracy: 0.8428\n",
            "Epoch: [ 0] [   21/60000], train_loss: 0.67627650, train_accuracy: 0.8359, test_Accuracy: 0.8338\n",
            "Epoch: [ 0] [   22/60000], train_loss: 0.52304584, train_accuracy: 0.8672, test_Accuracy: 0.8299\n",
            "Epoch: [ 0] [   23/60000], train_loss: 0.48872602, train_accuracy: 0.8438, test_Accuracy: 0.8409\n",
            "Epoch: [ 0] [   24/60000], train_loss: 0.45694360, train_accuracy: 0.9141, test_Accuracy: 0.8471\n",
            "Epoch: [ 0] [   25/60000], train_loss: 0.42827052, train_accuracy: 0.8828, test_Accuracy: 0.8323\n",
            "Epoch: [ 0] [   26/60000], train_loss: 0.45451468, train_accuracy: 0.8438, test_Accuracy: 0.8218\n",
            "Epoch: [ 0] [   27/60000], train_loss: 0.62725860, train_accuracy: 0.8125, test_Accuracy: 0.8361\n",
            "Epoch: [ 0] [   28/60000], train_loss: 0.32965726, train_accuracy: 0.9297, test_Accuracy: 0.8536\n",
            "Epoch: [ 0] [   29/60000], train_loss: 0.50489408, train_accuracy: 0.8594, test_Accuracy: 0.8605\n",
            "Epoch: [ 0] [   30/60000], train_loss: 0.40898269, train_accuracy: 0.8828, test_Accuracy: 0.8635\n",
            "Epoch: [ 0] [   31/60000], train_loss: 0.32070205, train_accuracy: 0.9062, test_Accuracy: 0.8706\n",
            "Epoch: [ 0] [   32/60000], train_loss: 0.42152619, train_accuracy: 0.8594, test_Accuracy: 0.8740\n",
            "Epoch: [ 0] [   33/60000], train_loss: 0.40997106, train_accuracy: 0.8828, test_Accuracy: 0.8739\n",
            "Epoch: [ 0] [   34/60000], train_loss: 0.39535487, train_accuracy: 0.8984, test_Accuracy: 0.8639\n",
            "Epoch: [ 0] [   35/60000], train_loss: 0.33493954, train_accuracy: 0.8672, test_Accuracy: 0.8568\n",
            "Epoch: [ 0] [   36/60000], train_loss: 0.37559927, train_accuracy: 0.8672, test_Accuracy: 0.8664\n",
            "Epoch: [ 0] [   37/60000], train_loss: 0.40916568, train_accuracy: 0.8594, test_Accuracy: 0.8796\n",
            "Epoch: [ 0] [   38/60000], train_loss: 0.31702289, train_accuracy: 0.9219, test_Accuracy: 0.8853\n",
            "Epoch: [ 0] [   39/60000], train_loss: 0.44405064, train_accuracy: 0.8516, test_Accuracy: 0.8766\n",
            "Epoch: [ 0] [   40/60000], train_loss: 0.38336295, train_accuracy: 0.8906, test_Accuracy: 0.8711\n",
            "Epoch: [ 0] [   41/60000], train_loss: 0.34688103, train_accuracy: 0.8984, test_Accuracy: 0.8675\n",
            "Epoch: [ 0] [   42/60000], train_loss: 0.34475845, train_accuracy: 0.8984, test_Accuracy: 0.8720\n",
            "Epoch: [ 0] [   43/60000], train_loss: 0.31810376, train_accuracy: 0.9062, test_Accuracy: 0.8833\n",
            "Epoch: [ 0] [   44/60000], train_loss: 0.32314456, train_accuracy: 0.9219, test_Accuracy: 0.8896\n",
            "Epoch: [ 0] [   45/60000], train_loss: 0.38607919, train_accuracy: 0.8906, test_Accuracy: 0.8895\n",
            "Epoch: [ 0] [   46/60000], train_loss: 0.63147092, train_accuracy: 0.8047, test_Accuracy: 0.8853\n",
            "Epoch: [ 0] [   47/60000], train_loss: 0.45828789, train_accuracy: 0.8438, test_Accuracy: 0.8869\n",
            "Epoch: [ 0] [   48/60000], train_loss: 0.51816368, train_accuracy: 0.8906, test_Accuracy: 0.8909\n",
            "Epoch: [ 0] [   49/60000], train_loss: 0.37981683, train_accuracy: 0.8984, test_Accuracy: 0.8989\n",
            "Epoch: [ 0] [   50/60000], train_loss: 0.43385324, train_accuracy: 0.8672, test_Accuracy: 0.8999\n",
            "Epoch: [ 0] [   51/60000], train_loss: 0.28386036, train_accuracy: 0.9375, test_Accuracy: 0.8973\n",
            "Epoch: [ 0] [   52/60000], train_loss: 0.45029306, train_accuracy: 0.8984, test_Accuracy: 0.8983\n",
            "Epoch: [ 0] [   53/60000], train_loss: 0.52457875, train_accuracy: 0.8672, test_Accuracy: 0.8940\n",
            "Epoch: [ 0] [   54/60000], train_loss: 0.43415734, train_accuracy: 0.8750, test_Accuracy: 0.8936\n",
            "Epoch: [ 0] [   55/60000], train_loss: 0.38801223, train_accuracy: 0.8750, test_Accuracy: 0.8981\n",
            "Epoch: [ 0] [   56/60000], train_loss: 0.22816065, train_accuracy: 0.9375, test_Accuracy: 0.8995\n",
            "Epoch: [ 0] [   57/60000], train_loss: 0.47106898, train_accuracy: 0.8594, test_Accuracy: 0.8996\n",
            "Epoch: [ 0] [   58/60000], train_loss: 0.29463911, train_accuracy: 0.9297, test_Accuracy: 0.9000\n",
            "Epoch: [ 0] [   59/60000], train_loss: 0.24837935, train_accuracy: 0.9453, test_Accuracy: 0.8969\n",
            "Epoch: [ 0] [   60/60000], train_loss: 0.35293323, train_accuracy: 0.8750, test_Accuracy: 0.8991\n",
            "Epoch: [ 0] [   61/60000], train_loss: 0.25268480, train_accuracy: 0.9297, test_Accuracy: 0.9011\n",
            "Epoch: [ 0] [   62/60000], train_loss: 0.32371539, train_accuracy: 0.9219, test_Accuracy: 0.9044\n",
            "Epoch: [ 0] [   63/60000], train_loss: 0.37554854, train_accuracy: 0.8906, test_Accuracy: 0.9046\n",
            "Epoch: [ 0] [   64/60000], train_loss: 0.24920392, train_accuracy: 0.9297, test_Accuracy: 0.9047\n",
            "Epoch: [ 0] [   65/60000], train_loss: 0.28550476, train_accuracy: 0.9141, test_Accuracy: 0.9067\n",
            "Epoch: [ 0] [   66/60000], train_loss: 0.30038196, train_accuracy: 0.9375, test_Accuracy: 0.9047\n",
            "Epoch: [ 0] [   67/60000], train_loss: 0.27459586, train_accuracy: 0.9062, test_Accuracy: 0.9008\n",
            "Epoch: [ 0] [   68/60000], train_loss: 0.48105183, train_accuracy: 0.8672, test_Accuracy: 0.9051\n",
            "Epoch: [ 0] [   69/60000], train_loss: 0.24170530, train_accuracy: 0.9141, test_Accuracy: 0.9057\n",
            "Epoch: [ 0] [   70/60000], train_loss: 0.18159689, train_accuracy: 0.9609, test_Accuracy: 0.9050\n",
            "Epoch: [ 0] [   71/60000], train_loss: 0.26704729, train_accuracy: 0.9062, test_Accuracy: 0.9033\n",
            "Epoch: [ 0] [   72/60000], train_loss: 0.30297756, train_accuracy: 0.9297, test_Accuracy: 0.9004\n",
            "Epoch: [ 0] [   73/60000], train_loss: 0.35720697, train_accuracy: 0.8672, test_Accuracy: 0.9020\n",
            "Epoch: [ 0] [   74/60000], train_loss: 0.32040456, train_accuracy: 0.8828, test_Accuracy: 0.9036\n",
            "Epoch: [ 0] [   75/60000], train_loss: 0.33330059, train_accuracy: 0.8984, test_Accuracy: 0.9015\n",
            "Epoch: [ 0] [   76/60000], train_loss: 0.37026614, train_accuracy: 0.8906, test_Accuracy: 0.9029\n",
            "Epoch: [ 0] [   77/60000], train_loss: 0.19439998, train_accuracy: 0.9219, test_Accuracy: 0.9078\n",
            "Epoch: [ 0] [   78/60000], train_loss: 0.39361179, train_accuracy: 0.8828, test_Accuracy: 0.9120\n",
            "Epoch: [ 0] [   79/60000], train_loss: 0.31895953, train_accuracy: 0.8906, test_Accuracy: 0.9166\n",
            "Epoch: [ 0] [   80/60000], train_loss: 0.37385455, train_accuracy: 0.8750, test_Accuracy: 0.9160\n",
            "Epoch: [ 0] [   81/60000], train_loss: 0.35660079, train_accuracy: 0.8828, test_Accuracy: 0.9091\n",
            "Epoch: [ 0] [   82/60000], train_loss: 0.37736195, train_accuracy: 0.9219, test_Accuracy: 0.9021\n",
            "Epoch: [ 0] [   83/60000], train_loss: 0.22872886, train_accuracy: 0.9141, test_Accuracy: 0.8992\n",
            "Epoch: [ 0] [   84/60000], train_loss: 0.43348527, train_accuracy: 0.8906, test_Accuracy: 0.9038\n",
            "Epoch: [ 0] [   85/60000], train_loss: 0.38024750, train_accuracy: 0.8828, test_Accuracy: 0.9108\n",
            "Epoch: [ 0] [   86/60000], train_loss: 0.21864876, train_accuracy: 0.9531, test_Accuracy: 0.9153\n",
            "Epoch: [ 0] [   87/60000], train_loss: 0.35104129, train_accuracy: 0.9219, test_Accuracy: 0.9155\n",
            "Epoch: [ 0] [   88/60000], train_loss: 0.28313798, train_accuracy: 0.8906, test_Accuracy: 0.9120\n",
            "Epoch: [ 0] [   89/60000], train_loss: 0.44036692, train_accuracy: 0.8750, test_Accuracy: 0.9101\n",
            "Epoch: [ 0] [   90/60000], train_loss: 0.20796297, train_accuracy: 0.9531, test_Accuracy: 0.9103\n",
            "Epoch: [ 0] [   91/60000], train_loss: 0.20458382, train_accuracy: 0.9297, test_Accuracy: 0.9114\n",
            "Epoch: [ 0] [   92/60000], train_loss: 0.28720361, train_accuracy: 0.9375, test_Accuracy: 0.9171\n",
            "Epoch: [ 0] [   93/60000], train_loss: 0.32346675, train_accuracy: 0.8984, test_Accuracy: 0.9173\n",
            "Epoch: [ 0] [   94/60000], train_loss: 0.31003228, train_accuracy: 0.9062, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [   95/60000], train_loss: 0.40957996, train_accuracy: 0.8984, test_Accuracy: 0.9112\n",
            "Epoch: [ 0] [   96/60000], train_loss: 0.25178635, train_accuracy: 0.9297, test_Accuracy: 0.9104\n",
            "Epoch: [ 0] [   97/60000], train_loss: 0.37546653, train_accuracy: 0.8906, test_Accuracy: 0.9138\n",
            "Epoch: [ 0] [   98/60000], train_loss: 0.20533381, train_accuracy: 0.9453, test_Accuracy: 0.9175\n",
            "Epoch: [ 0] [   99/60000], train_loss: 0.24232864, train_accuracy: 0.9141, test_Accuracy: 0.9184\n",
            "Epoch: [ 0] [  100/60000], train_loss: 0.38609824, train_accuracy: 0.8750, test_Accuracy: 0.9172\n",
            "Epoch: [ 0] [  101/60000], train_loss: 0.36230725, train_accuracy: 0.8672, test_Accuracy: 0.9155\n",
            "Epoch: [ 0] [  102/60000], train_loss: 0.18940452, train_accuracy: 0.9375, test_Accuracy: 0.9144\n",
            "Epoch: [ 0] [  103/60000], train_loss: 0.40342879, train_accuracy: 0.8984, test_Accuracy: 0.9142\n",
            "Epoch: [ 0] [  104/60000], train_loss: 0.23375121, train_accuracy: 0.9219, test_Accuracy: 0.9191\n",
            "Epoch: [ 0] [  105/60000], train_loss: 0.26220274, train_accuracy: 0.9531, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  106/60000], train_loss: 0.31159958, train_accuracy: 0.9141, test_Accuracy: 0.9236\n",
            "Epoch: [ 0] [  107/60000], train_loss: 0.20050704, train_accuracy: 0.9609, test_Accuracy: 0.9234\n",
            "Epoch: [ 0] [  108/60000], train_loss: 0.45104089, train_accuracy: 0.8750, test_Accuracy: 0.9225\n",
            "Epoch: [ 0] [  109/60000], train_loss: 0.26677749, train_accuracy: 0.9375, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  110/60000], train_loss: 0.32008958, train_accuracy: 0.8906, test_Accuracy: 0.9204\n",
            "Epoch: [ 0] [  111/60000], train_loss: 0.27748489, train_accuracy: 0.9375, test_Accuracy: 0.9179\n",
            "Epoch: [ 0] [  112/60000], train_loss: 0.28552955, train_accuracy: 0.9219, test_Accuracy: 0.9167\n",
            "Epoch: [ 0] [  113/60000], train_loss: 0.26262355, train_accuracy: 0.9141, test_Accuracy: 0.9191\n",
            "Epoch: [ 0] [  114/60000], train_loss: 0.22318535, train_accuracy: 0.9453, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  115/60000], train_loss: 0.30649137, train_accuracy: 0.9141, test_Accuracy: 0.9254\n",
            "Epoch: [ 0] [  116/60000], train_loss: 0.35482970, train_accuracy: 0.9219, test_Accuracy: 0.9272\n",
            "Epoch: [ 0] [  117/60000], train_loss: 0.28687552, train_accuracy: 0.9297, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  118/60000], train_loss: 0.20098177, train_accuracy: 0.9609, test_Accuracy: 0.9242\n",
            "Epoch: [ 0] [  119/60000], train_loss: 0.29116112, train_accuracy: 0.9141, test_Accuracy: 0.9230\n",
            "Epoch: [ 0] [  120/60000], train_loss: 0.17848364, train_accuracy: 0.9453, test_Accuracy: 0.9222\n",
            "Epoch: [ 0] [  121/60000], train_loss: 0.21801677, train_accuracy: 0.9453, test_Accuracy: 0.9213\n",
            "Epoch: [ 0] [  122/60000], train_loss: 0.23484927, train_accuracy: 0.9219, test_Accuracy: 0.9221\n",
            "Epoch: [ 0] [  123/60000], train_loss: 0.24822447, train_accuracy: 0.9375, test_Accuracy: 0.9239\n",
            "Epoch: [ 0] [  124/60000], train_loss: 0.26064622, train_accuracy: 0.9297, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  125/60000], train_loss: 0.25745451, train_accuracy: 0.9297, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [  126/60000], train_loss: 0.18648015, train_accuracy: 0.9453, test_Accuracy: 0.9273\n",
            "Epoch: [ 0] [  127/60000], train_loss: 0.33977079, train_accuracy: 0.9141, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  128/60000], train_loss: 0.17836353, train_accuracy: 0.9375, test_Accuracy: 0.9247\n",
            "Epoch: [ 0] [  129/60000], train_loss: 0.20558938, train_accuracy: 0.9531, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  130/60000], train_loss: 0.22446829, train_accuracy: 0.9219, test_Accuracy: 0.9236\n",
            "Epoch: [ 0] [  131/60000], train_loss: 0.30089772, train_accuracy: 0.8984, test_Accuracy: 0.9246\n",
            "Epoch: [ 0] [  132/60000], train_loss: 0.20135102, train_accuracy: 0.9453, test_Accuracy: 0.9247\n",
            "Epoch: [ 0] [  133/60000], train_loss: 0.29839343, train_accuracy: 0.9141, test_Accuracy: 0.9280\n",
            "Epoch: [ 0] [  134/60000], train_loss: 0.21697029, train_accuracy: 0.9375, test_Accuracy: 0.9301\n",
            "Epoch: [ 0] [  135/60000], train_loss: 0.16341162, train_accuracy: 0.9609, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  136/60000], train_loss: 0.12592643, train_accuracy: 0.9609, test_Accuracy: 0.9237\n",
            "Epoch: [ 0] [  137/60000], train_loss: 0.34073144, train_accuracy: 0.9141, test_Accuracy: 0.9224\n",
            "Epoch: [ 0] [  138/60000], train_loss: 0.22571757, train_accuracy: 0.9531, test_Accuracy: 0.9230\n",
            "Epoch: [ 0] [  139/60000], train_loss: 0.36010781, train_accuracy: 0.9219, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  140/60000], train_loss: 0.28434840, train_accuracy: 0.9141, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  141/60000], train_loss: 0.15586716, train_accuracy: 0.9531, test_Accuracy: 0.9254\n",
            "Epoch: [ 0] [  142/60000], train_loss: 0.30387160, train_accuracy: 0.9141, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  143/60000], train_loss: 0.21199518, train_accuracy: 0.9297, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  144/60000], train_loss: 0.22038364, train_accuracy: 0.9375, test_Accuracy: 0.9251\n",
            "Epoch: [ 0] [  145/60000], train_loss: 0.23109607, train_accuracy: 0.9453, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  146/60000], train_loss: 0.21178573, train_accuracy: 0.9297, test_Accuracy: 0.9242\n",
            "Epoch: [ 0] [  147/60000], train_loss: 0.25052050, train_accuracy: 0.8984, test_Accuracy: 0.9243\n",
            "Epoch: [ 0] [  148/60000], train_loss: 0.18556261, train_accuracy: 0.9219, test_Accuracy: 0.9269\n",
            "Epoch: [ 0] [  149/60000], train_loss: 0.18951328, train_accuracy: 0.9453, test_Accuracy: 0.9295\n",
            "Epoch: [ 0] [  150/60000], train_loss: 0.22395808, train_accuracy: 0.9453, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  151/60000], train_loss: 0.33527645, train_accuracy: 0.9219, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  152/60000], train_loss: 0.23907050, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  153/60000], train_loss: 0.23277962, train_accuracy: 0.9375, test_Accuracy: 0.9320\n",
            "Epoch: [ 0] [  154/60000], train_loss: 0.13755384, train_accuracy: 0.9375, test_Accuracy: 0.9304\n",
            "Epoch: [ 0] [  155/60000], train_loss: 0.25660637, train_accuracy: 0.9141, test_Accuracy: 0.9291\n",
            "Epoch: [ 0] [  156/60000], train_loss: 0.24186836, train_accuracy: 0.9219, test_Accuracy: 0.9301\n",
            "Epoch: [ 0] [  157/60000], train_loss: 0.28535312, train_accuracy: 0.9062, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  158/60000], train_loss: 0.26943129, train_accuracy: 0.9297, test_Accuracy: 0.9356\n",
            "Epoch: [ 0] [  159/60000], train_loss: 0.13292053, train_accuracy: 0.9609, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  160/60000], train_loss: 0.19356842, train_accuracy: 0.9453, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  161/60000], train_loss: 0.13802530, train_accuracy: 0.9766, test_Accuracy: 0.9356\n",
            "Epoch: [ 0] [  162/60000], train_loss: 0.22131471, train_accuracy: 0.9141, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  163/60000], train_loss: 0.15830609, train_accuracy: 0.9609, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  164/60000], train_loss: 0.23763716, train_accuracy: 0.9141, test_Accuracy: 0.9341\n",
            "Epoch: [ 0] [  165/60000], train_loss: 0.18892306, train_accuracy: 0.9297, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  166/60000], train_loss: 0.24323323, train_accuracy: 0.9297, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  167/60000], train_loss: 0.29813078, train_accuracy: 0.9141, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  168/60000], train_loss: 0.21054238, train_accuracy: 0.9453, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  169/60000], train_loss: 0.29398724, train_accuracy: 0.9062, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  170/60000], train_loss: 0.27207759, train_accuracy: 0.9453, test_Accuracy: 0.9345\n",
            "Epoch: [ 0] [  171/60000], train_loss: 0.35271692, train_accuracy: 0.8906, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  172/60000], train_loss: 0.16811986, train_accuracy: 0.9531, test_Accuracy: 0.9372\n",
            "Epoch: [ 0] [  173/60000], train_loss: 0.25475904, train_accuracy: 0.9219, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  174/60000], train_loss: 0.21973945, train_accuracy: 0.9453, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [  175/60000], train_loss: 0.16387457, train_accuracy: 0.9531, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  176/60000], train_loss: 0.22916681, train_accuracy: 0.9453, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  177/60000], train_loss: 0.31921291, train_accuracy: 0.9062, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  178/60000], train_loss: 0.23743334, train_accuracy: 0.9297, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  179/60000], train_loss: 0.26402503, train_accuracy: 0.9297, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  180/60000], train_loss: 0.17479086, train_accuracy: 0.9609, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  181/60000], train_loss: 0.37191460, train_accuracy: 0.9062, test_Accuracy: 0.9407\n",
            "Epoch: [ 0] [  182/60000], train_loss: 0.27059442, train_accuracy: 0.9141, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  183/60000], train_loss: 0.18197939, train_accuracy: 0.9297, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  184/60000], train_loss: 0.31626955, train_accuracy: 0.9219, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  185/60000], train_loss: 0.20283505, train_accuracy: 0.9531, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  186/60000], train_loss: 0.24489360, train_accuracy: 0.9375, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  187/60000], train_loss: 0.14380634, train_accuracy: 0.9609, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  188/60000], train_loss: 0.23031467, train_accuracy: 0.9375, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  189/60000], train_loss: 0.26146796, train_accuracy: 0.9219, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  190/60000], train_loss: 0.17953286, train_accuracy: 0.9609, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  191/60000], train_loss: 0.19571772, train_accuracy: 0.9531, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  192/60000], train_loss: 0.23532569, train_accuracy: 0.9297, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  193/60000], train_loss: 0.12313527, train_accuracy: 0.9688, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  194/60000], train_loss: 0.30002582, train_accuracy: 0.8984, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  195/60000], train_loss: 0.21538976, train_accuracy: 0.9375, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  196/60000], train_loss: 0.22685632, train_accuracy: 0.9531, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  197/60000], train_loss: 0.12799916, train_accuracy: 0.9609, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  198/60000], train_loss: 0.16532612, train_accuracy: 0.9688, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  199/60000], train_loss: 0.14975297, train_accuracy: 0.9453, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  200/60000], train_loss: 0.12950721, train_accuracy: 0.9688, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  201/60000], train_loss: 0.20894068, train_accuracy: 0.9531, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  202/60000], train_loss: 0.20135280, train_accuracy: 0.9375, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  203/60000], train_loss: 0.15571511, train_accuracy: 0.9531, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  204/60000], train_loss: 0.33560184, train_accuracy: 0.9219, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  205/60000], train_loss: 0.13390869, train_accuracy: 0.9688, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  206/60000], train_loss: 0.12340522, train_accuracy: 0.9531, test_Accuracy: 0.9409\n",
            "Epoch: [ 0] [  207/60000], train_loss: 0.08492796, train_accuracy: 0.9766, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  208/60000], train_loss: 0.18161824, train_accuracy: 0.9531, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  209/60000], train_loss: 0.19440567, train_accuracy: 0.9375, test_Accuracy: 0.9372\n",
            "Epoch: [ 0] [  210/60000], train_loss: 0.29158893, train_accuracy: 0.8906, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  211/60000], train_loss: 0.13907227, train_accuracy: 0.9453, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  212/60000], train_loss: 0.19372343, train_accuracy: 0.9297, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  213/60000], train_loss: 0.22266962, train_accuracy: 0.9375, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  214/60000], train_loss: 0.22507563, train_accuracy: 0.9297, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  215/60000], train_loss: 0.17262295, train_accuracy: 0.9531, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  216/60000], train_loss: 0.16212043, train_accuracy: 0.9453, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  217/60000], train_loss: 0.14776206, train_accuracy: 0.9688, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  218/60000], train_loss: 0.17870697, train_accuracy: 0.9453, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  219/60000], train_loss: 0.15759018, train_accuracy: 0.9453, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  220/60000], train_loss: 0.19531177, train_accuracy: 0.9531, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  221/60000], train_loss: 0.12309690, train_accuracy: 0.9688, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  222/60000], train_loss: 0.18364023, train_accuracy: 0.9453, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  223/60000], train_loss: 0.17801857, train_accuracy: 0.9609, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  224/60000], train_loss: 0.19401377, train_accuracy: 0.9531, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  225/60000], train_loss: 0.23310542, train_accuracy: 0.9375, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  226/60000], train_loss: 0.19613504, train_accuracy: 0.9531, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  227/60000], train_loss: 0.16329609, train_accuracy: 0.9531, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  228/60000], train_loss: 0.20888591, train_accuracy: 0.9375, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  229/60000], train_loss: 0.11308838, train_accuracy: 0.9844, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  230/60000], train_loss: 0.15320204, train_accuracy: 0.9453, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  231/60000], train_loss: 0.22686285, train_accuracy: 0.8984, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  232/60000], train_loss: 0.21770741, train_accuracy: 0.9375, test_Accuracy: 0.9432\n",
            "Epoch: [ 0] [  233/60000], train_loss: 0.11498062, train_accuracy: 0.9688, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  234/60000], train_loss: 0.34820911, train_accuracy: 0.9141, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  235/60000], train_loss: 0.15896797, train_accuracy: 0.9453, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  236/60000], train_loss: 0.21650913, train_accuracy: 0.9141, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  237/60000], train_loss: 0.17753483, train_accuracy: 0.9609, test_Accuracy: 0.9453\n",
            "Epoch: [ 0] [  238/60000], train_loss: 0.15891027, train_accuracy: 0.9375, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  239/60000], train_loss: 0.28690362, train_accuracy: 0.9219, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  240/60000], train_loss: 0.22145763, train_accuracy: 0.9297, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  241/60000], train_loss: 0.12223841, train_accuracy: 0.9688, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  242/60000], train_loss: 0.26982224, train_accuracy: 0.9062, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  243/60000], train_loss: 0.24254084, train_accuracy: 0.9141, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  244/60000], train_loss: 0.16822180, train_accuracy: 0.9375, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  245/60000], train_loss: 0.14163758, train_accuracy: 0.9531, test_Accuracy: 0.9405\n",
            "Epoch: [ 0] [  246/60000], train_loss: 0.15848452, train_accuracy: 0.9453, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  247/60000], train_loss: 0.10645311, train_accuracy: 0.9766, test_Accuracy: 0.9367\n",
            "Epoch: [ 0] [  248/60000], train_loss: 0.18453640, train_accuracy: 0.9531, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  249/60000], train_loss: 0.14119144, train_accuracy: 0.9609, test_Accuracy: 0.9345\n",
            "Epoch: [ 0] [  250/60000], train_loss: 0.34758154, train_accuracy: 0.9141, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  251/60000], train_loss: 0.16873011, train_accuracy: 0.9375, test_Accuracy: 0.9356\n",
            "Epoch: [ 0] [  252/60000], train_loss: 0.24758384, train_accuracy: 0.9453, test_Accuracy: 0.9409\n",
            "Epoch: [ 0] [  253/60000], train_loss: 0.16655758, train_accuracy: 0.9609, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  254/60000], train_loss: 0.19272700, train_accuracy: 0.9297, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [  255/60000], train_loss: 0.17492546, train_accuracy: 0.9375, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  256/60000], train_loss: 0.28858179, train_accuracy: 0.9531, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  257/60000], train_loss: 0.27084166, train_accuracy: 0.9219, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  258/60000], train_loss: 0.17749524, train_accuracy: 0.9531, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  259/60000], train_loss: 0.14163087, train_accuracy: 0.9766, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  260/60000], train_loss: 0.12615629, train_accuracy: 0.9766, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  261/60000], train_loss: 0.17320958, train_accuracy: 0.9531, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  262/60000], train_loss: 0.15329504, train_accuracy: 0.9531, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  263/60000], train_loss: 0.12356536, train_accuracy: 0.9688, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  264/60000], train_loss: 0.28767729, train_accuracy: 0.9297, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  265/60000], train_loss: 0.20575634, train_accuracy: 0.9453, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  266/60000], train_loss: 0.21107662, train_accuracy: 0.9375, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  267/60000], train_loss: 0.22264963, train_accuracy: 0.9141, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  268/60000], train_loss: 0.22295952, train_accuracy: 0.9297, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  269/60000], train_loss: 0.17276371, train_accuracy: 0.9609, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  270/60000], train_loss: 0.19321430, train_accuracy: 0.9141, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  271/60000], train_loss: 0.15541252, train_accuracy: 0.9453, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  272/60000], train_loss: 0.12366296, train_accuracy: 0.9688, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  273/60000], train_loss: 0.13567916, train_accuracy: 0.9531, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  274/60000], train_loss: 0.18091008, train_accuracy: 0.9609, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [  275/60000], train_loss: 0.11945483, train_accuracy: 0.9688, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  276/60000], train_loss: 0.11975934, train_accuracy: 0.9609, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  277/60000], train_loss: 0.20825770, train_accuracy: 0.9141, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  278/60000], train_loss: 0.18813390, train_accuracy: 0.9375, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  279/60000], train_loss: 0.16521558, train_accuracy: 0.9531, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  280/60000], train_loss: 0.18093506, train_accuracy: 0.9531, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  281/60000], train_loss: 0.08585306, train_accuracy: 0.9766, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  282/60000], train_loss: 0.22740275, train_accuracy: 0.9375, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  283/60000], train_loss: 0.20982808, train_accuracy: 0.9297, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  284/60000], train_loss: 0.24083334, train_accuracy: 0.9375, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  285/60000], train_loss: 0.11728843, train_accuracy: 0.9766, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  286/60000], train_loss: 0.11999983, train_accuracy: 0.9766, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  287/60000], train_loss: 0.13680464, train_accuracy: 0.9609, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  288/60000], train_loss: 0.19633983, train_accuracy: 0.9531, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  289/60000], train_loss: 0.16109331, train_accuracy: 0.9531, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  290/60000], train_loss: 0.10200284, train_accuracy: 0.9844, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  291/60000], train_loss: 0.17110527, train_accuracy: 0.9688, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  292/60000], train_loss: 0.18737608, train_accuracy: 0.9531, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  293/60000], train_loss: 0.22634459, train_accuracy: 0.9531, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  294/60000], train_loss: 0.20258649, train_accuracy: 0.9609, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  295/60000], train_loss: 0.14175482, train_accuracy: 0.9609, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  296/60000], train_loss: 0.20006511, train_accuracy: 0.9141, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  297/60000], train_loss: 0.09878747, train_accuracy: 0.9844, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  298/60000], train_loss: 0.09688266, train_accuracy: 0.9766, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  299/60000], train_loss: 0.18342981, train_accuracy: 0.9375, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  300/60000], train_loss: 0.22683433, train_accuracy: 0.9531, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  301/60000], train_loss: 0.11497796, train_accuracy: 0.9688, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  302/60000], train_loss: 0.22262016, train_accuracy: 0.9375, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  303/60000], train_loss: 0.27157491, train_accuracy: 0.8906, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  304/60000], train_loss: 0.22303677, train_accuracy: 0.9453, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  305/60000], train_loss: 0.19770622, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  306/60000], train_loss: 0.11872664, train_accuracy: 0.9766, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  307/60000], train_loss: 0.07455773, train_accuracy: 0.9922, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  308/60000], train_loss: 0.14595920, train_accuracy: 0.9453, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  309/60000], train_loss: 0.11945070, train_accuracy: 0.9609, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  310/60000], train_loss: 0.11669289, train_accuracy: 0.9609, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  311/60000], train_loss: 0.17090535, train_accuracy: 0.9297, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  312/60000], train_loss: 0.13407607, train_accuracy: 0.9688, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  313/60000], train_loss: 0.12223174, train_accuracy: 0.9766, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  314/60000], train_loss: 0.15960245, train_accuracy: 0.9531, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  315/60000], train_loss: 0.11349826, train_accuracy: 0.9766, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  316/60000], train_loss: 0.14797270, train_accuracy: 0.9531, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  317/60000], train_loss: 0.23032857, train_accuracy: 0.9219, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  318/60000], train_loss: 0.20896690, train_accuracy: 0.9297, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  319/60000], train_loss: 0.14094415, train_accuracy: 0.9453, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  320/60000], train_loss: 0.07718872, train_accuracy: 0.9844, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  321/60000], train_loss: 0.11242002, train_accuracy: 0.9688, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  322/60000], train_loss: 0.16192672, train_accuracy: 0.9375, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  323/60000], train_loss: 0.32710975, train_accuracy: 0.9297, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  324/60000], train_loss: 0.20038477, train_accuracy: 0.9531, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  325/60000], train_loss: 0.12721691, train_accuracy: 0.9688, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  326/60000], train_loss: 0.14336661, train_accuracy: 0.9375, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  327/60000], train_loss: 0.16718838, train_accuracy: 0.9531, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  328/60000], train_loss: 0.15554141, train_accuracy: 0.9531, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  329/60000], train_loss: 0.09332015, train_accuracy: 0.9688, test_Accuracy: 0.9453\n",
            "Epoch: [ 0] [  330/60000], train_loss: 0.19073583, train_accuracy: 0.9531, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  331/60000], train_loss: 0.07115913, train_accuracy: 0.9844, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  332/60000], train_loss: 0.10516931, train_accuracy: 0.9453, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  333/60000], train_loss: 0.21189353, train_accuracy: 0.9375, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  334/60000], train_loss: 0.19561532, train_accuracy: 0.9219, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  335/60000], train_loss: 0.13244669, train_accuracy: 0.9609, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  336/60000], train_loss: 0.05548819, train_accuracy: 0.9844, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  337/60000], train_loss: 0.06771228, train_accuracy: 0.9844, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  338/60000], train_loss: 0.16688579, train_accuracy: 0.9688, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  339/60000], train_loss: 0.09445983, train_accuracy: 0.9766, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  340/60000], train_loss: 0.18372276, train_accuracy: 0.9531, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  341/60000], train_loss: 0.26570097, train_accuracy: 0.9062, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  342/60000], train_loss: 0.11099798, train_accuracy: 0.9531, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  343/60000], train_loss: 0.16438107, train_accuracy: 0.9531, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  344/60000], train_loss: 0.17461169, train_accuracy: 0.9375, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  345/60000], train_loss: 0.11736605, train_accuracy: 0.9844, test_Accuracy: 0.9555\n",
            "Epoch: [ 0] [  346/60000], train_loss: 0.07927808, train_accuracy: 0.9844, test_Accuracy: 0.9555\n",
            "Epoch: [ 0] [  347/60000], train_loss: 0.13835667, train_accuracy: 0.9531, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  348/60000], train_loss: 0.10493778, train_accuracy: 0.9766, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  349/60000], train_loss: 0.14434451, train_accuracy: 0.9531, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  350/60000], train_loss: 0.09526995, train_accuracy: 0.9766, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  351/60000], train_loss: 0.06750589, train_accuracy: 0.9844, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  352/60000], train_loss: 0.24643476, train_accuracy: 0.9609, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  353/60000], train_loss: 0.26180905, train_accuracy: 0.9219, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  354/60000], train_loss: 0.18463750, train_accuracy: 0.9688, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  355/60000], train_loss: 0.14453474, train_accuracy: 0.9766, test_Accuracy: 0.9565\n",
            "Epoch: [ 0] [  356/60000], train_loss: 0.15574560, train_accuracy: 0.9609, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  357/60000], train_loss: 0.11430180, train_accuracy: 0.9609, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  358/60000], train_loss: 0.12648232, train_accuracy: 0.9688, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  359/60000], train_loss: 0.11859117, train_accuracy: 0.9688, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  360/60000], train_loss: 0.12628247, train_accuracy: 0.9688, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  361/60000], train_loss: 0.12765265, train_accuracy: 0.9844, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  362/60000], train_loss: 0.11002220, train_accuracy: 0.9766, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  363/60000], train_loss: 0.07795666, train_accuracy: 0.9844, test_Accuracy: 0.9567\n",
            "Epoch: [ 0] [  364/60000], train_loss: 0.20094492, train_accuracy: 0.9297, test_Accuracy: 0.9560\n",
            "Epoch: [ 0] [  365/60000], train_loss: 0.21589278, train_accuracy: 0.9688, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  366/60000], train_loss: 0.14241251, train_accuracy: 0.9609, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  367/60000], train_loss: 0.13397613, train_accuracy: 0.9766, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  368/60000], train_loss: 0.17038053, train_accuracy: 0.9453, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  369/60000], train_loss: 0.09880373, train_accuracy: 0.9844, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  370/60000], train_loss: 0.04165881, train_accuracy: 0.9922, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  371/60000], train_loss: 0.08264342, train_accuracy: 0.9922, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  372/60000], train_loss: 0.12114009, train_accuracy: 0.9688, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  373/60000], train_loss: 0.14256848, train_accuracy: 0.9453, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  374/60000], train_loss: 0.23899963, train_accuracy: 0.9297, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  375/60000], train_loss: 0.19279185, train_accuracy: 0.9531, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  376/60000], train_loss: 0.11504551, train_accuracy: 0.9844, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  377/60000], train_loss: 0.15295154, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  378/60000], train_loss: 0.09854289, train_accuracy: 0.9688, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  379/60000], train_loss: 0.14787561, train_accuracy: 0.9453, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  380/60000], train_loss: 0.10169059, train_accuracy: 0.9609, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  381/60000], train_loss: 0.06411624, train_accuracy: 0.9844, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  382/60000], train_loss: 0.20677862, train_accuracy: 0.9219, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  383/60000], train_loss: 0.20743389, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  384/60000], train_loss: 0.09256472, train_accuracy: 0.9609, test_Accuracy: 0.9559\n",
            "Epoch: [ 0] [  385/60000], train_loss: 0.11857038, train_accuracy: 0.9609, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  386/60000], train_loss: 0.07796250, train_accuracy: 0.9766, test_Accuracy: 0.9555\n",
            "Epoch: [ 0] [  387/60000], train_loss: 0.13264561, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  388/60000], train_loss: 0.18662670, train_accuracy: 0.9453, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  389/60000], train_loss: 0.11965015, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  390/60000], train_loss: 0.19476113, train_accuracy: 0.9609, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  391/60000], train_loss: 0.36238569, train_accuracy: 0.9062, test_Accuracy: 0.9535\n",
            "Epoch: [ 0] [  392/60000], train_loss: 0.15292661, train_accuracy: 0.9375, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  393/60000], train_loss: 0.07550885, train_accuracy: 0.9766, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  394/60000], train_loss: 0.11310416, train_accuracy: 0.9766, test_Accuracy: 0.9565\n",
            "Epoch: [ 0] [  395/60000], train_loss: 0.12182303, train_accuracy: 0.9688, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  396/60000], train_loss: 0.18493508, train_accuracy: 0.9531, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  397/60000], train_loss: 0.15952665, train_accuracy: 0.9453, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  398/60000], train_loss: 0.09548993, train_accuracy: 0.9766, test_Accuracy: 0.9556\n",
            "Epoch: [ 0] [  399/60000], train_loss: 0.07674432, train_accuracy: 0.9922, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  400/60000], train_loss: 0.11340427, train_accuracy: 0.9766, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  401/60000], train_loss: 0.11165710, train_accuracy: 0.9688, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  402/60000], train_loss: 0.12498327, train_accuracy: 0.9609, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  403/60000], train_loss: 0.17882656, train_accuracy: 0.9531, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  404/60000], train_loss: 0.25875342, train_accuracy: 0.9453, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  405/60000], train_loss: 0.22768185, train_accuracy: 0.9141, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  406/60000], train_loss: 0.09780212, train_accuracy: 0.9688, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  407/60000], train_loss: 0.16257925, train_accuracy: 0.9453, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  408/60000], train_loss: 0.12094152, train_accuracy: 0.9453, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  409/60000], train_loss: 0.05951697, train_accuracy: 0.9922, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  410/60000], train_loss: 0.09008132, train_accuracy: 0.9844, test_Accuracy: 0.9526\n",
            "Epoch: [ 0] [  411/60000], train_loss: 0.14309506, train_accuracy: 0.9609, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  412/60000], train_loss: 0.12277474, train_accuracy: 0.9688, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  413/60000], train_loss: 0.14283735, train_accuracy: 0.9297, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  414/60000], train_loss: 0.14899285, train_accuracy: 0.9453, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  415/60000], train_loss: 0.12018740, train_accuracy: 0.9609, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  416/60000], train_loss: 0.10384022, train_accuracy: 0.9688, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  417/60000], train_loss: 0.23312601, train_accuracy: 0.9531, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  418/60000], train_loss: 0.11507672, train_accuracy: 0.9766, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  419/60000], train_loss: 0.25932720, train_accuracy: 0.9141, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  420/60000], train_loss: 0.16880491, train_accuracy: 0.9453, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  421/60000], train_loss: 0.22791529, train_accuracy: 0.9375, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  422/60000], train_loss: 0.10753315, train_accuracy: 0.9766, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  423/60000], train_loss: 0.12930551, train_accuracy: 0.9531, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  424/60000], train_loss: 0.20165309, train_accuracy: 0.9375, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  425/60000], train_loss: 0.19181854, train_accuracy: 0.9453, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  426/60000], train_loss: 0.14262542, train_accuracy: 0.9453, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  427/60000], train_loss: 0.10939876, train_accuracy: 0.9453, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  428/60000], train_loss: 0.11555586, train_accuracy: 0.9766, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  429/60000], train_loss: 0.21202001, train_accuracy: 0.9688, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  430/60000], train_loss: 0.19851452, train_accuracy: 0.9297, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  431/60000], train_loss: 0.21599858, train_accuracy: 0.9375, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  432/60000], train_loss: 0.11120389, train_accuracy: 0.9609, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  433/60000], train_loss: 0.10495728, train_accuracy: 0.9609, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  434/60000], train_loss: 0.07217848, train_accuracy: 0.9766, test_Accuracy: 0.9558\n",
            "Epoch: [ 0] [  435/60000], train_loss: 0.17330164, train_accuracy: 0.9688, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  436/60000], train_loss: 0.19741999, train_accuracy: 0.9609, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  437/60000], train_loss: 0.05274183, train_accuracy: 0.9922, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  438/60000], train_loss: 0.13087732, train_accuracy: 0.9766, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  439/60000], train_loss: 0.11125205, train_accuracy: 0.9688, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  440/60000], train_loss: 0.22627947, train_accuracy: 0.9453, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  441/60000], train_loss: 0.14088818, train_accuracy: 0.9531, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  442/60000], train_loss: 0.09198479, train_accuracy: 0.9688, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  443/60000], train_loss: 0.17814809, train_accuracy: 0.9453, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  444/60000], train_loss: 0.07921609, train_accuracy: 0.9922, test_Accuracy: 0.9602\n",
            "Epoch: [ 0] [  445/60000], train_loss: 0.09993997, train_accuracy: 0.9766, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  446/60000], train_loss: 0.21316271, train_accuracy: 0.9609, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  447/60000], train_loss: 0.07011061, train_accuracy: 0.9844, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  448/60000], train_loss: 0.15367806, train_accuracy: 0.9688, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  449/60000], train_loss: 0.24540484, train_accuracy: 0.9297, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  450/60000], train_loss: 0.11033329, train_accuracy: 0.9609, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  451/60000], train_loss: 0.14988104, train_accuracy: 0.9688, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  452/60000], train_loss: 0.14969255, train_accuracy: 0.9609, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  453/60000], train_loss: 0.19240485, train_accuracy: 0.9375, test_Accuracy: 0.9619\n",
            "Epoch: [ 0] [  454/60000], train_loss: 0.07965952, train_accuracy: 0.9766, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  455/60000], train_loss: 0.29092774, train_accuracy: 0.9141, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  456/60000], train_loss: 0.12122634, train_accuracy: 0.9531, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  457/60000], train_loss: 0.15694368, train_accuracy: 0.9609, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  458/60000], train_loss: 0.12046271, train_accuracy: 0.9688, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  459/60000], train_loss: 0.07855244, train_accuracy: 0.9766, test_Accuracy: 0.9594\n",
            "Epoch: [ 0] [  460/60000], train_loss: 0.14195749, train_accuracy: 0.9609, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  461/60000], train_loss: 0.06350900, train_accuracy: 0.9688, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  462/60000], train_loss: 0.24180615, train_accuracy: 0.9297, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  463/60000], train_loss: 0.06740730, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  464/60000], train_loss: 0.09353627, train_accuracy: 0.9688, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  465/60000], train_loss: 0.09402889, train_accuracy: 0.9844, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  466/60000], train_loss: 0.07058688, train_accuracy: 0.9766, test_Accuracy: 0.9627\n",
            "Epoch: [ 0] [  467/60000], train_loss: 0.09028235, train_accuracy: 0.9766, test_Accuracy: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHW5L3LeDwh8"
      },
      "source": [
        "<h1>Relu Function Test Accuracy : 96.25%</h1>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCvRAu731KeO"
      },
      "source": [
        "# Class type의 모델 2번째 : Sigmoid를 사용한다.\n",
        "class create_model_sigmoid(tf.keras.Model): # tf.keras.Model을 상속받아야 한다.\n",
        "  def __init__(self, label_dim): # label_dim : 몇 개의 output을 낼 것인지를 알려준다. 여기서는 10.\n",
        "    super(create_model_sigmoid, self).__init__()\n",
        "\n",
        "    weight_init = tf.keras.initializers.RandomNormal() # weight_init을 랜덤하게 생성. (평균이 0, 분산이 1인 가우시안 분포)\n",
        "    self.model = tf.keras.Sequential() # 리스트 자료구조 타입으로, 네트워크 구조의 레이어들을 담고 있다고 보면 되나?\n",
        "\n",
        "    # model에 flatten 레이어 추가. 이미지 shape를 펼쳐 준다.\n",
        "    self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "    for i in range(2):\n",
        "      # [N, 784] -> [N, 256] -> [N, 256]\n",
        "      self.model.add(dense(256, weight_init)) # flip-connected function * 2\n",
        "      self.model.add(sigmoid()) # relu function * 2\n",
        "\n",
        "    # 네트워크의 logits를 구함. 10개의 output으로 출력.\n",
        "    self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        " \n",
        " # 위에서 만든 model을 실제로 호출하는 함수.\n",
        "  def call(self, x, training=None, mask=None):\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb74J3cHET9J",
        "outputId": "e88cedb4-b977-40a9-95de-b21f0ef96551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_sigmoid(label_dim)\n",
        "\n",
        "# 여기선 체크포인트 구현은 생략했다. (핵심도 아니고, 귀찮고, 코랩 쓰고 있다보니.......)\n",
        "start_epoch = 0\n",
        "start_iteration = 0\n",
        "\n",
        "for epoch in range(start_epoch, training_epochs):\n",
        "  for idx, (train_input, train_label) in enumerate(train_dataset): #epoch, iteration 2개에 대해 반복 수행.\n",
        "    # gradient 구한 후 적용, 네트워크를 학습시킨다.\n",
        "    grads = grad(network, train_input, train_label)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "    # loss, 정확도를 구한다.\n",
        "    train_loss = loss_fn(network, train_input, train_label)\n",
        "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "    # test dataset을 불러오고, 정확도를 구한다.\n",
        "    for test_input, test_label in test_dataset:\n",
        "      test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    # 그 결과값을 출력한다.\n",
        "    print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" %(epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 0] [    0/60000], train_loss: 2.26130342, train_accuracy: 0.2422, test_Accuracy: 0.1680\n",
            "Epoch: [ 0] [    1/60000], train_loss: 2.30395555, train_accuracy: 0.1406, test_Accuracy: 0.1071\n",
            "Epoch: [ 0] [    2/60000], train_loss: 2.31546450, train_accuracy: 0.1094, test_Accuracy: 0.1010\n",
            "Epoch: [ 0] [    3/60000], train_loss: 2.22051382, train_accuracy: 0.2578, test_Accuracy: 0.2212\n",
            "Epoch: [ 0] [    4/60000], train_loss: 2.26138830, train_accuracy: 0.1328, test_Accuracy: 0.0982\n",
            "Epoch: [ 0] [    5/60000], train_loss: 2.20962024, train_accuracy: 0.0938, test_Accuracy: 0.0982\n",
            "Epoch: [ 0] [    6/60000], train_loss: 2.13300753, train_accuracy: 0.2031, test_Accuracy: 0.2253\n",
            "Epoch: [ 0] [    7/60000], train_loss: 2.10313439, train_accuracy: 0.2891, test_Accuracy: 0.3122\n",
            "Epoch: [ 0] [    8/60000], train_loss: 2.02653980, train_accuracy: 0.3672, test_Accuracy: 0.3100\n",
            "Epoch: [ 0] [    9/60000], train_loss: 1.93359292, train_accuracy: 0.3359, test_Accuracy: 0.2817\n",
            "Epoch: [ 0] [   10/60000], train_loss: 1.95268536, train_accuracy: 0.3984, test_Accuracy: 0.3913\n",
            "Epoch: [ 0] [   11/60000], train_loss: 1.95009708, train_accuracy: 0.4531, test_Accuracy: 0.4827\n",
            "Epoch: [ 0] [   12/60000], train_loss: 1.86677456, train_accuracy: 0.5781, test_Accuracy: 0.6006\n",
            "Epoch: [ 0] [   13/60000], train_loss: 1.71730971, train_accuracy: 0.5859, test_Accuracy: 0.5823\n",
            "Epoch: [ 0] [   14/60000], train_loss: 1.63317394, train_accuracy: 0.5078, test_Accuracy: 0.5234\n",
            "Epoch: [ 0] [   15/60000], train_loss: 1.64087677, train_accuracy: 0.4922, test_Accuracy: 0.5550\n",
            "Epoch: [ 0] [   16/60000], train_loss: 1.43934667, train_accuracy: 0.6250, test_Accuracy: 0.6027\n",
            "Epoch: [ 0] [   17/60000], train_loss: 1.42865658, train_accuracy: 0.6562, test_Accuracy: 0.6258\n",
            "Epoch: [ 0] [   18/60000], train_loss: 1.49772692, train_accuracy: 0.5703, test_Accuracy: 0.6396\n",
            "Epoch: [ 0] [   19/60000], train_loss: 1.29482496, train_accuracy: 0.6875, test_Accuracy: 0.6758\n",
            "Epoch: [ 0] [   20/60000], train_loss: 1.24469161, train_accuracy: 0.7109, test_Accuracy: 0.6879\n",
            "Epoch: [ 0] [   21/60000], train_loss: 1.19394004, train_accuracy: 0.6719, test_Accuracy: 0.6942\n",
            "Epoch: [ 0] [   22/60000], train_loss: 1.20138967, train_accuracy: 0.6562, test_Accuracy: 0.7001\n",
            "Epoch: [ 0] [   23/60000], train_loss: 0.94992709, train_accuracy: 0.7578, test_Accuracy: 0.7010\n",
            "Epoch: [ 0] [   24/60000], train_loss: 0.97057819, train_accuracy: 0.7344, test_Accuracy: 0.6992\n",
            "Epoch: [ 0] [   25/60000], train_loss: 1.02631259, train_accuracy: 0.6953, test_Accuracy: 0.6916\n",
            "Epoch: [ 0] [   26/60000], train_loss: 0.91614288, train_accuracy: 0.7344, test_Accuracy: 0.6860\n",
            "Epoch: [ 0] [   27/60000], train_loss: 0.95872897, train_accuracy: 0.6797, test_Accuracy: 0.6941\n",
            "Epoch: [ 0] [   28/60000], train_loss: 1.06643462, train_accuracy: 0.6875, test_Accuracy: 0.7255\n",
            "Epoch: [ 0] [   29/60000], train_loss: 0.92098343, train_accuracy: 0.7969, test_Accuracy: 0.7796\n",
            "Epoch: [ 0] [   30/60000], train_loss: 0.87182701, train_accuracy: 0.7891, test_Accuracy: 0.7885\n",
            "Epoch: [ 0] [   31/60000], train_loss: 0.78150702, train_accuracy: 0.7969, test_Accuracy: 0.7780\n",
            "Epoch: [ 0] [   32/60000], train_loss: 0.72960448, train_accuracy: 0.8359, test_Accuracy: 0.7706\n",
            "Epoch: [ 0] [   33/60000], train_loss: 0.80011183, train_accuracy: 0.7578, test_Accuracy: 0.7650\n",
            "Epoch: [ 0] [   34/60000], train_loss: 0.83995998, train_accuracy: 0.7422, test_Accuracy: 0.7653\n",
            "Epoch: [ 0] [   35/60000], train_loss: 0.84172314, train_accuracy: 0.7344, test_Accuracy: 0.7714\n",
            "Epoch: [ 0] [   36/60000], train_loss: 0.77007741, train_accuracy: 0.7812, test_Accuracy: 0.7750\n",
            "Epoch: [ 0] [   37/60000], train_loss: 0.70178890, train_accuracy: 0.7891, test_Accuracy: 0.7739\n",
            "Epoch: [ 0] [   38/60000], train_loss: 0.74118483, train_accuracy: 0.7734, test_Accuracy: 0.7735\n",
            "Epoch: [ 0] [   39/60000], train_loss: 0.66043001, train_accuracy: 0.8125, test_Accuracy: 0.7889\n",
            "Epoch: [ 0] [   40/60000], train_loss: 0.78396851, train_accuracy: 0.7578, test_Accuracy: 0.8017\n",
            "Epoch: [ 0] [   41/60000], train_loss: 0.58264565, train_accuracy: 0.8828, test_Accuracy: 0.8122\n",
            "Epoch: [ 0] [   42/60000], train_loss: 0.54855072, train_accuracy: 0.8516, test_Accuracy: 0.8236\n",
            "Epoch: [ 0] [   43/60000], train_loss: 0.68169355, train_accuracy: 0.8438, test_Accuracy: 0.8323\n",
            "Epoch: [ 0] [   44/60000], train_loss: 0.78339785, train_accuracy: 0.7812, test_Accuracy: 0.8377\n",
            "Epoch: [ 0] [   45/60000], train_loss: 0.55195051, train_accuracy: 0.8438, test_Accuracy: 0.8399\n",
            "Epoch: [ 0] [   46/60000], train_loss: 0.60193360, train_accuracy: 0.8438, test_Accuracy: 0.8336\n",
            "Epoch: [ 0] [   47/60000], train_loss: 0.55356729, train_accuracy: 0.8516, test_Accuracy: 0.8307\n",
            "Epoch: [ 0] [   48/60000], train_loss: 0.57840538, train_accuracy: 0.8125, test_Accuracy: 0.8355\n",
            "Epoch: [ 0] [   49/60000], train_loss: 0.39638716, train_accuracy: 0.9219, test_Accuracy: 0.8435\n",
            "Epoch: [ 0] [   50/60000], train_loss: 0.51636147, train_accuracy: 0.8594, test_Accuracy: 0.8510\n",
            "Epoch: [ 0] [   51/60000], train_loss: 0.51551235, train_accuracy: 0.8672, test_Accuracy: 0.8547\n",
            "Epoch: [ 0] [   52/60000], train_loss: 0.50512838, train_accuracy: 0.8750, test_Accuracy: 0.8573\n",
            "Epoch: [ 0] [   53/60000], train_loss: 0.51674777, train_accuracy: 0.8594, test_Accuracy: 0.8573\n",
            "Epoch: [ 0] [   54/60000], train_loss: 0.56501669, train_accuracy: 0.8359, test_Accuracy: 0.8570\n",
            "Epoch: [ 0] [   55/60000], train_loss: 0.51787639, train_accuracy: 0.8672, test_Accuracy: 0.8565\n",
            "Epoch: [ 0] [   56/60000], train_loss: 0.52064651, train_accuracy: 0.9141, test_Accuracy: 0.8580\n",
            "Epoch: [ 0] [   57/60000], train_loss: 0.57561487, train_accuracy: 0.8438, test_Accuracy: 0.8614\n",
            "Epoch: [ 0] [   58/60000], train_loss: 0.57021976, train_accuracy: 0.8594, test_Accuracy: 0.8625\n",
            "Epoch: [ 0] [   59/60000], train_loss: 0.51448482, train_accuracy: 0.8516, test_Accuracy: 0.8643\n",
            "Epoch: [ 0] [   60/60000], train_loss: 0.43917143, train_accuracy: 0.8906, test_Accuracy: 0.8673\n",
            "Epoch: [ 0] [   61/60000], train_loss: 0.61285824, train_accuracy: 0.7969, test_Accuracy: 0.8670\n",
            "Epoch: [ 0] [   62/60000], train_loss: 0.44072866, train_accuracy: 0.8828, test_Accuracy: 0.8653\n",
            "Epoch: [ 0] [   63/60000], train_loss: 0.45567873, train_accuracy: 0.8828, test_Accuracy: 0.8663\n",
            "Epoch: [ 0] [   64/60000], train_loss: 0.39583972, train_accuracy: 0.8984, test_Accuracy: 0.8684\n",
            "Epoch: [ 0] [   65/60000], train_loss: 0.43856478, train_accuracy: 0.8203, test_Accuracy: 0.8693\n",
            "Epoch: [ 0] [   66/60000], train_loss: 0.46317029, train_accuracy: 0.8516, test_Accuracy: 0.8700\n",
            "Epoch: [ 0] [   67/60000], train_loss: 0.55452228, train_accuracy: 0.8281, test_Accuracy: 0.8717\n",
            "Epoch: [ 0] [   68/60000], train_loss: 0.45481271, train_accuracy: 0.8750, test_Accuracy: 0.8754\n",
            "Epoch: [ 0] [   69/60000], train_loss: 0.42218351, train_accuracy: 0.9141, test_Accuracy: 0.8770\n",
            "Epoch: [ 0] [   70/60000], train_loss: 0.48768753, train_accuracy: 0.8672, test_Accuracy: 0.8760\n",
            "Epoch: [ 0] [   71/60000], train_loss: 0.47517776, train_accuracy: 0.8594, test_Accuracy: 0.8743\n",
            "Epoch: [ 0] [   72/60000], train_loss: 0.47710839, train_accuracy: 0.8203, test_Accuracy: 0.8748\n",
            "Epoch: [ 0] [   73/60000], train_loss: 0.38316292, train_accuracy: 0.8750, test_Accuracy: 0.8771\n",
            "Epoch: [ 0] [   74/60000], train_loss: 0.46901780, train_accuracy: 0.8438, test_Accuracy: 0.8796\n",
            "Epoch: [ 0] [   75/60000], train_loss: 0.46318960, train_accuracy: 0.8906, test_Accuracy: 0.8826\n",
            "Epoch: [ 0] [   76/60000], train_loss: 0.30216351, train_accuracy: 0.9141, test_Accuracy: 0.8836\n",
            "Epoch: [ 0] [   77/60000], train_loss: 0.38863683, train_accuracy: 0.8984, test_Accuracy: 0.8824\n",
            "Epoch: [ 0] [   78/60000], train_loss: 0.33782685, train_accuracy: 0.8750, test_Accuracy: 0.8817\n",
            "Epoch: [ 0] [   79/60000], train_loss: 0.49809855, train_accuracy: 0.8438, test_Accuracy: 0.8814\n",
            "Epoch: [ 0] [   80/60000], train_loss: 0.43296671, train_accuracy: 0.8828, test_Accuracy: 0.8824\n",
            "Epoch: [ 0] [   81/60000], train_loss: 0.49783438, train_accuracy: 0.8750, test_Accuracy: 0.8839\n",
            "Epoch: [ 0] [   82/60000], train_loss: 0.30739748, train_accuracy: 0.9062, test_Accuracy: 0.8850\n",
            "Epoch: [ 0] [   83/60000], train_loss: 0.51736164, train_accuracy: 0.8438, test_Accuracy: 0.8859\n",
            "Epoch: [ 0] [   84/60000], train_loss: 0.29814377, train_accuracy: 0.9297, test_Accuracy: 0.8881\n",
            "Epoch: [ 0] [   85/60000], train_loss: 0.39716697, train_accuracy: 0.9141, test_Accuracy: 0.8902\n",
            "Epoch: [ 0] [   86/60000], train_loss: 0.39062098, train_accuracy: 0.8984, test_Accuracy: 0.8897\n",
            "Epoch: [ 0] [   87/60000], train_loss: 0.47495630, train_accuracy: 0.8828, test_Accuracy: 0.8912\n",
            "Epoch: [ 0] [   88/60000], train_loss: 0.29907858, train_accuracy: 0.9062, test_Accuracy: 0.8922\n",
            "Epoch: [ 0] [   89/60000], train_loss: 0.48637086, train_accuracy: 0.8438, test_Accuracy: 0.8928\n",
            "Epoch: [ 0] [   90/60000], train_loss: 0.44994870, train_accuracy: 0.8906, test_Accuracy: 0.8923\n",
            "Epoch: [ 0] [   91/60000], train_loss: 0.33269721, train_accuracy: 0.9219, test_Accuracy: 0.8922\n",
            "Epoch: [ 0] [   92/60000], train_loss: 0.32203832, train_accuracy: 0.9219, test_Accuracy: 0.8928\n",
            "Epoch: [ 0] [   93/60000], train_loss: 0.27603805, train_accuracy: 0.9219, test_Accuracy: 0.8923\n",
            "Epoch: [ 0] [   94/60000], train_loss: 0.23960182, train_accuracy: 0.9375, test_Accuracy: 0.8903\n",
            "Epoch: [ 0] [   95/60000], train_loss: 0.41066843, train_accuracy: 0.9062, test_Accuracy: 0.8913\n",
            "Epoch: [ 0] [   96/60000], train_loss: 0.27338612, train_accuracy: 0.9375, test_Accuracy: 0.8929\n",
            "Epoch: [ 0] [   97/60000], train_loss: 0.34458870, train_accuracy: 0.9219, test_Accuracy: 0.8952\n",
            "Epoch: [ 0] [   98/60000], train_loss: 0.43002832, train_accuracy: 0.8750, test_Accuracy: 0.8998\n",
            "Epoch: [ 0] [   99/60000], train_loss: 0.38243276, train_accuracy: 0.8828, test_Accuracy: 0.9025\n",
            "Epoch: [ 0] [  100/60000], train_loss: 0.36629713, train_accuracy: 0.9141, test_Accuracy: 0.9029\n",
            "Epoch: [ 0] [  101/60000], train_loss: 0.37967288, train_accuracy: 0.9297, test_Accuracy: 0.9007\n",
            "Epoch: [ 0] [  102/60000], train_loss: 0.37399411, train_accuracy: 0.9219, test_Accuracy: 0.8993\n",
            "Epoch: [ 0] [  103/60000], train_loss: 0.43481213, train_accuracy: 0.8906, test_Accuracy: 0.8980\n",
            "Epoch: [ 0] [  104/60000], train_loss: 0.34251615, train_accuracy: 0.8984, test_Accuracy: 0.8997\n",
            "Epoch: [ 0] [  105/60000], train_loss: 0.29587811, train_accuracy: 0.9141, test_Accuracy: 0.9032\n",
            "Epoch: [ 0] [  106/60000], train_loss: 0.28275758, train_accuracy: 0.9297, test_Accuracy: 0.9045\n",
            "Epoch: [ 0] [  107/60000], train_loss: 0.32142633, train_accuracy: 0.8984, test_Accuracy: 0.9058\n",
            "Epoch: [ 0] [  108/60000], train_loss: 0.38968855, train_accuracy: 0.8984, test_Accuracy: 0.9057\n",
            "Epoch: [ 0] [  109/60000], train_loss: 0.17377803, train_accuracy: 0.9688, test_Accuracy: 0.9038\n",
            "Epoch: [ 0] [  110/60000], train_loss: 0.38907099, train_accuracy: 0.8594, test_Accuracy: 0.9037\n",
            "Epoch: [ 0] [  111/60000], train_loss: 0.33046764, train_accuracy: 0.8750, test_Accuracy: 0.9017\n",
            "Epoch: [ 0] [  112/60000], train_loss: 0.36877412, train_accuracy: 0.8672, test_Accuracy: 0.9039\n",
            "Epoch: [ 0] [  113/60000], train_loss: 0.24934591, train_accuracy: 0.9297, test_Accuracy: 0.9047\n",
            "Epoch: [ 0] [  114/60000], train_loss: 0.34571087, train_accuracy: 0.9141, test_Accuracy: 0.9064\n",
            "Epoch: [ 0] [  115/60000], train_loss: 0.25757572, train_accuracy: 0.9141, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [  116/60000], train_loss: 0.31875944, train_accuracy: 0.9062, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [  117/60000], train_loss: 0.41043037, train_accuracy: 0.8438, test_Accuracy: 0.9073\n",
            "Epoch: [ 0] [  118/60000], train_loss: 0.28290725, train_accuracy: 0.9297, test_Accuracy: 0.9070\n",
            "Epoch: [ 0] [  119/60000], train_loss: 0.44337857, train_accuracy: 0.8594, test_Accuracy: 0.9062\n",
            "Epoch: [ 0] [  120/60000], train_loss: 0.46105611, train_accuracy: 0.8672, test_Accuracy: 0.9034\n",
            "Epoch: [ 0] [  121/60000], train_loss: 0.31959534, train_accuracy: 0.9297, test_Accuracy: 0.9032\n",
            "Epoch: [ 0] [  122/60000], train_loss: 0.28552049, train_accuracy: 0.9062, test_Accuracy: 0.9025\n",
            "Epoch: [ 0] [  123/60000], train_loss: 0.35962957, train_accuracy: 0.9141, test_Accuracy: 0.9044\n",
            "Epoch: [ 0] [  124/60000], train_loss: 0.36753699, train_accuracy: 0.8750, test_Accuracy: 0.9067\n",
            "Epoch: [ 0] [  125/60000], train_loss: 0.35862800, train_accuracy: 0.8828, test_Accuracy: 0.9087\n",
            "Epoch: [ 0] [  126/60000], train_loss: 0.21910134, train_accuracy: 0.9141, test_Accuracy: 0.9109\n",
            "Epoch: [ 0] [  127/60000], train_loss: 0.30079263, train_accuracy: 0.9219, test_Accuracy: 0.9106\n",
            "Epoch: [ 0] [  128/60000], train_loss: 0.30056852, train_accuracy: 0.9062, test_Accuracy: 0.9129\n",
            "Epoch: [ 0] [  129/60000], train_loss: 0.40345612, train_accuracy: 0.8984, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [  130/60000], train_loss: 0.28259057, train_accuracy: 0.9141, test_Accuracy: 0.9131\n",
            "Epoch: [ 0] [  131/60000], train_loss: 0.24246228, train_accuracy: 0.9375, test_Accuracy: 0.9130\n",
            "Epoch: [ 0] [  132/60000], train_loss: 0.33185023, train_accuracy: 0.9219, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [  133/60000], train_loss: 0.30030164, train_accuracy: 0.9219, test_Accuracy: 0.9117\n",
            "Epoch: [ 0] [  134/60000], train_loss: 0.34610039, train_accuracy: 0.9141, test_Accuracy: 0.9127\n",
            "Epoch: [ 0] [  135/60000], train_loss: 0.29065055, train_accuracy: 0.9062, test_Accuracy: 0.9135\n",
            "Epoch: [ 0] [  136/60000], train_loss: 0.24354097, train_accuracy: 0.9453, test_Accuracy: 0.9138\n",
            "Epoch: [ 0] [  137/60000], train_loss: 0.28294000, train_accuracy: 0.9141, test_Accuracy: 0.9132\n",
            "Epoch: [ 0] [  138/60000], train_loss: 0.22457495, train_accuracy: 0.9219, test_Accuracy: 0.9128\n",
            "Epoch: [ 0] [  139/60000], train_loss: 0.31080675, train_accuracy: 0.9297, test_Accuracy: 0.9135\n",
            "Epoch: [ 0] [  140/60000], train_loss: 0.35334086, train_accuracy: 0.9141, test_Accuracy: 0.9138\n",
            "Epoch: [ 0] [  141/60000], train_loss: 0.33659858, train_accuracy: 0.8594, test_Accuracy: 0.9143\n",
            "Epoch: [ 0] [  142/60000], train_loss: 0.23312604, train_accuracy: 0.9375, test_Accuracy: 0.9146\n",
            "Epoch: [ 0] [  143/60000], train_loss: 0.41515854, train_accuracy: 0.8906, test_Accuracy: 0.9145\n",
            "Epoch: [ 0] [  144/60000], train_loss: 0.28871983, train_accuracy: 0.9219, test_Accuracy: 0.9137\n",
            "Epoch: [ 0] [  145/60000], train_loss: 0.23325631, train_accuracy: 0.9297, test_Accuracy: 0.9139\n",
            "Epoch: [ 0] [  146/60000], train_loss: 0.34457409, train_accuracy: 0.8828, test_Accuracy: 0.9129\n",
            "Epoch: [ 0] [  147/60000], train_loss: 0.19825065, train_accuracy: 0.9375, test_Accuracy: 0.9133\n",
            "Epoch: [ 0] [  148/60000], train_loss: 0.20451345, train_accuracy: 0.9453, test_Accuracy: 0.9133\n",
            "Epoch: [ 0] [  149/60000], train_loss: 0.38615882, train_accuracy: 0.8906, test_Accuracy: 0.9140\n",
            "Epoch: [ 0] [  150/60000], train_loss: 0.16049105, train_accuracy: 0.9531, test_Accuracy: 0.9130\n",
            "Epoch: [ 0] [  151/60000], train_loss: 0.33761162, train_accuracy: 0.9219, test_Accuracy: 0.9117\n",
            "Epoch: [ 0] [  152/60000], train_loss: 0.23983324, train_accuracy: 0.9219, test_Accuracy: 0.9110\n",
            "Epoch: [ 0] [  153/60000], train_loss: 0.40710694, train_accuracy: 0.8828, test_Accuracy: 0.9093\n",
            "Epoch: [ 0] [  154/60000], train_loss: 0.32305205, train_accuracy: 0.9062, test_Accuracy: 0.9104\n",
            "Epoch: [ 0] [  155/60000], train_loss: 0.45299092, train_accuracy: 0.8828, test_Accuracy: 0.9118\n",
            "Epoch: [ 0] [  156/60000], train_loss: 0.28870943, train_accuracy: 0.9062, test_Accuracy: 0.9115\n",
            "Epoch: [ 0] [  157/60000], train_loss: 0.37950218, train_accuracy: 0.8828, test_Accuracy: 0.9120\n",
            "Epoch: [ 0] [  158/60000], train_loss: 0.39461076, train_accuracy: 0.8906, test_Accuracy: 0.9105\n",
            "Epoch: [ 0] [  159/60000], train_loss: 0.32128531, train_accuracy: 0.9219, test_Accuracy: 0.9102\n",
            "Epoch: [ 0] [  160/60000], train_loss: 0.22993754, train_accuracy: 0.9219, test_Accuracy: 0.9075\n",
            "Epoch: [ 0] [  161/60000], train_loss: 0.34714782, train_accuracy: 0.8984, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [  162/60000], train_loss: 0.35905737, train_accuracy: 0.8750, test_Accuracy: 0.9084\n",
            "Epoch: [ 0] [  163/60000], train_loss: 0.18127033, train_accuracy: 0.9609, test_Accuracy: 0.9097\n",
            "Epoch: [ 0] [  164/60000], train_loss: 0.27793980, train_accuracy: 0.8906, test_Accuracy: 0.9115\n",
            "Epoch: [ 0] [  165/60000], train_loss: 0.25167656, train_accuracy: 0.9141, test_Accuracy: 0.9132\n",
            "Epoch: [ 0] [  166/60000], train_loss: 0.46188819, train_accuracy: 0.8750, test_Accuracy: 0.9147\n",
            "Epoch: [ 0] [  167/60000], train_loss: 0.31258854, train_accuracy: 0.9062, test_Accuracy: 0.9136\n",
            "Epoch: [ 0] [  168/60000], train_loss: 0.27204379, train_accuracy: 0.9062, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [  169/60000], train_loss: 0.27997330, train_accuracy: 0.9141, test_Accuracy: 0.9131\n",
            "Epoch: [ 0] [  170/60000], train_loss: 0.21405165, train_accuracy: 0.9375, test_Accuracy: 0.9123\n",
            "Epoch: [ 0] [  171/60000], train_loss: 0.23774287, train_accuracy: 0.9531, test_Accuracy: 0.9122\n",
            "Epoch: [ 0] [  172/60000], train_loss: 0.31572241, train_accuracy: 0.9219, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [  173/60000], train_loss: 0.19559960, train_accuracy: 0.9375, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [  174/60000], train_loss: 0.31435817, train_accuracy: 0.8984, test_Accuracy: 0.9134\n",
            "Epoch: [ 0] [  175/60000], train_loss: 0.30746579, train_accuracy: 0.9141, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [  176/60000], train_loss: 0.28744051, train_accuracy: 0.9453, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [  177/60000], train_loss: 0.33158585, train_accuracy: 0.8750, test_Accuracy: 0.9157\n",
            "Epoch: [ 0] [  178/60000], train_loss: 0.31711841, train_accuracy: 0.8984, test_Accuracy: 0.9164\n",
            "Epoch: [ 0] [  179/60000], train_loss: 0.34526393, train_accuracy: 0.8906, test_Accuracy: 0.9146\n",
            "Epoch: [ 0] [  180/60000], train_loss: 0.32214320, train_accuracy: 0.9062, test_Accuracy: 0.9148\n",
            "Epoch: [ 0] [  181/60000], train_loss: 0.39527380, train_accuracy: 0.9062, test_Accuracy: 0.9129\n",
            "Epoch: [ 0] [  182/60000], train_loss: 0.26862746, train_accuracy: 0.9219, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [  183/60000], train_loss: 0.30562919, train_accuracy: 0.8984, test_Accuracy: 0.9126\n",
            "Epoch: [ 0] [  184/60000], train_loss: 0.19169198, train_accuracy: 0.9531, test_Accuracy: 0.9130\n",
            "Epoch: [ 0] [  185/60000], train_loss: 0.27647561, train_accuracy: 0.9062, test_Accuracy: 0.9136\n",
            "Epoch: [ 0] [  186/60000], train_loss: 0.22137356, train_accuracy: 0.9609, test_Accuracy: 0.9128\n",
            "Epoch: [ 0] [  187/60000], train_loss: 0.26091099, train_accuracy: 0.9219, test_Accuracy: 0.9119\n",
            "Epoch: [ 0] [  188/60000], train_loss: 0.26293951, train_accuracy: 0.9219, test_Accuracy: 0.9119\n",
            "Epoch: [ 0] [  189/60000], train_loss: 0.26129124, train_accuracy: 0.8906, test_Accuracy: 0.9129\n",
            "Epoch: [ 0] [  190/60000], train_loss: 0.27692422, train_accuracy: 0.9062, test_Accuracy: 0.9145\n",
            "Epoch: [ 0] [  191/60000], train_loss: 0.36575523, train_accuracy: 0.8906, test_Accuracy: 0.9168\n",
            "Epoch: [ 0] [  192/60000], train_loss: 0.25378537, train_accuracy: 0.9453, test_Accuracy: 0.9167\n",
            "Epoch: [ 0] [  193/60000], train_loss: 0.39154446, train_accuracy: 0.8906, test_Accuracy: 0.9170\n",
            "Epoch: [ 0] [  194/60000], train_loss: 0.36186093, train_accuracy: 0.8906, test_Accuracy: 0.9167\n",
            "Epoch: [ 0] [  195/60000], train_loss: 0.16305304, train_accuracy: 0.9531, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [  196/60000], train_loss: 0.21293956, train_accuracy: 0.9453, test_Accuracy: 0.9155\n",
            "Epoch: [ 0] [  197/60000], train_loss: 0.42234164, train_accuracy: 0.8594, test_Accuracy: 0.9171\n",
            "Epoch: [ 0] [  198/60000], train_loss: 0.17919949, train_accuracy: 0.9531, test_Accuracy: 0.9190\n",
            "Epoch: [ 0] [  199/60000], train_loss: 0.32737824, train_accuracy: 0.8906, test_Accuracy: 0.9218\n",
            "Epoch: [ 0] [  200/60000], train_loss: 0.22594501, train_accuracy: 0.9297, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  201/60000], train_loss: 0.41122112, train_accuracy: 0.8984, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  202/60000], train_loss: 0.17439188, train_accuracy: 0.9531, test_Accuracy: 0.9169\n",
            "Epoch: [ 0] [  203/60000], train_loss: 0.30043951, train_accuracy: 0.9297, test_Accuracy: 0.9147\n",
            "Epoch: [ 0] [  204/60000], train_loss: 0.22351211, train_accuracy: 0.9531, test_Accuracy: 0.9133\n",
            "Epoch: [ 0] [  205/60000], train_loss: 0.24664637, train_accuracy: 0.9141, test_Accuracy: 0.9126\n",
            "Epoch: [ 0] [  206/60000], train_loss: 0.28328106, train_accuracy: 0.9141, test_Accuracy: 0.9127\n",
            "Epoch: [ 0] [  207/60000], train_loss: 0.29807526, train_accuracy: 0.9219, test_Accuracy: 0.9140\n",
            "Epoch: [ 0] [  208/60000], train_loss: 0.26862806, train_accuracy: 0.9141, test_Accuracy: 0.9141\n",
            "Epoch: [ 0] [  209/60000], train_loss: 0.20555046, train_accuracy: 0.9375, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [  210/60000], train_loss: 0.28841609, train_accuracy: 0.9219, test_Accuracy: 0.9190\n",
            "Epoch: [ 0] [  211/60000], train_loss: 0.30668822, train_accuracy: 0.8828, test_Accuracy: 0.9205\n",
            "Epoch: [ 0] [  212/60000], train_loss: 0.31784439, train_accuracy: 0.8984, test_Accuracy: 0.9201\n",
            "Epoch: [ 0] [  213/60000], train_loss: 0.29687068, train_accuracy: 0.9141, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  214/60000], train_loss: 0.25710380, train_accuracy: 0.9062, test_Accuracy: 0.9202\n",
            "Epoch: [ 0] [  215/60000], train_loss: 0.23482436, train_accuracy: 0.9375, test_Accuracy: 0.9207\n",
            "Epoch: [ 0] [  216/60000], train_loss: 0.33752209, train_accuracy: 0.8906, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  217/60000], train_loss: 0.33502305, train_accuracy: 0.8906, test_Accuracy: 0.9210\n",
            "Epoch: [ 0] [  218/60000], train_loss: 0.22090445, train_accuracy: 0.9219, test_Accuracy: 0.9202\n",
            "Epoch: [ 0] [  219/60000], train_loss: 0.32800996, train_accuracy: 0.9141, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  220/60000], train_loss: 0.24296251, train_accuracy: 0.9141, test_Accuracy: 0.9214\n",
            "Epoch: [ 0] [  221/60000], train_loss: 0.33823586, train_accuracy: 0.8828, test_Accuracy: 0.9218\n",
            "Epoch: [ 0] [  222/60000], train_loss: 0.29910401, train_accuracy: 0.9141, test_Accuracy: 0.9221\n",
            "Epoch: [ 0] [  223/60000], train_loss: 0.30492344, train_accuracy: 0.9297, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  224/60000], train_loss: 0.27775371, train_accuracy: 0.9141, test_Accuracy: 0.9215\n",
            "Epoch: [ 0] [  225/60000], train_loss: 0.27338925, train_accuracy: 0.9141, test_Accuracy: 0.9221\n",
            "Epoch: [ 0] [  226/60000], train_loss: 0.33766043, train_accuracy: 0.8984, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  227/60000], train_loss: 0.20793128, train_accuracy: 0.9453, test_Accuracy: 0.9224\n",
            "Epoch: [ 0] [  228/60000], train_loss: 0.28050447, train_accuracy: 0.9297, test_Accuracy: 0.9223\n",
            "Epoch: [ 0] [  229/60000], train_loss: 0.32577908, train_accuracy: 0.9062, test_Accuracy: 0.9223\n",
            "Epoch: [ 0] [  230/60000], train_loss: 0.27155578, train_accuracy: 0.9219, test_Accuracy: 0.9215\n",
            "Epoch: [ 0] [  231/60000], train_loss: 0.29057974, train_accuracy: 0.8906, test_Accuracy: 0.9219\n",
            "Epoch: [ 0] [  232/60000], train_loss: 0.37495399, train_accuracy: 0.9062, test_Accuracy: 0.9209\n",
            "Epoch: [ 0] [  233/60000], train_loss: 0.28550947, train_accuracy: 0.9141, test_Accuracy: 0.9204\n",
            "Epoch: [ 0] [  234/60000], train_loss: 0.31529820, train_accuracy: 0.8984, test_Accuracy: 0.9205\n",
            "Epoch: [ 0] [  235/60000], train_loss: 0.28590694, train_accuracy: 0.9141, test_Accuracy: 0.9212\n",
            "Epoch: [ 0] [  236/60000], train_loss: 0.20157510, train_accuracy: 0.9453, test_Accuracy: 0.9209\n",
            "Epoch: [ 0] [  237/60000], train_loss: 0.35373408, train_accuracy: 0.8984, test_Accuracy: 0.9206\n",
            "Epoch: [ 0] [  238/60000], train_loss: 0.34067348, train_accuracy: 0.9062, test_Accuracy: 0.9213\n",
            "Epoch: [ 0] [  239/60000], train_loss: 0.17926696, train_accuracy: 0.9531, test_Accuracy: 0.9212\n",
            "Epoch: [ 0] [  240/60000], train_loss: 0.34853750, train_accuracy: 0.9141, test_Accuracy: 0.9225\n",
            "Epoch: [ 0] [  241/60000], train_loss: 0.21499914, train_accuracy: 0.9453, test_Accuracy: 0.9224\n",
            "Epoch: [ 0] [  242/60000], train_loss: 0.34770191, train_accuracy: 0.8828, test_Accuracy: 0.9234\n",
            "Epoch: [ 0] [  243/60000], train_loss: 0.28176987, train_accuracy: 0.9062, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  244/60000], train_loss: 0.19399439, train_accuracy: 0.9453, test_Accuracy: 0.9241\n",
            "Epoch: [ 0] [  245/60000], train_loss: 0.28995192, train_accuracy: 0.8828, test_Accuracy: 0.9252\n",
            "Epoch: [ 0] [  246/60000], train_loss: 0.22140920, train_accuracy: 0.9297, test_Accuracy: 0.9257\n",
            "Epoch: [ 0] [  247/60000], train_loss: 0.26408309, train_accuracy: 0.9375, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  248/60000], train_loss: 0.25928032, train_accuracy: 0.9453, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  249/60000], train_loss: 0.21390581, train_accuracy: 0.9297, test_Accuracy: 0.9253\n",
            "Epoch: [ 0] [  250/60000], train_loss: 0.24494627, train_accuracy: 0.9297, test_Accuracy: 0.9246\n",
            "Epoch: [ 0] [  251/60000], train_loss: 0.25413632, train_accuracy: 0.9219, test_Accuracy: 0.9252\n",
            "Epoch: [ 0] [  252/60000], train_loss: 0.23166862, train_accuracy: 0.9141, test_Accuracy: 0.9254\n",
            "Epoch: [ 0] [  253/60000], train_loss: 0.23716752, train_accuracy: 0.9297, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  254/60000], train_loss: 0.24879523, train_accuracy: 0.9297, test_Accuracy: 0.9255\n",
            "Epoch: [ 0] [  255/60000], train_loss: 0.26342806, train_accuracy: 0.8984, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  256/60000], train_loss: 0.17738117, train_accuracy: 0.9375, test_Accuracy: 0.9256\n",
            "Epoch: [ 0] [  257/60000], train_loss: 0.19002916, train_accuracy: 0.9453, test_Accuracy: 0.9247\n",
            "Epoch: [ 0] [  258/60000], train_loss: 0.25032121, train_accuracy: 0.9375, test_Accuracy: 0.9250\n",
            "Epoch: [ 0] [  259/60000], train_loss: 0.33575523, train_accuracy: 0.9062, test_Accuracy: 0.9256\n",
            "Epoch: [ 0] [  260/60000], train_loss: 0.22038162, train_accuracy: 0.9609, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [  261/60000], train_loss: 0.27314889, train_accuracy: 0.9141, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [  262/60000], train_loss: 0.25502110, train_accuracy: 0.9141, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  263/60000], train_loss: 0.32055524, train_accuracy: 0.8828, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  264/60000], train_loss: 0.26936868, train_accuracy: 0.8906, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  265/60000], train_loss: 0.20296977, train_accuracy: 0.9453, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  266/60000], train_loss: 0.32670930, train_accuracy: 0.9141, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  267/60000], train_loss: 0.31830978, train_accuracy: 0.9141, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  268/60000], train_loss: 0.24133813, train_accuracy: 0.9219, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  269/60000], train_loss: 0.25370753, train_accuracy: 0.9219, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  270/60000], train_loss: 0.17074311, train_accuracy: 0.9375, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  271/60000], train_loss: 0.20190787, train_accuracy: 0.9219, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  272/60000], train_loss: 0.27715948, train_accuracy: 0.9062, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  273/60000], train_loss: 0.28679013, train_accuracy: 0.9219, test_Accuracy: 0.9256\n",
            "Epoch: [ 0] [  274/60000], train_loss: 0.27776912, train_accuracy: 0.9219, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  275/60000], train_loss: 0.27760792, train_accuracy: 0.9297, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  276/60000], train_loss: 0.20390880, train_accuracy: 0.9141, test_Accuracy: 0.9273\n",
            "Epoch: [ 0] [  277/60000], train_loss: 0.18679492, train_accuracy: 0.9297, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [  278/60000], train_loss: 0.26021335, train_accuracy: 0.9219, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [  279/60000], train_loss: 0.35714522, train_accuracy: 0.8828, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  280/60000], train_loss: 0.12491284, train_accuracy: 0.9844, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  281/60000], train_loss: 0.27115405, train_accuracy: 0.8906, test_Accuracy: 0.9288\n",
            "Epoch: [ 0] [  282/60000], train_loss: 0.20210725, train_accuracy: 0.9688, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  283/60000], train_loss: 0.11952637, train_accuracy: 0.9688, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  284/60000], train_loss: 0.33674544, train_accuracy: 0.8750, test_Accuracy: 0.9272\n",
            "Epoch: [ 0] [  285/60000], train_loss: 0.27654243, train_accuracy: 0.9375, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  286/60000], train_loss: 0.22445801, train_accuracy: 0.9219, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  287/60000], train_loss: 0.23231500, train_accuracy: 0.9375, test_Accuracy: 0.9281\n",
            "Epoch: [ 0] [  288/60000], train_loss: 0.28589860, train_accuracy: 0.9297, test_Accuracy: 0.9287\n",
            "Epoch: [ 0] [  289/60000], train_loss: 0.37645271, train_accuracy: 0.9141, test_Accuracy: 0.9279\n",
            "Epoch: [ 0] [  290/60000], train_loss: 0.15582237, train_accuracy: 0.9609, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  291/60000], train_loss: 0.21242104, train_accuracy: 0.9219, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  292/60000], train_loss: 0.22503322, train_accuracy: 0.9375, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  293/60000], train_loss: 0.14972308, train_accuracy: 0.9609, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  294/60000], train_loss: 0.31390992, train_accuracy: 0.9062, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  295/60000], train_loss: 0.26465821, train_accuracy: 0.9219, test_Accuracy: 0.9272\n",
            "Epoch: [ 0] [  296/60000], train_loss: 0.24471141, train_accuracy: 0.9219, test_Accuracy: 0.9279\n",
            "Epoch: [ 0] [  297/60000], train_loss: 0.27030179, train_accuracy: 0.9141, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  298/60000], train_loss: 0.31771925, train_accuracy: 0.8984, test_Accuracy: 0.9261\n",
            "Epoch: [ 0] [  299/60000], train_loss: 0.23771302, train_accuracy: 0.9219, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [  300/60000], train_loss: 0.20227653, train_accuracy: 0.9453, test_Accuracy: 0.9273\n",
            "Epoch: [ 0] [  301/60000], train_loss: 0.20969665, train_accuracy: 0.9531, test_Accuracy: 0.9279\n",
            "Epoch: [ 0] [  302/60000], train_loss: 0.13065946, train_accuracy: 0.9531, test_Accuracy: 0.9279\n",
            "Epoch: [ 0] [  303/60000], train_loss: 0.16024147, train_accuracy: 0.9531, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  304/60000], train_loss: 0.21430296, train_accuracy: 0.9297, test_Accuracy: 0.9299\n",
            "Epoch: [ 0] [  305/60000], train_loss: 0.20127937, train_accuracy: 0.9375, test_Accuracy: 0.9309\n",
            "Epoch: [ 0] [  306/60000], train_loss: 0.28403077, train_accuracy: 0.9141, test_Accuracy: 0.9312\n",
            "Epoch: [ 0] [  307/60000], train_loss: 0.27027464, train_accuracy: 0.9141, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  308/60000], train_loss: 0.19150546, train_accuracy: 0.9375, test_Accuracy: 0.9316\n",
            "Epoch: [ 0] [  309/60000], train_loss: 0.21488371, train_accuracy: 0.9609, test_Accuracy: 0.9325\n",
            "Epoch: [ 0] [  310/60000], train_loss: 0.20751674, train_accuracy: 0.9453, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  311/60000], train_loss: 0.21336503, train_accuracy: 0.9375, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  312/60000], train_loss: 0.12639086, train_accuracy: 0.9531, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  313/60000], train_loss: 0.27480260, train_accuracy: 0.9141, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  314/60000], train_loss: 0.29388615, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  315/60000], train_loss: 0.19063365, train_accuracy: 0.9609, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  316/60000], train_loss: 0.15659396, train_accuracy: 0.9531, test_Accuracy: 0.9309\n",
            "Epoch: [ 0] [  317/60000], train_loss: 0.25741979, train_accuracy: 0.9297, test_Accuracy: 0.9293\n",
            "Epoch: [ 0] [  318/60000], train_loss: 0.25306076, train_accuracy: 0.9219, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [  319/60000], train_loss: 0.22484031, train_accuracy: 0.9375, test_Accuracy: 0.9277\n",
            "Epoch: [ 0] [  320/60000], train_loss: 0.25026560, train_accuracy: 0.9219, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  321/60000], train_loss: 0.28098792, train_accuracy: 0.9141, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  322/60000], train_loss: 0.21697684, train_accuracy: 0.9219, test_Accuracy: 0.9305\n",
            "Epoch: [ 0] [  323/60000], train_loss: 0.23085323, train_accuracy: 0.9375, test_Accuracy: 0.9308\n",
            "Epoch: [ 0] [  324/60000], train_loss: 0.14794183, train_accuracy: 0.9844, test_Accuracy: 0.9308\n",
            "Epoch: [ 0] [  325/60000], train_loss: 0.22496907, train_accuracy: 0.9375, test_Accuracy: 0.9310\n",
            "Epoch: [ 0] [  326/60000], train_loss: 0.24507639, train_accuracy: 0.9297, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [  327/60000], train_loss: 0.28844970, train_accuracy: 0.9062, test_Accuracy: 0.9319\n",
            "Epoch: [ 0] [  328/60000], train_loss: 0.21609463, train_accuracy: 0.9453, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  329/60000], train_loss: 0.14632431, train_accuracy: 0.9609, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  330/60000], train_loss: 0.21162009, train_accuracy: 0.9375, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  331/60000], train_loss: 0.29795998, train_accuracy: 0.8984, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  332/60000], train_loss: 0.20665400, train_accuracy: 0.9219, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  333/60000], train_loss: 0.13876538, train_accuracy: 0.9453, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  334/60000], train_loss: 0.16215569, train_accuracy: 0.9609, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  335/60000], train_loss: 0.26244828, train_accuracy: 0.8906, test_Accuracy: 0.9311\n",
            "Epoch: [ 0] [  336/60000], train_loss: 0.22858912, train_accuracy: 0.9453, test_Accuracy: 0.9312\n",
            "Epoch: [ 0] [  337/60000], train_loss: 0.22390971, train_accuracy: 0.9297, test_Accuracy: 0.9313\n",
            "Epoch: [ 0] [  338/60000], train_loss: 0.17080823, train_accuracy: 0.9297, test_Accuracy: 0.9318\n",
            "Epoch: [ 0] [  339/60000], train_loss: 0.27157348, train_accuracy: 0.9141, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  340/60000], train_loss: 0.32066166, train_accuracy: 0.8984, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  341/60000], train_loss: 0.23265016, train_accuracy: 0.9297, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  342/60000], train_loss: 0.23232940, train_accuracy: 0.9375, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  343/60000], train_loss: 0.24247907, train_accuracy: 0.9375, test_Accuracy: 0.9322\n",
            "Epoch: [ 0] [  344/60000], train_loss: 0.20858780, train_accuracy: 0.9453, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  345/60000], train_loss: 0.22802754, train_accuracy: 0.9609, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  346/60000], train_loss: 0.17455038, train_accuracy: 0.9531, test_Accuracy: 0.9334\n",
            "Epoch: [ 0] [  347/60000], train_loss: 0.32783645, train_accuracy: 0.9219, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  348/60000], train_loss: 0.27678916, train_accuracy: 0.9297, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  349/60000], train_loss: 0.37611023, train_accuracy: 0.8906, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  350/60000], train_loss: 0.19270027, train_accuracy: 0.9375, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  351/60000], train_loss: 0.24205141, train_accuracy: 0.9375, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  352/60000], train_loss: 0.23689385, train_accuracy: 0.9219, test_Accuracy: 0.9334\n",
            "Epoch: [ 0] [  353/60000], train_loss: 0.27312464, train_accuracy: 0.9531, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  354/60000], train_loss: 0.16208926, train_accuracy: 0.9766, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  355/60000], train_loss: 0.22153378, train_accuracy: 0.9453, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  356/60000], train_loss: 0.25561708, train_accuracy: 0.9297, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  357/60000], train_loss: 0.24148357, train_accuracy: 0.9141, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  358/60000], train_loss: 0.12598144, train_accuracy: 0.9531, test_Accuracy: 0.9341\n",
            "Epoch: [ 0] [  359/60000], train_loss: 0.17224088, train_accuracy: 0.9219, test_Accuracy: 0.9340\n",
            "Epoch: [ 0] [  360/60000], train_loss: 0.25186670, train_accuracy: 0.9141, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [  361/60000], train_loss: 0.28230876, train_accuracy: 0.9297, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  362/60000], train_loss: 0.11336251, train_accuracy: 0.9688, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  363/60000], train_loss: 0.26540855, train_accuracy: 0.9375, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  364/60000], train_loss: 0.25763980, train_accuracy: 0.9062, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  365/60000], train_loss: 0.23539570, train_accuracy: 0.9453, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  366/60000], train_loss: 0.13387936, train_accuracy: 0.9688, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  367/60000], train_loss: 0.12584469, train_accuracy: 0.9688, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  368/60000], train_loss: 0.23710611, train_accuracy: 0.9219, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  369/60000], train_loss: 0.13508019, train_accuracy: 0.9531, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  370/60000], train_loss: 0.18010980, train_accuracy: 0.9453, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  371/60000], train_loss: 0.26178938, train_accuracy: 0.9062, test_Accuracy: 0.9325\n",
            "Epoch: [ 0] [  372/60000], train_loss: 0.14246166, train_accuracy: 0.9609, test_Accuracy: 0.9323\n",
            "Epoch: [ 0] [  373/60000], train_loss: 0.18099561, train_accuracy: 0.9453, test_Accuracy: 0.9322\n",
            "Epoch: [ 0] [  374/60000], train_loss: 0.18006654, train_accuracy: 0.9297, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  375/60000], train_loss: 0.13650848, train_accuracy: 0.9609, test_Accuracy: 0.9345\n",
            "Epoch: [ 0] [  376/60000], train_loss: 0.16995710, train_accuracy: 0.9375, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  377/60000], train_loss: 0.23719519, train_accuracy: 0.9219, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  378/60000], train_loss: 0.27669221, train_accuracy: 0.9297, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  379/60000], train_loss: 0.18504927, train_accuracy: 0.9375, test_Accuracy: 0.9379\n",
            "Epoch: [ 0] [  380/60000], train_loss: 0.18534127, train_accuracy: 0.9219, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  381/60000], train_loss: 0.20250306, train_accuracy: 0.9297, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  382/60000], train_loss: 0.17456605, train_accuracy: 0.9531, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  383/60000], train_loss: 0.27887273, train_accuracy: 0.9297, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  384/60000], train_loss: 0.19875938, train_accuracy: 0.9453, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  385/60000], train_loss: 0.22768372, train_accuracy: 0.9453, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  386/60000], train_loss: 0.26016253, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  387/60000], train_loss: 0.32375887, train_accuracy: 0.8984, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  388/60000], train_loss: 0.21554175, train_accuracy: 0.9375, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  389/60000], train_loss: 0.34797817, train_accuracy: 0.9141, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  390/60000], train_loss: 0.18375342, train_accuracy: 0.9297, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  391/60000], train_loss: 0.13770820, train_accuracy: 0.9609, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  392/60000], train_loss: 0.21391195, train_accuracy: 0.9297, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  393/60000], train_loss: 0.12244979, train_accuracy: 0.9766, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  394/60000], train_loss: 0.14607516, train_accuracy: 0.9531, test_Accuracy: 0.9372\n",
            "Epoch: [ 0] [  395/60000], train_loss: 0.13819501, train_accuracy: 0.9609, test_Accuracy: 0.9367\n",
            "Epoch: [ 0] [  396/60000], train_loss: 0.30424821, train_accuracy: 0.8828, test_Accuracy: 0.9356\n",
            "Epoch: [ 0] [  397/60000], train_loss: 0.15912567, train_accuracy: 0.9531, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  398/60000], train_loss: 0.16012609, train_accuracy: 0.9375, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  399/60000], train_loss: 0.18098572, train_accuracy: 0.9375, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  400/60000], train_loss: 0.20169818, train_accuracy: 0.9219, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  401/60000], train_loss: 0.22173104, train_accuracy: 0.9297, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  402/60000], train_loss: 0.17242749, train_accuracy: 0.9609, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  403/60000], train_loss: 0.23404056, train_accuracy: 0.9453, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  404/60000], train_loss: 0.15919101, train_accuracy: 0.9688, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  405/60000], train_loss: 0.11607665, train_accuracy: 0.9844, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  406/60000], train_loss: 0.18334165, train_accuracy: 0.9375, test_Accuracy: 0.9350\n",
            "Epoch: [ 0] [  407/60000], train_loss: 0.25674254, train_accuracy: 0.9453, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  408/60000], train_loss: 0.21431896, train_accuracy: 0.9297, test_Accuracy: 0.9367\n",
            "Epoch: [ 0] [  409/60000], train_loss: 0.14539269, train_accuracy: 0.9453, test_Accuracy: 0.9369\n",
            "Epoch: [ 0] [  410/60000], train_loss: 0.20871490, train_accuracy: 0.9453, test_Accuracy: 0.9366\n",
            "Epoch: [ 0] [  411/60000], train_loss: 0.18754080, train_accuracy: 0.9531, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  412/60000], train_loss: 0.18278144, train_accuracy: 0.9375, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  413/60000], train_loss: 0.24565272, train_accuracy: 0.8906, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  414/60000], train_loss: 0.16002414, train_accuracy: 0.9531, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  415/60000], train_loss: 0.17981003, train_accuracy: 0.9453, test_Accuracy: 0.9372\n",
            "Epoch: [ 0] [  416/60000], train_loss: 0.24887738, train_accuracy: 0.9219, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  417/60000], train_loss: 0.27283812, train_accuracy: 0.9219, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  418/60000], train_loss: 0.29067707, train_accuracy: 0.9062, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  419/60000], train_loss: 0.16920167, train_accuracy: 0.9375, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  420/60000], train_loss: 0.22979735, train_accuracy: 0.9453, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  421/60000], train_loss: 0.29031965, train_accuracy: 0.9297, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  422/60000], train_loss: 0.24036506, train_accuracy: 0.9297, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  423/60000], train_loss: 0.11383758, train_accuracy: 0.9688, test_Accuracy: 0.9374\n",
            "Epoch: [ 0] [  424/60000], train_loss: 0.22468272, train_accuracy: 0.9297, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  425/60000], train_loss: 0.21571870, train_accuracy: 0.9375, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  426/60000], train_loss: 0.20322043, train_accuracy: 0.9375, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  427/60000], train_loss: 0.14803067, train_accuracy: 0.9688, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  428/60000], train_loss: 0.18315494, train_accuracy: 0.9453, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  429/60000], train_loss: 0.13718021, train_accuracy: 0.9531, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  430/60000], train_loss: 0.14932074, train_accuracy: 0.9453, test_Accuracy: 0.9392\n",
            "Epoch: [ 0] [  431/60000], train_loss: 0.22445953, train_accuracy: 0.9297, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  432/60000], train_loss: 0.14904030, train_accuracy: 0.9609, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  433/60000], train_loss: 0.23339978, train_accuracy: 0.9219, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  434/60000], train_loss: 0.35057640, train_accuracy: 0.9062, test_Accuracy: 0.9379\n",
            "Epoch: [ 0] [  435/60000], train_loss: 0.18770750, train_accuracy: 0.9297, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  436/60000], train_loss: 0.11522185, train_accuracy: 0.9766, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  437/60000], train_loss: 0.50620472, train_accuracy: 0.8828, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  438/60000], train_loss: 0.18626842, train_accuracy: 0.9375, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  439/60000], train_loss: 0.24985988, train_accuracy: 0.9297, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  440/60000], train_loss: 0.20697115, train_accuracy: 0.9375, test_Accuracy: 0.9362\n",
            "Epoch: [ 0] [  441/60000], train_loss: 0.13071090, train_accuracy: 0.9609, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  442/60000], train_loss: 0.23190506, train_accuracy: 0.9531, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  443/60000], train_loss: 0.22523735, train_accuracy: 0.9375, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  444/60000], train_loss: 0.21330273, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  445/60000], train_loss: 0.20626426, train_accuracy: 0.9375, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  446/60000], train_loss: 0.15190060, train_accuracy: 0.9531, test_Accuracy: 0.9407\n",
            "Epoch: [ 0] [  447/60000], train_loss: 0.30623904, train_accuracy: 0.9062, test_Accuracy: 0.9396\n",
            "Epoch: [ 0] [  448/60000], train_loss: 0.33578902, train_accuracy: 0.8984, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  449/60000], train_loss: 0.17550650, train_accuracy: 0.9375, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  450/60000], train_loss: 0.37718922, train_accuracy: 0.8750, test_Accuracy: 0.9374\n",
            "Epoch: [ 0] [  451/60000], train_loss: 0.10065356, train_accuracy: 0.9766, test_Accuracy: 0.9362\n",
            "Epoch: [ 0] [  452/60000], train_loss: 0.18281847, train_accuracy: 0.9453, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  453/60000], train_loss: 0.21813898, train_accuracy: 0.9297, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  454/60000], train_loss: 0.19872293, train_accuracy: 0.9609, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  455/60000], train_loss: 0.20714098, train_accuracy: 0.9453, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  456/60000], train_loss: 0.25054389, train_accuracy: 0.9375, test_Accuracy: 0.9393\n",
            "Epoch: [ 0] [  457/60000], train_loss: 0.16018507, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  458/60000], train_loss: 0.14511351, train_accuracy: 0.9688, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  459/60000], train_loss: 0.10083064, train_accuracy: 0.9766, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  460/60000], train_loss: 0.25028205, train_accuracy: 0.9219, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  461/60000], train_loss: 0.20974362, train_accuracy: 0.9453, test_Accuracy: 0.9410\n",
            "Epoch: [ 0] [  462/60000], train_loss: 0.24331208, train_accuracy: 0.9609, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  463/60000], train_loss: 0.22570662, train_accuracy: 0.9219, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [  464/60000], train_loss: 0.15034038, train_accuracy: 0.9531, test_Accuracy: 0.9405\n",
            "Epoch: [ 0] [  465/60000], train_loss: 0.20743726, train_accuracy: 0.8984, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  466/60000], train_loss: 0.16441004, train_accuracy: 0.9375, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  467/60000], train_loss: 0.19059682, train_accuracy: 0.9219, test_Accuracy: 0.9404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9kqznmxFe5_"
      },
      "source": [
        "<h1>Sigmoid Function Test Accuracy : 94.04%</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEFcGk6KNI-J"
      },
      "source": [
        "### Lab 10-2: Weight 초기화 잘해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w42S5D1MOqhx"
      },
      "source": [
        "Weight 초기화를 잘 해주지 않으면, Locai Minima나 Saddle Point에 빠져서, Global Minima를 찾지 못하게 될 수 있다. 이를 방지하기 위해서, 여러 가지 방법으로 최대한 Global Minima에 가까운 지점으로 Weight를 초기화한다.\n",
        "<br><br>\n",
        "1. Xavier Initialization (Glorot Initialization)\n",
        "<br>: 평균은 0, 분산은 아래와 같은 Random 분포를 사용한다. $${2 \\over ChannelIn + ChannelOut}$$<br>\n",
        "여기서 Channel_In은 input으로 들어가는 채널의 갯수, Channel_Out은 output으로 나오는 채널의 갯수를 의미한다.\n",
        "<br><br><br>\n",
        "2. He Initialization\n",
        "<br>: Relu에 특화된 Weight 초기화. Xavier와 거의 비슷하나, 분산만 2배로 준다는 차이점이 있다. 즉, 평균은 0, 분산은 아래와 같은 Random 분포를 사용한다. $${4 \\over ChannelIn + ChannelOut}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGR_W7LNKl-"
      },
      "source": [
        "# 10-1의 소스 코드와 같다.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist # fasion_mnist, cifar10, cifar100과 같은 다양한 데이터셋이 있다.\n",
        "\n",
        "# mnist 데이터셋을 받아온 뒤 전처리.\n",
        "def load_mnist():\n",
        "  (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  train_data = np.expand_dims(train_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "  test_data = np.expand_dims(test_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "\n",
        "  train_data, test_data = normalize(train_data, test_data) # 범위는 0~255 -> 0~1\n",
        "\n",
        "  train_labels = to_categorical(train_labels, 10)\n",
        "  test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "def normalize(train_data, test_data):\n",
        "  train_data = train_data.astype(np.float32) / 255.0\n",
        "  test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "  return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrC1AkIAUArE"
      },
      "source": [
        "# 10-1의 소스 코드와 같다.\n",
        "\n",
        "# shape를 펼쳐주는 함수\n",
        "# 다차원 배열을 1차원으로 만드는 레이어를 추가한다고 보면 된다.\n",
        "def flatten():\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "# Dense Layer(Flip Connected Layer) 사용, 케라스 레이어에 Dense 추가\n",
        "def dense(channel, weight_init):\n",
        "  return tf.keras.layers.Dense(units=channel, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "# Relu Activation Function\n",
        "def relu():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq0sUV35UNAM"
      },
      "source": [
        "# Class type의 모델.\n",
        "class create_model(tf.keras.Model):\n",
        "  def __init__(self, label_dim):\n",
        "    super(create_model, self).__init__()\n",
        "\n",
        "    # 이 부분을 바꿈으로써 weight 초기화를 할 수 있다.\n",
        "    # Xavier는 glorot_uniform(), he는 he_uniform().\n",
        "    weight_init = tf.keras.initializers.he_uniform()\n",
        "    self.model = tf.keras.Sequential()\n",
        "\n",
        "    self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "    for i in range(2):\n",
        "      # [N, 784] -> [N, 256] -> [N, 256]\n",
        "      self.model.add(dense(256, weight_init)) # flip-connected function * 2\n",
        "      self.model.add(relu()) # relu function * 2\n",
        "\n",
        "    self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        " \n",
        "  def call(self, x, training=None, mask=None):\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDjETlUqWYCi"
      },
      "source": [
        "# 10-1의 소스 코드와 같다.\n",
        "\n",
        "# loss 값 구하는 함수.\n",
        "def loss_fn(model, images, labels):\n",
        "  logits = model(images, training=True) # images의 숫자를 추출.\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)) # softmax로 loss 구함.\n",
        "  return loss\n",
        "\n",
        "# 정확도 측정 함수.\n",
        "# argmax : 가장 큰 숫자값의 위치를 찾는 함수. 여기서는 마지막(-1번째) 차원을 제거한다.\n",
        "def accuracy_fn(model, images, labels):\n",
        "  logits = model(images, training=False)\n",
        "  prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "# Gradient Descent 함수.\n",
        "def grad(model, images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model, images, labels)\n",
        "  return tape.gradient(loss, model.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmFC4e1yWmVV",
        "outputId": "dc9453c3-fad0-4a4c-f5bd-9d235c5a03c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 10-1의 소스 코드와 같다.\n",
        "\n",
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128 # 이미지를 한 번에 학습시킬 갯수.\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x)\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=batch_size).\\\n",
        "  batch(batch_size, drop_remainder=True)\n",
        "  #repeat() #이를 계속 반복.\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=len(test_x)).\\\n",
        "  batch(len(test_x))\n",
        "  #repeat()\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "# 어떤 Optimizer를 써서 loss값을 최소화할 것인가 : 여기서는 AdamOptimizer를 사용.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8si76V0Wzsb",
        "outputId": "2fd85908-4147-4536-f455-8ba981cf34a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 10-1의 소스 코드와 같다.\n",
        "\n",
        "# 여기선 체크포인트 구현은 생략했다. (핵심도 아니고, 귀찮고, 코랩 쓰고 있다보니.......)\n",
        "start_epoch = 0\n",
        "start_iteration = 0\n",
        "\n",
        "for epoch in range(start_epoch, training_epochs):\n",
        "  for idx, (train_input, train_label) in enumerate(train_dataset): #epoch, iteration 2개에 대해 반복 수행.\n",
        "    # gradient 구한 후 적용, 네트워크를 학습시킨다.\n",
        "    grads = grad(network, train_input, train_label)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "    # loss, 정확도를 구한다.\n",
        "    train_loss = loss_fn(network, train_input, train_label)\n",
        "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "    # test dataset을 불러오고, 정확도를 구한다.\n",
        "    for test_input, test_label in test_dataset:\n",
        "      test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    # 그 결과값을 출력한다.\n",
        "    print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" %(epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 0] [    0/60000], train_loss: 2.07590556, train_accuracy: 0.3359, test_Accuracy: 0.1874\n",
            "Epoch: [ 0] [    1/60000], train_loss: 1.94007158, train_accuracy: 0.3594, test_Accuracy: 0.2799\n",
            "Epoch: [ 0] [    2/60000], train_loss: 1.96643960, train_accuracy: 0.3438, test_Accuracy: 0.3874\n",
            "Epoch: [ 0] [    3/60000], train_loss: 1.65629196, train_accuracy: 0.6562, test_Accuracy: 0.5510\n",
            "Epoch: [ 0] [    4/60000], train_loss: 1.62113547, train_accuracy: 0.6953, test_Accuracy: 0.6776\n",
            "Epoch: [ 0] [    5/60000], train_loss: 1.54488420, train_accuracy: 0.7031, test_Accuracy: 0.7170\n",
            "Epoch: [ 0] [    6/60000], train_loss: 1.28875422, train_accuracy: 0.8281, test_Accuracy: 0.7378\n",
            "Epoch: [ 0] [    7/60000], train_loss: 1.21884727, train_accuracy: 0.7344, test_Accuracy: 0.7592\n",
            "Epoch: [ 0] [    8/60000], train_loss: 1.03884292, train_accuracy: 0.8438, test_Accuracy: 0.7749\n",
            "Epoch: [ 0] [    9/60000], train_loss: 1.04049039, train_accuracy: 0.7578, test_Accuracy: 0.7883\n",
            "Epoch: [ 0] [   10/60000], train_loss: 0.99915361, train_accuracy: 0.7344, test_Accuracy: 0.8035\n",
            "Epoch: [ 0] [   11/60000], train_loss: 0.85147047, train_accuracy: 0.7969, test_Accuracy: 0.8129\n",
            "Epoch: [ 0] [   12/60000], train_loss: 0.79943562, train_accuracy: 0.8594, test_Accuracy: 0.8169\n",
            "Epoch: [ 0] [   13/60000], train_loss: 0.69648612, train_accuracy: 0.8516, test_Accuracy: 0.8196\n",
            "Epoch: [ 0] [   14/60000], train_loss: 0.55321378, train_accuracy: 0.9062, test_Accuracy: 0.8221\n",
            "Epoch: [ 0] [   15/60000], train_loss: 0.71522284, train_accuracy: 0.8203, test_Accuracy: 0.8271\n",
            "Epoch: [ 0] [   16/60000], train_loss: 0.61402333, train_accuracy: 0.7969, test_Accuracy: 0.8350\n",
            "Epoch: [ 0] [   17/60000], train_loss: 0.70191109, train_accuracy: 0.8281, test_Accuracy: 0.8447\n",
            "Epoch: [ 0] [   18/60000], train_loss: 0.52699286, train_accuracy: 0.9062, test_Accuracy: 0.8523\n",
            "Epoch: [ 0] [   19/60000], train_loss: 0.55291802, train_accuracy: 0.8516, test_Accuracy: 0.8544\n",
            "Epoch: [ 0] [   20/60000], train_loss: 0.55979657, train_accuracy: 0.8516, test_Accuracy: 0.8514\n",
            "Epoch: [ 0] [   21/60000], train_loss: 0.43365502, train_accuracy: 0.8672, test_Accuracy: 0.8568\n",
            "Epoch: [ 0] [   22/60000], train_loss: 0.38797686, train_accuracy: 0.8906, test_Accuracy: 0.8614\n",
            "Epoch: [ 0] [   23/60000], train_loss: 0.38771492, train_accuracy: 0.8750, test_Accuracy: 0.8705\n",
            "Epoch: [ 0] [   24/60000], train_loss: 0.45297250, train_accuracy: 0.8359, test_Accuracy: 0.8724\n",
            "Epoch: [ 0] [   25/60000], train_loss: 0.37422204, train_accuracy: 0.8828, test_Accuracy: 0.8665\n",
            "Epoch: [ 0] [   26/60000], train_loss: 0.52634072, train_accuracy: 0.8359, test_Accuracy: 0.8659\n",
            "Epoch: [ 0] [   27/60000], train_loss: 0.39189017, train_accuracy: 0.8828, test_Accuracy: 0.8747\n",
            "Epoch: [ 0] [   28/60000], train_loss: 0.45905793, train_accuracy: 0.8516, test_Accuracy: 0.8825\n",
            "Epoch: [ 0] [   29/60000], train_loss: 0.38944227, train_accuracy: 0.8906, test_Accuracy: 0.8835\n",
            "Epoch: [ 0] [   30/60000], train_loss: 0.42780167, train_accuracy: 0.8672, test_Accuracy: 0.8840\n",
            "Epoch: [ 0] [   31/60000], train_loss: 0.48870081, train_accuracy: 0.8594, test_Accuracy: 0.8851\n",
            "Epoch: [ 0] [   32/60000], train_loss: 0.40788862, train_accuracy: 0.9297, test_Accuracy: 0.8856\n",
            "Epoch: [ 0] [   33/60000], train_loss: 0.45403963, train_accuracy: 0.8672, test_Accuracy: 0.8894\n",
            "Epoch: [ 0] [   34/60000], train_loss: 0.37535584, train_accuracy: 0.9062, test_Accuracy: 0.8891\n",
            "Epoch: [ 0] [   35/60000], train_loss: 0.38755015, train_accuracy: 0.8750, test_Accuracy: 0.8887\n",
            "Epoch: [ 0] [   36/60000], train_loss: 0.30702549, train_accuracy: 0.8984, test_Accuracy: 0.8899\n",
            "Epoch: [ 0] [   37/60000], train_loss: 0.37814420, train_accuracy: 0.9219, test_Accuracy: 0.8917\n",
            "Epoch: [ 0] [   38/60000], train_loss: 0.32758909, train_accuracy: 0.9141, test_Accuracy: 0.8923\n",
            "Epoch: [ 0] [   39/60000], train_loss: 0.26360908, train_accuracy: 0.8984, test_Accuracy: 0.8938\n",
            "Epoch: [ 0] [   40/60000], train_loss: 0.22111291, train_accuracy: 0.9141, test_Accuracy: 0.8940\n",
            "Epoch: [ 0] [   41/60000], train_loss: 0.37312406, train_accuracy: 0.8750, test_Accuracy: 0.8951\n",
            "Epoch: [ 0] [   42/60000], train_loss: 0.32158813, train_accuracy: 0.9062, test_Accuracy: 0.8993\n",
            "Epoch: [ 0] [   43/60000], train_loss: 0.31845206, train_accuracy: 0.9141, test_Accuracy: 0.9003\n",
            "Epoch: [ 0] [   44/60000], train_loss: 0.31919986, train_accuracy: 0.8672, test_Accuracy: 0.8989\n",
            "Epoch: [ 0] [   45/60000], train_loss: 0.40637195, train_accuracy: 0.8516, test_Accuracy: 0.8951\n",
            "Epoch: [ 0] [   46/60000], train_loss: 0.38684577, train_accuracy: 0.9062, test_Accuracy: 0.8971\n",
            "Epoch: [ 0] [   47/60000], train_loss: 0.18887711, train_accuracy: 0.9609, test_Accuracy: 0.9011\n",
            "Epoch: [ 0] [   48/60000], train_loss: 0.31299773, train_accuracy: 0.9062, test_Accuracy: 0.9084\n",
            "Epoch: [ 0] [   49/60000], train_loss: 0.34539929, train_accuracy: 0.9141, test_Accuracy: 0.9070\n",
            "Epoch: [ 0] [   50/60000], train_loss: 0.34363925, train_accuracy: 0.8750, test_Accuracy: 0.9013\n",
            "Epoch: [ 0] [   51/60000], train_loss: 0.28370786, train_accuracy: 0.9297, test_Accuracy: 0.9008\n",
            "Epoch: [ 0] [   52/60000], train_loss: 0.26140282, train_accuracy: 0.9453, test_Accuracy: 0.9003\n",
            "Epoch: [ 0] [   53/60000], train_loss: 0.24588206, train_accuracy: 0.9141, test_Accuracy: 0.8995\n",
            "Epoch: [ 0] [   54/60000], train_loss: 0.31712162, train_accuracy: 0.9062, test_Accuracy: 0.9009\n",
            "Epoch: [ 0] [   55/60000], train_loss: 0.30255657, train_accuracy: 0.9062, test_Accuracy: 0.9059\n",
            "Epoch: [ 0] [   56/60000], train_loss: 0.29901794, train_accuracy: 0.9141, test_Accuracy: 0.9103\n",
            "Epoch: [ 0] [   57/60000], train_loss: 0.31810200, train_accuracy: 0.8984, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [   58/60000], train_loss: 0.16257723, train_accuracy: 0.9609, test_Accuracy: 0.9132\n",
            "Epoch: [ 0] [   59/60000], train_loss: 0.46154130, train_accuracy: 0.8359, test_Accuracy: 0.9120\n",
            "Epoch: [ 0] [   60/60000], train_loss: 0.40037107, train_accuracy: 0.9062, test_Accuracy: 0.9167\n",
            "Epoch: [ 0] [   61/60000], train_loss: 0.29108486, train_accuracy: 0.8984, test_Accuracy: 0.9176\n",
            "Epoch: [ 0] [   62/60000], train_loss: 0.20384181, train_accuracy: 0.9531, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [   63/60000], train_loss: 0.19736879, train_accuracy: 0.9375, test_Accuracy: 0.9176\n",
            "Epoch: [ 0] [   64/60000], train_loss: 0.29503340, train_accuracy: 0.9219, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [   65/60000], train_loss: 0.33126503, train_accuracy: 0.8906, test_Accuracy: 0.9142\n",
            "Epoch: [ 0] [   66/60000], train_loss: 0.30563441, train_accuracy: 0.9062, test_Accuracy: 0.9134\n",
            "Epoch: [ 0] [   67/60000], train_loss: 0.32223570, train_accuracy: 0.9141, test_Accuracy: 0.9115\n",
            "Epoch: [ 0] [   68/60000], train_loss: 0.30883703, train_accuracy: 0.8906, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [   69/60000], train_loss: 0.34562641, train_accuracy: 0.9141, test_Accuracy: 0.9153\n",
            "Epoch: [ 0] [   70/60000], train_loss: 0.35401899, train_accuracy: 0.9062, test_Accuracy: 0.9183\n",
            "Epoch: [ 0] [   71/60000], train_loss: 0.30961707, train_accuracy: 0.8984, test_Accuracy: 0.9177\n",
            "Epoch: [ 0] [   72/60000], train_loss: 0.28024814, train_accuracy: 0.9531, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [   73/60000], train_loss: 0.28153390, train_accuracy: 0.9062, test_Accuracy: 0.9139\n",
            "Epoch: [ 0] [   74/60000], train_loss: 0.25721002, train_accuracy: 0.9062, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [   75/60000], train_loss: 0.34569180, train_accuracy: 0.9375, test_Accuracy: 0.9114\n",
            "Epoch: [ 0] [   76/60000], train_loss: 0.28256944, train_accuracy: 0.9219, test_Accuracy: 0.9098\n",
            "Epoch: [ 0] [   77/60000], train_loss: 0.29192722, train_accuracy: 0.8984, test_Accuracy: 0.9107\n",
            "Epoch: [ 0] [   78/60000], train_loss: 0.34574622, train_accuracy: 0.8984, test_Accuracy: 0.9126\n",
            "Epoch: [ 0] [   79/60000], train_loss: 0.25205058, train_accuracy: 0.9297, test_Accuracy: 0.9149\n",
            "Epoch: [ 0] [   80/60000], train_loss: 0.20388460, train_accuracy: 0.9219, test_Accuracy: 0.9146\n",
            "Epoch: [ 0] [   81/60000], train_loss: 0.24769607, train_accuracy: 0.9297, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [   82/60000], train_loss: 0.28347480, train_accuracy: 0.9219, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [   83/60000], train_loss: 0.20660681, train_accuracy: 0.9375, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [   84/60000], train_loss: 0.18551844, train_accuracy: 0.9375, test_Accuracy: 0.9213\n",
            "Epoch: [ 0] [   85/60000], train_loss: 0.30014345, train_accuracy: 0.9219, test_Accuracy: 0.9201\n",
            "Epoch: [ 0] [   86/60000], train_loss: 0.22188577, train_accuracy: 0.9375, test_Accuracy: 0.9219\n",
            "Epoch: [ 0] [   87/60000], train_loss: 0.22849423, train_accuracy: 0.9141, test_Accuracy: 0.9247\n",
            "Epoch: [ 0] [   88/60000], train_loss: 0.27881968, train_accuracy: 0.9375, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [   89/60000], train_loss: 0.23975822, train_accuracy: 0.9297, test_Accuracy: 0.9253\n",
            "Epoch: [ 0] [   90/60000], train_loss: 0.26181209, train_accuracy: 0.9375, test_Accuracy: 0.9244\n",
            "Epoch: [ 0] [   91/60000], train_loss: 0.41481987, train_accuracy: 0.8984, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [   92/60000], train_loss: 0.29796535, train_accuracy: 0.9141, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [   93/60000], train_loss: 0.22509664, train_accuracy: 0.9375, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [   94/60000], train_loss: 0.21911225, train_accuracy: 0.9375, test_Accuracy: 0.9300\n",
            "Epoch: [ 0] [   95/60000], train_loss: 0.25067112, train_accuracy: 0.9297, test_Accuracy: 0.9316\n",
            "Epoch: [ 0] [   96/60000], train_loss: 0.21799488, train_accuracy: 0.9531, test_Accuracy: 0.9323\n",
            "Epoch: [ 0] [   97/60000], train_loss: 0.34023809, train_accuracy: 0.8672, test_Accuracy: 0.9316\n",
            "Epoch: [ 0] [   98/60000], train_loss: 0.32362026, train_accuracy: 0.9062, test_Accuracy: 0.9324\n",
            "Epoch: [ 0] [   99/60000], train_loss: 0.29415578, train_accuracy: 0.9219, test_Accuracy: 0.9300\n",
            "Epoch: [ 0] [  100/60000], train_loss: 0.23494342, train_accuracy: 0.9375, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  101/60000], train_loss: 0.22681019, train_accuracy: 0.9141, test_Accuracy: 0.9277\n",
            "Epoch: [ 0] [  102/60000], train_loss: 0.14536555, train_accuracy: 0.9531, test_Accuracy: 0.9289\n",
            "Epoch: [ 0] [  103/60000], train_loss: 0.16728133, train_accuracy: 0.9844, test_Accuracy: 0.9304\n",
            "Epoch: [ 0] [  104/60000], train_loss: 0.25383684, train_accuracy: 0.9219, test_Accuracy: 0.9310\n",
            "Epoch: [ 0] [  105/60000], train_loss: 0.18510763, train_accuracy: 0.9219, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  106/60000], train_loss: 0.31973153, train_accuracy: 0.9219, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  107/60000], train_loss: 0.12324641, train_accuracy: 0.9766, test_Accuracy: 0.9367\n",
            "Epoch: [ 0] [  108/60000], train_loss: 0.17192216, train_accuracy: 0.9609, test_Accuracy: 0.9372\n",
            "Epoch: [ 0] [  109/60000], train_loss: 0.18737546, train_accuracy: 0.9453, test_Accuracy: 0.9350\n",
            "Epoch: [ 0] [  110/60000], train_loss: 0.17418326, train_accuracy: 0.9297, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  111/60000], train_loss: 0.23557742, train_accuracy: 0.9297, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  112/60000], train_loss: 0.25970113, train_accuracy: 0.8984, test_Accuracy: 0.9318\n",
            "Epoch: [ 0] [  113/60000], train_loss: 0.31349728, train_accuracy: 0.9219, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  114/60000], train_loss: 0.18731852, train_accuracy: 0.9531, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  115/60000], train_loss: 0.14720267, train_accuracy: 0.9609, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  116/60000], train_loss: 0.16431135, train_accuracy: 0.9375, test_Accuracy: 0.9250\n",
            "Epoch: [ 0] [  117/60000], train_loss: 0.22259055, train_accuracy: 0.9375, test_Accuracy: 0.9229\n",
            "Epoch: [ 0] [  118/60000], train_loss: 0.30763745, train_accuracy: 0.9141, test_Accuracy: 0.9232\n",
            "Epoch: [ 0] [  119/60000], train_loss: 0.20725852, train_accuracy: 0.9453, test_Accuracy: 0.9314\n",
            "Epoch: [ 0] [  120/60000], train_loss: 0.21077260, train_accuracy: 0.9531, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  121/60000], train_loss: 0.20208526, train_accuracy: 0.9375, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  122/60000], train_loss: 0.23230511, train_accuracy: 0.9531, test_Accuracy: 0.9318\n",
            "Epoch: [ 0] [  123/60000], train_loss: 0.35025525, train_accuracy: 0.8828, test_Accuracy: 0.9299\n",
            "Epoch: [ 0] [  124/60000], train_loss: 0.18234584, train_accuracy: 0.9453, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  125/60000], train_loss: 0.10188189, train_accuracy: 0.9688, test_Accuracy: 0.9291\n",
            "Epoch: [ 0] [  126/60000], train_loss: 0.23183538, train_accuracy: 0.9375, test_Accuracy: 0.9308\n",
            "Epoch: [ 0] [  127/60000], train_loss: 0.25690848, train_accuracy: 0.9453, test_Accuracy: 0.9311\n",
            "Epoch: [ 0] [  128/60000], train_loss: 0.20758888, train_accuracy: 0.9375, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  129/60000], train_loss: 0.22064286, train_accuracy: 0.9297, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  130/60000], train_loss: 0.23218958, train_accuracy: 0.9219, test_Accuracy: 0.9314\n",
            "Epoch: [ 0] [  131/60000], train_loss: 0.17753041, train_accuracy: 0.9297, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  132/60000], train_loss: 0.16344029, train_accuracy: 0.9609, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  133/60000], train_loss: 0.13463938, train_accuracy: 0.9609, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  134/60000], train_loss: 0.21924561, train_accuracy: 0.9141, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  135/60000], train_loss: 0.24670222, train_accuracy: 0.9531, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  136/60000], train_loss: 0.15753493, train_accuracy: 0.9609, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  137/60000], train_loss: 0.27237073, train_accuracy: 0.9219, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  138/60000], train_loss: 0.19366834, train_accuracy: 0.9531, test_Accuracy: 0.9345\n",
            "Epoch: [ 0] [  139/60000], train_loss: 0.12936747, train_accuracy: 0.9766, test_Accuracy: 0.9361\n",
            "Epoch: [ 0] [  140/60000], train_loss: 0.09387404, train_accuracy: 0.9766, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  141/60000], train_loss: 0.18894346, train_accuracy: 0.9453, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  142/60000], train_loss: 0.25838923, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  143/60000], train_loss: 0.31600952, train_accuracy: 0.9297, test_Accuracy: 0.9410\n",
            "Epoch: [ 0] [  144/60000], train_loss: 0.12232833, train_accuracy: 0.9766, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  145/60000], train_loss: 0.20565060, train_accuracy: 0.9141, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  146/60000], train_loss: 0.18499538, train_accuracy: 0.9453, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  147/60000], train_loss: 0.18888453, train_accuracy: 0.9297, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  148/60000], train_loss: 0.24165291, train_accuracy: 0.9297, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  149/60000], train_loss: 0.28424045, train_accuracy: 0.9141, test_Accuracy: 0.9376\n",
            "Epoch: [ 0] [  150/60000], train_loss: 0.17144084, train_accuracy: 0.9609, test_Accuracy: 0.9361\n",
            "Epoch: [ 0] [  151/60000], train_loss: 0.19637059, train_accuracy: 0.9453, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  152/60000], train_loss: 0.19021776, train_accuracy: 0.9609, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  153/60000], train_loss: 0.18656376, train_accuracy: 0.9531, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  154/60000], train_loss: 0.20721641, train_accuracy: 0.9141, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  155/60000], train_loss: 0.16232058, train_accuracy: 0.9609, test_Accuracy: 0.9379\n",
            "Epoch: [ 0] [  156/60000], train_loss: 0.17827758, train_accuracy: 0.9453, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  157/60000], train_loss: 0.18623747, train_accuracy: 0.9766, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  158/60000], train_loss: 0.11621555, train_accuracy: 0.9766, test_Accuracy: 0.9396\n",
            "Epoch: [ 0] [  159/60000], train_loss: 0.22127852, train_accuracy: 0.9297, test_Accuracy: 0.9409\n",
            "Epoch: [ 0] [  160/60000], train_loss: 0.18164584, train_accuracy: 0.9453, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  161/60000], train_loss: 0.16986403, train_accuracy: 0.9531, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  162/60000], train_loss: 0.21674706, train_accuracy: 0.9297, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  163/60000], train_loss: 0.20169856, train_accuracy: 0.9453, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  164/60000], train_loss: 0.15779319, train_accuracy: 0.9453, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [  165/60000], train_loss: 0.14730167, train_accuracy: 0.9688, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  166/60000], train_loss: 0.22196154, train_accuracy: 0.9375, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  167/60000], train_loss: 0.27583060, train_accuracy: 0.9531, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  168/60000], train_loss: 0.18327910, train_accuracy: 0.9375, test_Accuracy: 0.9382\n",
            "Epoch: [ 0] [  169/60000], train_loss: 0.23339070, train_accuracy: 0.9297, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  170/60000], train_loss: 0.33264968, train_accuracy: 0.9141, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  171/60000], train_loss: 0.17594099, train_accuracy: 0.9531, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  172/60000], train_loss: 0.15117702, train_accuracy: 0.9688, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  173/60000], train_loss: 0.15835162, train_accuracy: 0.9453, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  174/60000], train_loss: 0.18034360, train_accuracy: 0.9609, test_Accuracy: 0.9382\n",
            "Epoch: [ 0] [  175/60000], train_loss: 0.22930814, train_accuracy: 0.9375, test_Accuracy: 0.9379\n",
            "Epoch: [ 0] [  176/60000], train_loss: 0.12720767, train_accuracy: 0.9609, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  177/60000], train_loss: 0.18803701, train_accuracy: 0.9375, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  178/60000], train_loss: 0.11609820, train_accuracy: 0.9766, test_Accuracy: 0.9392\n",
            "Epoch: [ 0] [  179/60000], train_loss: 0.22573006, train_accuracy: 0.9453, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  180/60000], train_loss: 0.17194211, train_accuracy: 0.9375, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  181/60000], train_loss: 0.30048841, train_accuracy: 0.9453, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  182/60000], train_loss: 0.21835649, train_accuracy: 0.9297, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  183/60000], train_loss: 0.16208673, train_accuracy: 0.9609, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  184/60000], train_loss: 0.14820679, train_accuracy: 0.9609, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  185/60000], train_loss: 0.23733181, train_accuracy: 0.9219, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  186/60000], train_loss: 0.12264125, train_accuracy: 0.9844, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  187/60000], train_loss: 0.15527555, train_accuracy: 0.9531, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  188/60000], train_loss: 0.23193073, train_accuracy: 0.9219, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  189/60000], train_loss: 0.13854812, train_accuracy: 0.9609, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  190/60000], train_loss: 0.09828826, train_accuracy: 0.9844, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  191/60000], train_loss: 0.25970164, train_accuracy: 0.9375, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  192/60000], train_loss: 0.22097933, train_accuracy: 0.9453, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  193/60000], train_loss: 0.10348564, train_accuracy: 0.9844, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  194/60000], train_loss: 0.14427358, train_accuracy: 0.9531, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  195/60000], train_loss: 0.17764717, train_accuracy: 0.9609, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  196/60000], train_loss: 0.25646317, train_accuracy: 0.9375, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  197/60000], train_loss: 0.22392094, train_accuracy: 0.9531, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  198/60000], train_loss: 0.11177564, train_accuracy: 0.9609, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  199/60000], train_loss: 0.30474043, train_accuracy: 0.9375, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  200/60000], train_loss: 0.20275971, train_accuracy: 0.9297, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  201/60000], train_loss: 0.11481304, train_accuracy: 0.9688, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  202/60000], train_loss: 0.15109745, train_accuracy: 0.9609, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  203/60000], train_loss: 0.24041507, train_accuracy: 0.9375, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  204/60000], train_loss: 0.31233802, train_accuracy: 0.9062, test_Accuracy: 0.9425\n",
            "Epoch: [ 0] [  205/60000], train_loss: 0.18207502, train_accuracy: 0.9297, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  206/60000], train_loss: 0.22298680, train_accuracy: 0.9375, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  207/60000], train_loss: 0.13277875, train_accuracy: 0.9688, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  208/60000], train_loss: 0.16526690, train_accuracy: 0.9688, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  209/60000], train_loss: 0.17410392, train_accuracy: 0.9531, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  210/60000], train_loss: 0.30749470, train_accuracy: 0.9219, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  211/60000], train_loss: 0.12408198, train_accuracy: 0.9766, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  212/60000], train_loss: 0.16975640, train_accuracy: 0.9453, test_Accuracy: 0.9498\n",
            "Epoch: [ 0] [  213/60000], train_loss: 0.10677867, train_accuracy: 0.9766, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  214/60000], train_loss: 0.15496659, train_accuracy: 0.9609, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  215/60000], train_loss: 0.21667266, train_accuracy: 0.9141, test_Accuracy: 0.9502\n",
            "Epoch: [ 0] [  216/60000], train_loss: 0.19820794, train_accuracy: 0.9453, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  217/60000], train_loss: 0.14437355, train_accuracy: 0.9688, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  218/60000], train_loss: 0.17315492, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  219/60000], train_loss: 0.15703458, train_accuracy: 0.9375, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  220/60000], train_loss: 0.17271358, train_accuracy: 0.9375, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  221/60000], train_loss: 0.17094828, train_accuracy: 0.9453, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  222/60000], train_loss: 0.10765015, train_accuracy: 0.9688, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  223/60000], train_loss: 0.11723532, train_accuracy: 0.9688, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  224/60000], train_loss: 0.22978979, train_accuracy: 0.9062, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  225/60000], train_loss: 0.21025911, train_accuracy: 0.9375, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  226/60000], train_loss: 0.13463089, train_accuracy: 0.9453, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  227/60000], train_loss: 0.15478764, train_accuracy: 0.9766, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  228/60000], train_loss: 0.11291431, train_accuracy: 0.9688, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  229/60000], train_loss: 0.11388457, train_accuracy: 0.9609, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  230/60000], train_loss: 0.13043085, train_accuracy: 0.9609, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  231/60000], train_loss: 0.10601862, train_accuracy: 0.9688, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  232/60000], train_loss: 0.13547494, train_accuracy: 0.9766, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  233/60000], train_loss: 0.17034480, train_accuracy: 0.9531, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  234/60000], train_loss: 0.11615452, train_accuracy: 0.9688, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  235/60000], train_loss: 0.14134327, train_accuracy: 0.9766, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  236/60000], train_loss: 0.18785454, train_accuracy: 0.9375, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  237/60000], train_loss: 0.20845321, train_accuracy: 0.9609, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  238/60000], train_loss: 0.17243521, train_accuracy: 0.9453, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  239/60000], train_loss: 0.22951500, train_accuracy: 0.9375, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  240/60000], train_loss: 0.22756577, train_accuracy: 0.9766, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  241/60000], train_loss: 0.23215447, train_accuracy: 0.9297, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  242/60000], train_loss: 0.20036286, train_accuracy: 0.9375, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  243/60000], train_loss: 0.11240767, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  244/60000], train_loss: 0.13671376, train_accuracy: 0.9453, test_Accuracy: 0.9517\n",
            "Epoch: [ 0] [  245/60000], train_loss: 0.15775411, train_accuracy: 0.9453, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  246/60000], train_loss: 0.11975077, train_accuracy: 0.9766, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  247/60000], train_loss: 0.21675661, train_accuracy: 0.9219, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  248/60000], train_loss: 0.17905730, train_accuracy: 0.9375, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  249/60000], train_loss: 0.19507462, train_accuracy: 0.9297, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  250/60000], train_loss: 0.15981990, train_accuracy: 0.9531, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  251/60000], train_loss: 0.06821464, train_accuracy: 0.9844, test_Accuracy: 0.9546\n",
            "Epoch: [ 0] [  252/60000], train_loss: 0.19416487, train_accuracy: 0.9375, test_Accuracy: 0.9558\n",
            "Epoch: [ 0] [  253/60000], train_loss: 0.23448788, train_accuracy: 0.9453, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  254/60000], train_loss: 0.19507134, train_accuracy: 0.9453, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  255/60000], train_loss: 0.08261843, train_accuracy: 0.9922, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  256/60000], train_loss: 0.11382753, train_accuracy: 0.9609, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  257/60000], train_loss: 0.12166950, train_accuracy: 0.9609, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  258/60000], train_loss: 0.14107096, train_accuracy: 0.9375, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  259/60000], train_loss: 0.17144391, train_accuracy: 0.9375, test_Accuracy: 0.9481\n",
            "Epoch: [ 0] [  260/60000], train_loss: 0.22719903, train_accuracy: 0.9297, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  261/60000], train_loss: 0.16898236, train_accuracy: 0.9531, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  262/60000], train_loss: 0.30831468, train_accuracy: 0.9297, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  263/60000], train_loss: 0.08369411, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  264/60000], train_loss: 0.11839649, train_accuracy: 0.9609, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  265/60000], train_loss: 0.18173262, train_accuracy: 0.9453, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  266/60000], train_loss: 0.14092602, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  267/60000], train_loss: 0.11125910, train_accuracy: 0.9766, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  268/60000], train_loss: 0.20040807, train_accuracy: 0.9453, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  269/60000], train_loss: 0.09749099, train_accuracy: 0.9922, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  270/60000], train_loss: 0.11570334, train_accuracy: 0.9766, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  271/60000], train_loss: 0.17770410, train_accuracy: 0.9375, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  272/60000], train_loss: 0.08846289, train_accuracy: 0.9766, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  273/60000], train_loss: 0.25394222, train_accuracy: 0.9062, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  274/60000], train_loss: 0.24854895, train_accuracy: 0.9141, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  275/60000], train_loss: 0.09919994, train_accuracy: 0.9609, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  276/60000], train_loss: 0.13451347, train_accuracy: 0.9688, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  277/60000], train_loss: 0.24030429, train_accuracy: 0.9453, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  278/60000], train_loss: 0.15632468, train_accuracy: 0.9609, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  279/60000], train_loss: 0.07541941, train_accuracy: 0.9844, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  280/60000], train_loss: 0.12367157, train_accuracy: 0.9688, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  281/60000], train_loss: 0.13198575, train_accuracy: 0.9609, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  282/60000], train_loss: 0.22202057, train_accuracy: 0.9531, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  283/60000], train_loss: 0.15497336, train_accuracy: 0.9688, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  284/60000], train_loss: 0.26489776, train_accuracy: 0.9609, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  285/60000], train_loss: 0.09368420, train_accuracy: 0.9766, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  286/60000], train_loss: 0.12523368, train_accuracy: 0.9531, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  287/60000], train_loss: 0.08546843, train_accuracy: 0.9844, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  288/60000], train_loss: 0.06737326, train_accuracy: 0.9766, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  289/60000], train_loss: 0.09225868, train_accuracy: 0.9844, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  290/60000], train_loss: 0.14049469, train_accuracy: 0.9453, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  291/60000], train_loss: 0.11899097, train_accuracy: 0.9766, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  292/60000], train_loss: 0.11869992, train_accuracy: 0.9766, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  293/60000], train_loss: 0.21745019, train_accuracy: 0.9219, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  294/60000], train_loss: 0.21000531, train_accuracy: 0.9453, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  295/60000], train_loss: 0.10817211, train_accuracy: 0.9766, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  296/60000], train_loss: 0.21842948, train_accuracy: 0.9375, test_Accuracy: 0.9526\n",
            "Epoch: [ 0] [  297/60000], train_loss: 0.16274674, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  298/60000], train_loss: 0.10589761, train_accuracy: 0.9609, test_Accuracy: 0.9552\n",
            "Epoch: [ 0] [  299/60000], train_loss: 0.21414690, train_accuracy: 0.9297, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  300/60000], train_loss: 0.11412721, train_accuracy: 0.9766, test_Accuracy: 0.9565\n",
            "Epoch: [ 0] [  301/60000], train_loss: 0.06430762, train_accuracy: 0.9844, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  302/60000], train_loss: 0.11951053, train_accuracy: 0.9453, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  303/60000], train_loss: 0.13979754, train_accuracy: 0.9609, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  304/60000], train_loss: 0.17046821, train_accuracy: 0.9531, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  305/60000], train_loss: 0.21424712, train_accuracy: 0.9453, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  306/60000], train_loss: 0.12525377, train_accuracy: 0.9766, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  307/60000], train_loss: 0.13201310, train_accuracy: 0.9688, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  308/60000], train_loss: 0.15343997, train_accuracy: 0.9688, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  309/60000], train_loss: 0.09644136, train_accuracy: 0.9766, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  310/60000], train_loss: 0.17131519, train_accuracy: 0.9609, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  311/60000], train_loss: 0.10376079, train_accuracy: 0.9531, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  312/60000], train_loss: 0.06759735, train_accuracy: 0.9844, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  313/60000], train_loss: 0.10664517, train_accuracy: 0.9609, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  314/60000], train_loss: 0.13191858, train_accuracy: 0.9609, test_Accuracy: 0.9602\n",
            "Epoch: [ 0] [  315/60000], train_loss: 0.13520382, train_accuracy: 0.9766, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  316/60000], train_loss: 0.10989386, train_accuracy: 0.9453, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  317/60000], train_loss: 0.20197582, train_accuracy: 0.9297, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  318/60000], train_loss: 0.16288888, train_accuracy: 0.9297, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  319/60000], train_loss: 0.11967182, train_accuracy: 0.9531, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  320/60000], train_loss: 0.05125656, train_accuracy: 1.0000, test_Accuracy: 0.9585\n",
            "Epoch: [ 0] [  321/60000], train_loss: 0.12549199, train_accuracy: 0.9531, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  322/60000], train_loss: 0.12346988, train_accuracy: 0.9766, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  323/60000], train_loss: 0.15180010, train_accuracy: 0.9531, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  324/60000], train_loss: 0.07614550, train_accuracy: 0.9766, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  325/60000], train_loss: 0.07692783, train_accuracy: 0.9531, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  326/60000], train_loss: 0.16783872, train_accuracy: 0.9219, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  327/60000], train_loss: 0.07468429, train_accuracy: 0.9844, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  328/60000], train_loss: 0.09812318, train_accuracy: 0.9688, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  329/60000], train_loss: 0.25333527, train_accuracy: 0.9453, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  330/60000], train_loss: 0.10108411, train_accuracy: 0.9766, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  331/60000], train_loss: 0.27495188, train_accuracy: 0.9453, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  332/60000], train_loss: 0.19580406, train_accuracy: 0.9453, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  333/60000], train_loss: 0.10781513, train_accuracy: 0.9688, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  334/60000], train_loss: 0.05421151, train_accuracy: 0.9922, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  335/60000], train_loss: 0.08837298, train_accuracy: 0.9531, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  336/60000], train_loss: 0.12745836, train_accuracy: 0.9688, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  337/60000], train_loss: 0.19598329, train_accuracy: 0.9375, test_Accuracy: 0.9573\n",
            "Epoch: [ 0] [  338/60000], train_loss: 0.07504243, train_accuracy: 0.9766, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  339/60000], train_loss: 0.15152937, train_accuracy: 0.9375, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  340/60000], train_loss: 0.15812027, train_accuracy: 0.9297, test_Accuracy: 0.9559\n",
            "Epoch: [ 0] [  341/60000], train_loss: 0.08968747, train_accuracy: 0.9844, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  342/60000], train_loss: 0.21335706, train_accuracy: 0.9297, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  343/60000], train_loss: 0.07926616, train_accuracy: 0.9766, test_Accuracy: 0.9627\n",
            "Epoch: [ 0] [  344/60000], train_loss: 0.07167141, train_accuracy: 0.9766, test_Accuracy: 0.9636\n",
            "Epoch: [ 0] [  345/60000], train_loss: 0.21603066, train_accuracy: 0.9531, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  346/60000], train_loss: 0.19806314, train_accuracy: 0.9141, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  347/60000], train_loss: 0.08332153, train_accuracy: 0.9922, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  348/60000], train_loss: 0.23617791, train_accuracy: 0.9375, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  349/60000], train_loss: 0.07480324, train_accuracy: 0.9844, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  350/60000], train_loss: 0.12460265, train_accuracy: 0.9766, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  351/60000], train_loss: 0.13369501, train_accuracy: 0.9688, test_Accuracy: 0.9617\n",
            "Epoch: [ 0] [  352/60000], train_loss: 0.12238534, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  353/60000], train_loss: 0.10246269, train_accuracy: 0.9609, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  354/60000], train_loss: 0.09568179, train_accuracy: 0.9688, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  355/60000], train_loss: 0.07858288, train_accuracy: 0.9844, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  356/60000], train_loss: 0.14586005, train_accuracy: 0.9531, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  357/60000], train_loss: 0.09615745, train_accuracy: 0.9766, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  358/60000], train_loss: 0.09157193, train_accuracy: 0.9766, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  359/60000], train_loss: 0.14319356, train_accuracy: 0.9531, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  360/60000], train_loss: 0.08825384, train_accuracy: 0.9609, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  361/60000], train_loss: 0.14154159, train_accuracy: 0.9609, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  362/60000], train_loss: 0.13757430, train_accuracy: 0.9609, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  363/60000], train_loss: 0.07097317, train_accuracy: 0.9844, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  364/60000], train_loss: 0.09368417, train_accuracy: 0.9766, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  365/60000], train_loss: 0.10957877, train_accuracy: 0.9688, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  366/60000], train_loss: 0.11814249, train_accuracy: 0.9609, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  367/60000], train_loss: 0.18488167, train_accuracy: 0.9297, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  368/60000], train_loss: 0.05549767, train_accuracy: 0.9922, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  369/60000], train_loss: 0.11072470, train_accuracy: 0.9766, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  370/60000], train_loss: 0.11109297, train_accuracy: 0.9453, test_Accuracy: 0.9653\n",
            "Epoch: [ 0] [  371/60000], train_loss: 0.07754843, train_accuracy: 0.9688, test_Accuracy: 0.9652\n",
            "Epoch: [ 0] [  372/60000], train_loss: 0.07048596, train_accuracy: 0.9844, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  373/60000], train_loss: 0.16930607, train_accuracy: 0.9453, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  374/60000], train_loss: 0.07412034, train_accuracy: 0.9766, test_Accuracy: 0.9637\n",
            "Epoch: [ 0] [  375/60000], train_loss: 0.11350727, train_accuracy: 0.9531, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  376/60000], train_loss: 0.13525629, train_accuracy: 0.9766, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  377/60000], train_loss: 0.13931161, train_accuracy: 0.9531, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  378/60000], train_loss: 0.18749727, train_accuracy: 0.9609, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  379/60000], train_loss: 0.12673971, train_accuracy: 0.9531, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  380/60000], train_loss: 0.09321080, train_accuracy: 0.9844, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  381/60000], train_loss: 0.13721302, train_accuracy: 0.9688, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  382/60000], train_loss: 0.09910198, train_accuracy: 0.9844, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  383/60000], train_loss: 0.08531873, train_accuracy: 0.9844, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  384/60000], train_loss: 0.11282255, train_accuracy: 0.9688, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  385/60000], train_loss: 0.05810302, train_accuracy: 1.0000, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  386/60000], train_loss: 0.08872004, train_accuracy: 0.9766, test_Accuracy: 0.9585\n",
            "Epoch: [ 0] [  387/60000], train_loss: 0.05203456, train_accuracy: 0.9844, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  388/60000], train_loss: 0.10020225, train_accuracy: 0.9766, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  389/60000], train_loss: 0.10532241, train_accuracy: 0.9766, test_Accuracy: 0.9602\n",
            "Epoch: [ 0] [  390/60000], train_loss: 0.10559183, train_accuracy: 0.9688, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  391/60000], train_loss: 0.07600830, train_accuracy: 0.9844, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  392/60000], train_loss: 0.04992573, train_accuracy: 0.9844, test_Accuracy: 0.9619\n",
            "Epoch: [ 0] [  393/60000], train_loss: 0.06627959, train_accuracy: 0.9844, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  394/60000], train_loss: 0.06330667, train_accuracy: 0.9844, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  395/60000], train_loss: 0.08049088, train_accuracy: 0.9766, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  396/60000], train_loss: 0.13219963, train_accuracy: 0.9609, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  397/60000], train_loss: 0.21326903, train_accuracy: 0.9531, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  398/60000], train_loss: 0.13942242, train_accuracy: 0.9531, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  399/60000], train_loss: 0.11797475, train_accuracy: 0.9688, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  400/60000], train_loss: 0.12609026, train_accuracy: 0.9453, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  401/60000], train_loss: 0.18370548, train_accuracy: 0.9453, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  402/60000], train_loss: 0.04581260, train_accuracy: 0.9922, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  403/60000], train_loss: 0.11155425, train_accuracy: 0.9688, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  404/60000], train_loss: 0.15218645, train_accuracy: 0.9375, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  405/60000], train_loss: 0.17454255, train_accuracy: 0.9375, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  406/60000], train_loss: 0.14709529, train_accuracy: 0.9688, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  407/60000], train_loss: 0.10113743, train_accuracy: 0.9766, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  408/60000], train_loss: 0.21271086, train_accuracy: 0.9297, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  409/60000], train_loss: 0.13211933, train_accuracy: 0.9609, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  410/60000], train_loss: 0.06726427, train_accuracy: 0.9844, test_Accuracy: 0.9585\n",
            "Epoch: [ 0] [  411/60000], train_loss: 0.11418085, train_accuracy: 0.9609, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  412/60000], train_loss: 0.19219406, train_accuracy: 0.9297, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  413/60000], train_loss: 0.10014462, train_accuracy: 0.9766, test_Accuracy: 0.9649\n",
            "Epoch: [ 0] [  414/60000], train_loss: 0.17222798, train_accuracy: 0.9688, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  415/60000], train_loss: 0.14376865, train_accuracy: 0.9453, test_Accuracy: 0.9634\n",
            "Epoch: [ 0] [  416/60000], train_loss: 0.13858503, train_accuracy: 0.9453, test_Accuracy: 0.9628\n",
            "Epoch: [ 0] [  417/60000], train_loss: 0.20023850, train_accuracy: 0.9453, test_Accuracy: 0.9629\n",
            "Epoch: [ 0] [  418/60000], train_loss: 0.14347234, train_accuracy: 0.9531, test_Accuracy: 0.9627\n",
            "Epoch: [ 0] [  419/60000], train_loss: 0.15977499, train_accuracy: 0.9531, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  420/60000], train_loss: 0.12236630, train_accuracy: 0.9609, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  421/60000], train_loss: 0.15406416, train_accuracy: 0.9531, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  422/60000], train_loss: 0.06056298, train_accuracy: 0.9766, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  423/60000], train_loss: 0.07062665, train_accuracy: 0.9844, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  424/60000], train_loss: 0.15093517, train_accuracy: 0.9453, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  425/60000], train_loss: 0.09239083, train_accuracy: 0.9688, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  426/60000], train_loss: 0.19799232, train_accuracy: 0.9531, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  427/60000], train_loss: 0.10561946, train_accuracy: 0.9766, test_Accuracy: 0.9632\n",
            "Epoch: [ 0] [  428/60000], train_loss: 0.11213849, train_accuracy: 0.9844, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  429/60000], train_loss: 0.11369295, train_accuracy: 0.9766, test_Accuracy: 0.9653\n",
            "Epoch: [ 0] [  430/60000], train_loss: 0.10185917, train_accuracy: 0.9844, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  431/60000], train_loss: 0.13537998, train_accuracy: 0.9688, test_Accuracy: 0.9629\n",
            "Epoch: [ 0] [  432/60000], train_loss: 0.17674468, train_accuracy: 0.9609, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  433/60000], train_loss: 0.07738638, train_accuracy: 0.9766, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  434/60000], train_loss: 0.16209985, train_accuracy: 0.9531, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  435/60000], train_loss: 0.09094987, train_accuracy: 0.9766, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  436/60000], train_loss: 0.20483552, train_accuracy: 0.9609, test_Accuracy: 0.9559\n",
            "Epoch: [ 0] [  437/60000], train_loss: 0.14151463, train_accuracy: 0.9688, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  438/60000], train_loss: 0.14417468, train_accuracy: 0.9609, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  439/60000], train_loss: 0.07393857, train_accuracy: 0.9844, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  440/60000], train_loss: 0.06911100, train_accuracy: 0.9844, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  441/60000], train_loss: 0.12439628, train_accuracy: 0.9609, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  442/60000], train_loss: 0.14544217, train_accuracy: 0.9609, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  443/60000], train_loss: 0.12130193, train_accuracy: 0.9688, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  444/60000], train_loss: 0.11719123, train_accuracy: 0.9766, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  445/60000], train_loss: 0.12025626, train_accuracy: 0.9766, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  446/60000], train_loss: 0.10257983, train_accuracy: 0.9688, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  447/60000], train_loss: 0.17551430, train_accuracy: 0.9766, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  448/60000], train_loss: 0.06669413, train_accuracy: 0.9766, test_Accuracy: 0.9647\n",
            "Epoch: [ 0] [  449/60000], train_loss: 0.11246601, train_accuracy: 0.9609, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  450/60000], train_loss: 0.07534584, train_accuracy: 0.9688, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  451/60000], train_loss: 0.07395342, train_accuracy: 0.9766, test_Accuracy: 0.9664\n",
            "Epoch: [ 0] [  452/60000], train_loss: 0.09755078, train_accuracy: 0.9766, test_Accuracy: 0.9667\n",
            "Epoch: [ 0] [  453/60000], train_loss: 0.13570783, train_accuracy: 0.9609, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  454/60000], train_loss: 0.17400354, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  455/60000], train_loss: 0.17623283, train_accuracy: 0.9375, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  456/60000], train_loss: 0.16384289, train_accuracy: 0.9688, test_Accuracy: 0.9660\n",
            "Epoch: [ 0] [  457/60000], train_loss: 0.09303072, train_accuracy: 0.9609, test_Accuracy: 0.9652\n",
            "Epoch: [ 0] [  458/60000], train_loss: 0.11854982, train_accuracy: 0.9766, test_Accuracy: 0.9665\n",
            "Epoch: [ 0] [  459/60000], train_loss: 0.05564140, train_accuracy: 0.9844, test_Accuracy: 0.9669\n",
            "Epoch: [ 0] [  460/60000], train_loss: 0.12699246, train_accuracy: 0.9453, test_Accuracy: 0.9663\n",
            "Epoch: [ 0] [  461/60000], train_loss: 0.13592288, train_accuracy: 0.9609, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  462/60000], train_loss: 0.07226320, train_accuracy: 0.9844, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  463/60000], train_loss: 0.09668763, train_accuracy: 0.9766, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  464/60000], train_loss: 0.12099993, train_accuracy: 0.9688, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  465/60000], train_loss: 0.12879542, train_accuracy: 0.9609, test_Accuracy: 0.9667\n",
            "Epoch: [ 0] [  466/60000], train_loss: 0.09729035, train_accuracy: 0.9844, test_Accuracy: 0.9671\n",
            "Epoch: [ 0] [  467/60000], train_loss: 0.14460711, train_accuracy: 0.9688, test_Accuracy: 0.9669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ev1KsMDZ2-7"
      },
      "source": [
        "<h1>Relu Function With He Initialization Test Accuracy : 96.69%</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVNSM6fZXrVL"
      },
      "source": [
        "### Lab 10-3: Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6OV0KCOaipn"
      },
      "source": [
        "Overfitting을 방지하고, 모델을 잘 학습시키기 위한 Regularization 기법.\n",
        "- 모델의 노드 중 일부 노드를 끄고 학습시키는 방법. 이 때 끄는 노드는 Random으로 결정된다. 이후 테스트 때는 껏던 노드를 켜서, 모든 노드를 이용한다.\n",
        "- 랜덤으로 뉴런 일부를 제외함으로써 영향력이 지나치게 강한 뉴런, 즉 학습데이터에 지나치게 의존되어 새로운 데이터에 대한 예측력이 떨어지는 뉴런을 학습에서 랜덤으로 배제할 수 있는 가능성을 얻을 수 있고, 그럴 경우에 과적합을 줄일 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egpdvL_HXb-6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def load_mnist():\n",
        "  (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  train_data = np.expand_dims(train_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "  test_data = np.expand_dims(test_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "\n",
        "  train_data, test_data = normalize(train_data, test_data) # 범위는 0~255 -> 0~1\n",
        "\n",
        "  train_labels = to_categorical(train_labels, 10)\n",
        "  test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "def normalize(train_data, test_data):\n",
        "  train_data = train_data.astype(np.float32) / 255.0\n",
        "  test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "  return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVLmtBjah4IJ"
      },
      "source": [
        "# shape를 펼쳐주는 함수\n",
        "# 다차원 배열을 1차원으로 만드는 레이어를 추가한다고 보면 된다.\n",
        "def flatten():\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "# Dense Layer(Flip Connected Layer) 사용, 케라스 레이어에 Dense 추가\n",
        "def dense(channel, weight_init):\n",
        "  # units = output으로 나가는 채널 갯수, use_bias = bias 사용 여부\n",
        "  return tf.keras.layers.Dense(units=channel, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "# Relu Activation Function\n",
        "def relu():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "# Dropout Function을 추가한다.\n",
        "# rate : 전체 노드 중 끄는 노드의 비율. 0~1 사이의 값.\n",
        "def dropout(rate):\n",
        "  return tf.keras.layers.Dropout(rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyWVJp_TiFJo"
      },
      "source": [
        "# Class type의 모델.\n",
        "class create_model(tf.keras.Model):\n",
        "  def __init__(self, label_dim):\n",
        "    super(create_model, self).__init__()\n",
        "\n",
        "    # he initialization\n",
        "    weight_init = tf.keras.initializers.he_uniform()\n",
        "    self.model = tf.keras.Sequential()\n",
        "\n",
        "    self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "    for i in range(2):\n",
        "      self.model.add(dense(256, weight_init)) # flip-connected function * 2\n",
        "      self.model.add(relu()) # relu function * 2\n",
        "      self.model.add(dropout(rate=0.5)) # dropout 추가(절반 정도 끔)\n",
        "\n",
        "    self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        " \n",
        "  def call(self, x, training=None, mask=None):\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckcONLWIiWUI"
      },
      "source": [
        "# loss 값 구하는 함수.\n",
        "def loss_fn(model, images, labels):\n",
        "  logits = model(images, training=True) # training이 True이면 dropout을 사용한다. (일부 노드로 학습한다.)\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)) # softmax로 loss 구함.\n",
        "  return loss\n",
        "\n",
        "# 정확도 측정 함수.\n",
        "def accuracy_fn(model, images, labels):\n",
        "  logits = model(images, training=False) # training이 False이면 dropout을 사용하지 않는다. (모든 노드를 써서 테스트한다.)\n",
        "  prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32)) # prediction은 Boolean 이기 때문에, 이를 숫자값으로 변경.\n",
        "  return accuracy\n",
        "\n",
        "# Gradient Descent 함수.\n",
        "def grad(model, images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model, images, labels)\n",
        "  return tape.gradient(loss, model.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED0eKNiKiyOH"
      },
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128 # 이미지를 한 번에 학습시킬 갯수.\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x)\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=batch_size).\\\n",
        "  batch(batch_size, drop_remainder=True)\n",
        "  #repeat() #이를 계속 반복.\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=len(test_x)).\\\n",
        "  batch(len(test_x))\n",
        "  #repeat()\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA6j0v7Oi8Ce",
        "outputId": "82c9c8e8-25c7-49aa-d726-b84921282f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "# 여기선 체크포인트 구현은 생략했다. (핵심도 아니고, 귀찮고, 코랩 쓰고 있다보니.......)\n",
        "start_epoch = 0\n",
        "start_iteration = 0\n",
        "\n",
        "for epoch in range(start_epoch, training_epochs):\n",
        "  for idx, (train_input, train_label) in enumerate(train_dataset): #epoch, iteration 2개에 대해 반복 수행.\n",
        "    # gradient 구한 후 적용, 네트워크를 학습시킨다.\n",
        "    grads = grad(network, train_input, train_label)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "    # loss, 정확도를 구한다.\n",
        "    train_loss = loss_fn(network, train_input, train_label)\n",
        "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "    # test dataset을 불러오고, 정확도를 구한다.\n",
        "    for test_input, test_label in test_dataset:\n",
        "      test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    # 그 결과값을 출력한다.\n",
        "    print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" %(epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 0] [    0/60000], train_loss: 2.44036508, train_accuracy: 0.2422, test_Accuracy: 0.1822\n",
            "Epoch: [ 0] [    1/60000], train_loss: 2.22232723, train_accuracy: 0.3594, test_Accuracy: 0.2955\n",
            "Epoch: [ 0] [    2/60000], train_loss: 2.28636074, train_accuracy: 0.3594, test_Accuracy: 0.3273\n",
            "Epoch: [ 0] [    3/60000], train_loss: 2.26121664, train_accuracy: 0.2891, test_Accuracy: 0.3715\n",
            "Epoch: [ 0] [    4/60000], train_loss: 2.06596875, train_accuracy: 0.4453, test_Accuracy: 0.4100\n",
            "Epoch: [ 0] [    5/60000], train_loss: 2.13599539, train_accuracy: 0.4531, test_Accuracy: 0.4787\n",
            "Epoch: [ 0] [    6/60000], train_loss: 2.05927420, train_accuracy: 0.5625, test_Accuracy: 0.5366\n",
            "Epoch: [ 0] [    7/60000], train_loss: 2.06446075, train_accuracy: 0.5000, test_Accuracy: 0.5737\n",
            "Epoch: [ 0] [    8/60000], train_loss: 1.96438074, train_accuracy: 0.5938, test_Accuracy: 0.5976\n",
            "Epoch: [ 0] [    9/60000], train_loss: 1.92078853, train_accuracy: 0.5938, test_Accuracy: 0.6148\n",
            "Epoch: [ 0] [   10/60000], train_loss: 1.69402087, train_accuracy: 0.7266, test_Accuracy: 0.6239\n",
            "Epoch: [ 0] [   11/60000], train_loss: 1.85700703, train_accuracy: 0.6172, test_Accuracy: 0.6389\n",
            "Epoch: [ 0] [   12/60000], train_loss: 1.74449372, train_accuracy: 0.6797, test_Accuracy: 0.6543\n",
            "Epoch: [ 0] [   13/60000], train_loss: 1.71377039, train_accuracy: 0.6406, test_Accuracy: 0.6726\n",
            "Epoch: [ 0] [   14/60000], train_loss: 1.55842352, train_accuracy: 0.6562, test_Accuracy: 0.6885\n",
            "Epoch: [ 0] [   15/60000], train_loss: 1.51427221, train_accuracy: 0.7109, test_Accuracy: 0.7015\n",
            "Epoch: [ 0] [   16/60000], train_loss: 1.53666067, train_accuracy: 0.6953, test_Accuracy: 0.7182\n",
            "Epoch: [ 0] [   17/60000], train_loss: 1.37200487, train_accuracy: 0.7031, test_Accuracy: 0.7299\n",
            "Epoch: [ 0] [   18/60000], train_loss: 1.42015719, train_accuracy: 0.6953, test_Accuracy: 0.7408\n",
            "Epoch: [ 0] [   19/60000], train_loss: 1.41461146, train_accuracy: 0.7734, test_Accuracy: 0.7525\n",
            "Epoch: [ 0] [   20/60000], train_loss: 1.51796103, train_accuracy: 0.7344, test_Accuracy: 0.7608\n",
            "Epoch: [ 0] [   21/60000], train_loss: 1.31361556, train_accuracy: 0.8125, test_Accuracy: 0.7688\n",
            "Epoch: [ 0] [   22/60000], train_loss: 1.24360895, train_accuracy: 0.8281, test_Accuracy: 0.7759\n",
            "Epoch: [ 0] [   23/60000], train_loss: 1.30992007, train_accuracy: 0.7734, test_Accuracy: 0.7837\n",
            "Epoch: [ 0] [   24/60000], train_loss: 1.17291260, train_accuracy: 0.8203, test_Accuracy: 0.7872\n",
            "Epoch: [ 0] [   25/60000], train_loss: 1.15179193, train_accuracy: 0.8125, test_Accuracy: 0.7940\n",
            "Epoch: [ 0] [   26/60000], train_loss: 1.23268771, train_accuracy: 0.7500, test_Accuracy: 0.7984\n",
            "Epoch: [ 0] [   27/60000], train_loss: 1.09982276, train_accuracy: 0.7891, test_Accuracy: 0.8041\n",
            "Epoch: [ 0] [   28/60000], train_loss: 1.13597894, train_accuracy: 0.8672, test_Accuracy: 0.8119\n",
            "Epoch: [ 0] [   29/60000], train_loss: 1.02146840, train_accuracy: 0.8516, test_Accuracy: 0.8172\n",
            "Epoch: [ 0] [   30/60000], train_loss: 1.06373584, train_accuracy: 0.8359, test_Accuracy: 0.8216\n",
            "Epoch: [ 0] [   31/60000], train_loss: 0.96357834, train_accuracy: 0.8203, test_Accuracy: 0.8255\n",
            "Epoch: [ 0] [   32/60000], train_loss: 1.10458255, train_accuracy: 0.8594, test_Accuracy: 0.8293\n",
            "Epoch: [ 0] [   33/60000], train_loss: 0.96879703, train_accuracy: 0.8359, test_Accuracy: 0.8344\n",
            "Epoch: [ 0] [   34/60000], train_loss: 0.96709049, train_accuracy: 0.8516, test_Accuracy: 0.8392\n",
            "Epoch: [ 0] [   35/60000], train_loss: 1.06892943, train_accuracy: 0.7969, test_Accuracy: 0.8427\n",
            "Epoch: [ 0] [   36/60000], train_loss: 0.89597607, train_accuracy: 0.8203, test_Accuracy: 0.8475\n",
            "Epoch: [ 0] [   37/60000], train_loss: 0.73065817, train_accuracy: 0.9062, test_Accuracy: 0.8515\n",
            "Epoch: [ 0] [   38/60000], train_loss: 0.97383797, train_accuracy: 0.8281, test_Accuracy: 0.8517\n",
            "Epoch: [ 0] [   39/60000], train_loss: 1.04382920, train_accuracy: 0.8047, test_Accuracy: 0.8518\n",
            "Epoch: [ 0] [   40/60000], train_loss: 0.88638604, train_accuracy: 0.7656, test_Accuracy: 0.8525\n",
            "Epoch: [ 0] [   41/60000], train_loss: 0.90592998, train_accuracy: 0.8516, test_Accuracy: 0.8524\n",
            "Epoch: [ 0] [   42/60000], train_loss: 0.78243494, train_accuracy: 0.8359, test_Accuracy: 0.8518\n",
            "Epoch: [ 0] [   43/60000], train_loss: 0.95693588, train_accuracy: 0.7969, test_Accuracy: 0.8533\n",
            "Epoch: [ 0] [   44/60000], train_loss: 0.78544259, train_accuracy: 0.8438, test_Accuracy: 0.8539\n",
            "Epoch: [ 0] [   45/60000], train_loss: 0.85679173, train_accuracy: 0.8750, test_Accuracy: 0.8566\n",
            "Epoch: [ 0] [   46/60000], train_loss: 0.89472258, train_accuracy: 0.8438, test_Accuracy: 0.8575\n",
            "Epoch: [ 0] [   47/60000], train_loss: 0.80156678, train_accuracy: 0.8828, test_Accuracy: 0.8581\n",
            "Epoch: [ 0] [   48/60000], train_loss: 0.85596049, train_accuracy: 0.8047, test_Accuracy: 0.8598\n",
            "Epoch: [ 0] [   49/60000], train_loss: 0.71807134, train_accuracy: 0.8750, test_Accuracy: 0.8593\n",
            "Epoch: [ 0] [   50/60000], train_loss: 0.87816262, train_accuracy: 0.8672, test_Accuracy: 0.8603\n",
            "Epoch: [ 0] [   51/60000], train_loss: 0.86057085, train_accuracy: 0.8203, test_Accuracy: 0.8614\n",
            "Epoch: [ 0] [   52/60000], train_loss: 0.63434625, train_accuracy: 0.8594, test_Accuracy: 0.8622\n",
            "Epoch: [ 0] [   53/60000], train_loss: 0.68542075, train_accuracy: 0.8594, test_Accuracy: 0.8630\n",
            "Epoch: [ 0] [   54/60000], train_loss: 0.56988442, train_accuracy: 0.8906, test_Accuracy: 0.8649\n",
            "Epoch: [ 0] [   55/60000], train_loss: 0.73122376, train_accuracy: 0.8203, test_Accuracy: 0.8666\n",
            "Epoch: [ 0] [   56/60000], train_loss: 0.72058177, train_accuracy: 0.8516, test_Accuracy: 0.8673\n",
            "Epoch: [ 0] [   57/60000], train_loss: 0.76761049, train_accuracy: 0.8828, test_Accuracy: 0.8678\n",
            "Epoch: [ 0] [   58/60000], train_loss: 0.66445553, train_accuracy: 0.8672, test_Accuracy: 0.8677\n",
            "Epoch: [ 0] [   59/60000], train_loss: 0.79570794, train_accuracy: 0.8438, test_Accuracy: 0.8700\n",
            "Epoch: [ 0] [   60/60000], train_loss: 0.83274007, train_accuracy: 0.8516, test_Accuracy: 0.8731\n",
            "Epoch: [ 0] [   61/60000], train_loss: 0.69921982, train_accuracy: 0.8203, test_Accuracy: 0.8777\n",
            "Epoch: [ 0] [   62/60000], train_loss: 0.79954386, train_accuracy: 0.8359, test_Accuracy: 0.8799\n",
            "Epoch: [ 0] [   63/60000], train_loss: 0.53788835, train_accuracy: 0.8828, test_Accuracy: 0.8834\n",
            "Epoch: [ 0] [   64/60000], train_loss: 0.69326180, train_accuracy: 0.8828, test_Accuracy: 0.8836\n",
            "Epoch: [ 0] [   65/60000], train_loss: 0.68533695, train_accuracy: 0.8828, test_Accuracy: 0.8846\n",
            "Epoch: [ 0] [   66/60000], train_loss: 0.69508410, train_accuracy: 0.8672, test_Accuracy: 0.8852\n",
            "Epoch: [ 0] [   67/60000], train_loss: 0.65961456, train_accuracy: 0.8516, test_Accuracy: 0.8869\n",
            "Epoch: [ 0] [   68/60000], train_loss: 0.71280813, train_accuracy: 0.8906, test_Accuracy: 0.8865\n",
            "Epoch: [ 0] [   69/60000], train_loss: 0.54890704, train_accuracy: 0.8828, test_Accuracy: 0.8876\n",
            "Epoch: [ 0] [   70/60000], train_loss: 0.53509563, train_accuracy: 0.9141, test_Accuracy: 0.8872\n",
            "Epoch: [ 0] [   71/60000], train_loss: 0.52221859, train_accuracy: 0.9297, test_Accuracy: 0.8871\n",
            "Epoch: [ 0] [   72/60000], train_loss: 0.53940797, train_accuracy: 0.9062, test_Accuracy: 0.8887\n",
            "Epoch: [ 0] [   73/60000], train_loss: 0.74033040, train_accuracy: 0.8750, test_Accuracy: 0.8911\n",
            "Epoch: [ 0] [   74/60000], train_loss: 0.78959453, train_accuracy: 0.8594, test_Accuracy: 0.8935\n",
            "Epoch: [ 0] [   75/60000], train_loss: 0.47039813, train_accuracy: 0.9062, test_Accuracy: 0.8953\n",
            "Epoch: [ 0] [   76/60000], train_loss: 0.69292557, train_accuracy: 0.8281, test_Accuracy: 0.8968\n",
            "Epoch: [ 0] [   77/60000], train_loss: 0.77470899, train_accuracy: 0.8828, test_Accuracy: 0.8967\n",
            "Epoch: [ 0] [   78/60000], train_loss: 0.71472752, train_accuracy: 0.8672, test_Accuracy: 0.8965\n",
            "Epoch: [ 0] [   79/60000], train_loss: 0.53319466, train_accuracy: 0.9297, test_Accuracy: 0.8965\n",
            "Epoch: [ 0] [   80/60000], train_loss: 0.46614766, train_accuracy: 0.8984, test_Accuracy: 0.8979\n",
            "Epoch: [ 0] [   81/60000], train_loss: 0.59325689, train_accuracy: 0.8672, test_Accuracy: 0.8988\n",
            "Epoch: [ 0] [   82/60000], train_loss: 0.50368142, train_accuracy: 0.9062, test_Accuracy: 0.9003\n",
            "Epoch: [ 0] [   83/60000], train_loss: 0.60679352, train_accuracy: 0.8906, test_Accuracy: 0.9004\n",
            "Epoch: [ 0] [   84/60000], train_loss: 0.59634131, train_accuracy: 0.8594, test_Accuracy: 0.9001\n",
            "Epoch: [ 0] [   85/60000], train_loss: 0.58505225, train_accuracy: 0.8750, test_Accuracy: 0.8998\n",
            "Epoch: [ 0] [   86/60000], train_loss: 0.52019429, train_accuracy: 0.9219, test_Accuracy: 0.8989\n",
            "Epoch: [ 0] [   87/60000], train_loss: 0.59818339, train_accuracy: 0.8984, test_Accuracy: 0.8988\n",
            "Epoch: [ 0] [   88/60000], train_loss: 0.49976274, train_accuracy: 0.8984, test_Accuracy: 0.8996\n",
            "Epoch: [ 0] [   89/60000], train_loss: 0.50388777, train_accuracy: 0.9297, test_Accuracy: 0.8966\n",
            "Epoch: [ 0] [   90/60000], train_loss: 0.78231180, train_accuracy: 0.8359, test_Accuracy: 0.8937\n",
            "Epoch: [ 0] [   91/60000], train_loss: 0.62502337, train_accuracy: 0.8828, test_Accuracy: 0.8900\n",
            "Epoch: [ 0] [   92/60000], train_loss: 0.69560105, train_accuracy: 0.8594, test_Accuracy: 0.8874\n",
            "Epoch: [ 0] [   93/60000], train_loss: 0.58650208, train_accuracy: 0.9375, test_Accuracy: 0.8870\n",
            "Epoch: [ 0] [   94/60000], train_loss: 0.48217985, train_accuracy: 0.9141, test_Accuracy: 0.8872\n",
            "Epoch: [ 0] [   95/60000], train_loss: 0.65004098, train_accuracy: 0.8750, test_Accuracy: 0.8898\n",
            "Epoch: [ 0] [   96/60000], train_loss: 0.77612978, train_accuracy: 0.8594, test_Accuracy: 0.8913\n",
            "Epoch: [ 0] [   97/60000], train_loss: 0.43633497, train_accuracy: 0.9609, test_Accuracy: 0.8957\n",
            "Epoch: [ 0] [   98/60000], train_loss: 0.53055197, train_accuracy: 0.9219, test_Accuracy: 0.8977\n",
            "Epoch: [ 0] [   99/60000], train_loss: 0.35436434, train_accuracy: 0.9219, test_Accuracy: 0.9000\n",
            "Epoch: [ 0] [  100/60000], train_loss: 0.53607750, train_accuracy: 0.9141, test_Accuracy: 0.9020\n",
            "Epoch: [ 0] [  101/60000], train_loss: 0.42973363, train_accuracy: 0.9609, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [  102/60000], train_loss: 0.44575262, train_accuracy: 0.8828, test_Accuracy: 0.9034\n",
            "Epoch: [ 0] [  103/60000], train_loss: 0.48806387, train_accuracy: 0.9219, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [  104/60000], train_loss: 0.62039936, train_accuracy: 0.8594, test_Accuracy: 0.9032\n",
            "Epoch: [ 0] [  105/60000], train_loss: 0.45639491, train_accuracy: 0.9141, test_Accuracy: 0.9028\n",
            "Epoch: [ 0] [  106/60000], train_loss: 0.50366819, train_accuracy: 0.8984, test_Accuracy: 0.9020\n",
            "Epoch: [ 0] [  107/60000], train_loss: 0.36757582, train_accuracy: 0.9531, test_Accuracy: 0.9025\n",
            "Epoch: [ 0] [  108/60000], train_loss: 0.48665285, train_accuracy: 0.9219, test_Accuracy: 0.9020\n",
            "Epoch: [ 0] [  109/60000], train_loss: 0.51015091, train_accuracy: 0.8750, test_Accuracy: 0.9024\n",
            "Epoch: [ 0] [  110/60000], train_loss: 0.42242852, train_accuracy: 0.9141, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [  111/60000], train_loss: 0.44472986, train_accuracy: 0.9375, test_Accuracy: 0.9030\n",
            "Epoch: [ 0] [  112/60000], train_loss: 0.34064502, train_accuracy: 0.9453, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [  113/60000], train_loss: 0.59050298, train_accuracy: 0.8203, test_Accuracy: 0.9059\n",
            "Epoch: [ 0] [  114/60000], train_loss: 0.45676488, train_accuracy: 0.9297, test_Accuracy: 0.9067\n",
            "Epoch: [ 0] [  115/60000], train_loss: 0.52868605, train_accuracy: 0.8594, test_Accuracy: 0.9076\n",
            "Epoch: [ 0] [  116/60000], train_loss: 0.38770598, train_accuracy: 0.9297, test_Accuracy: 0.9086\n",
            "Epoch: [ 0] [  117/60000], train_loss: 0.47160599, train_accuracy: 0.9141, test_Accuracy: 0.9097\n",
            "Epoch: [ 0] [  118/60000], train_loss: 0.47921336, train_accuracy: 0.8828, test_Accuracy: 0.9100\n",
            "Epoch: [ 0] [  119/60000], train_loss: 0.50508863, train_accuracy: 0.9141, test_Accuracy: 0.9112\n",
            "Epoch: [ 0] [  120/60000], train_loss: 0.44760191, train_accuracy: 0.8828, test_Accuracy: 0.9115\n",
            "Epoch: [ 0] [  121/60000], train_loss: 0.45746291, train_accuracy: 0.9297, test_Accuracy: 0.9123\n",
            "Epoch: [ 0] [  122/60000], train_loss: 0.51231819, train_accuracy: 0.9297, test_Accuracy: 0.9130\n",
            "Epoch: [ 0] [  123/60000], train_loss: 0.38307431, train_accuracy: 0.9219, test_Accuracy: 0.9133\n",
            "Epoch: [ 0] [  124/60000], train_loss: 0.54073322, train_accuracy: 0.8984, test_Accuracy: 0.9141\n",
            "Epoch: [ 0] [  125/60000], train_loss: 0.39547765, train_accuracy: 0.9297, test_Accuracy: 0.9142\n",
            "Epoch: [ 0] [  126/60000], train_loss: 0.43131799, train_accuracy: 0.9219, test_Accuracy: 0.9146\n",
            "Epoch: [ 0] [  127/60000], train_loss: 0.49832660, train_accuracy: 0.9219, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [  128/60000], train_loss: 0.52652496, train_accuracy: 0.9141, test_Accuracy: 0.9162\n",
            "Epoch: [ 0] [  129/60000], train_loss: 0.51796162, train_accuracy: 0.9141, test_Accuracy: 0.9165\n",
            "Epoch: [ 0] [  130/60000], train_loss: 0.53290844, train_accuracy: 0.9141, test_Accuracy: 0.9170\n",
            "Epoch: [ 0] [  131/60000], train_loss: 0.55303013, train_accuracy: 0.8984, test_Accuracy: 0.9173\n",
            "Epoch: [ 0] [  132/60000], train_loss: 0.41067415, train_accuracy: 0.9453, test_Accuracy: 0.9175\n",
            "Epoch: [ 0] [  133/60000], train_loss: 0.42177707, train_accuracy: 0.8984, test_Accuracy: 0.9182\n",
            "Epoch: [ 0] [  134/60000], train_loss: 0.54607564, train_accuracy: 0.8750, test_Accuracy: 0.9179\n",
            "Epoch: [ 0] [  135/60000], train_loss: 0.45319813, train_accuracy: 0.9141, test_Accuracy: 0.9177\n",
            "Epoch: [ 0] [  136/60000], train_loss: 0.43542013, train_accuracy: 0.9141, test_Accuracy: 0.9181\n",
            "Epoch: [ 0] [  137/60000], train_loss: 0.48449957, train_accuracy: 0.9453, test_Accuracy: 0.9180\n",
            "Epoch: [ 0] [  138/60000], train_loss: 0.45469484, train_accuracy: 0.8984, test_Accuracy: 0.9179\n",
            "Epoch: [ 0] [  139/60000], train_loss: 0.50741428, train_accuracy: 0.9219, test_Accuracy: 0.9190\n",
            "Epoch: [ 0] [  140/60000], train_loss: 0.56797004, train_accuracy: 0.8906, test_Accuracy: 0.9182\n",
            "Epoch: [ 0] [  141/60000], train_loss: 0.56250399, train_accuracy: 0.8828, test_Accuracy: 0.9184\n",
            "Epoch: [ 0] [  142/60000], train_loss: 0.58062553, train_accuracy: 0.8672, test_Accuracy: 0.9186\n",
            "Epoch: [ 0] [  143/60000], train_loss: 0.51735502, train_accuracy: 0.8984, test_Accuracy: 0.9190\n",
            "Epoch: [ 0] [  144/60000], train_loss: 0.48043284, train_accuracy: 0.9141, test_Accuracy: 0.9195\n",
            "Epoch: [ 0] [  145/60000], train_loss: 0.43489102, train_accuracy: 0.9141, test_Accuracy: 0.9201\n",
            "Epoch: [ 0] [  146/60000], train_loss: 0.46771753, train_accuracy: 0.8750, test_Accuracy: 0.9199\n",
            "Epoch: [ 0] [  147/60000], train_loss: 0.47787064, train_accuracy: 0.8828, test_Accuracy: 0.9195\n",
            "Epoch: [ 0] [  148/60000], train_loss: 0.33391732, train_accuracy: 0.9531, test_Accuracy: 0.9182\n",
            "Epoch: [ 0] [  149/60000], train_loss: 0.36873668, train_accuracy: 0.9141, test_Accuracy: 0.9186\n",
            "Epoch: [ 0] [  150/60000], train_loss: 0.36240432, train_accuracy: 0.9531, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  151/60000], train_loss: 0.34531808, train_accuracy: 0.9219, test_Accuracy: 0.9188\n",
            "Epoch: [ 0] [  152/60000], train_loss: 0.40746474, train_accuracy: 0.9297, test_Accuracy: 0.9186\n",
            "Epoch: [ 0] [  153/60000], train_loss: 0.61615175, train_accuracy: 0.8438, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [  154/60000], train_loss: 0.57739925, train_accuracy: 0.8594, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [  155/60000], train_loss: 0.51053536, train_accuracy: 0.9141, test_Accuracy: 0.9221\n",
            "Epoch: [ 0] [  156/60000], train_loss: 0.34793165, train_accuracy: 0.9453, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  157/60000], train_loss: 0.43903068, train_accuracy: 0.9297, test_Accuracy: 0.9215\n",
            "Epoch: [ 0] [  158/60000], train_loss: 0.47361180, train_accuracy: 0.9219, test_Accuracy: 0.9206\n",
            "Epoch: [ 0] [  159/60000], train_loss: 0.52921438, train_accuracy: 0.9219, test_Accuracy: 0.9211\n",
            "Epoch: [ 0] [  160/60000], train_loss: 0.37166077, train_accuracy: 0.9531, test_Accuracy: 0.9224\n",
            "Epoch: [ 0] [  161/60000], train_loss: 0.38702214, train_accuracy: 0.9297, test_Accuracy: 0.9227\n",
            "Epoch: [ 0] [  162/60000], train_loss: 0.39644781, train_accuracy: 0.9375, test_Accuracy: 0.9234\n",
            "Epoch: [ 0] [  163/60000], train_loss: 0.34893358, train_accuracy: 0.9375, test_Accuracy: 0.9232\n",
            "Epoch: [ 0] [  164/60000], train_loss: 0.31111875, train_accuracy: 0.9688, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  165/60000], train_loss: 0.42306322, train_accuracy: 0.9375, test_Accuracy: 0.9241\n",
            "Epoch: [ 0] [  166/60000], train_loss: 0.43248987, train_accuracy: 0.9375, test_Accuracy: 0.9242\n",
            "Epoch: [ 0] [  167/60000], train_loss: 0.53880239, train_accuracy: 0.8984, test_Accuracy: 0.9245\n",
            "Epoch: [ 0] [  168/60000], train_loss: 0.41963202, train_accuracy: 0.9297, test_Accuracy: 0.9243\n",
            "Epoch: [ 0] [  169/60000], train_loss: 0.54926735, train_accuracy: 0.8906, test_Accuracy: 0.9243\n",
            "Epoch: [ 0] [  170/60000], train_loss: 0.32242548, train_accuracy: 0.9453, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  171/60000], train_loss: 0.53685367, train_accuracy: 0.8906, test_Accuracy: 0.9251\n",
            "Epoch: [ 0] [  172/60000], train_loss: 0.31905726, train_accuracy: 0.9531, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  173/60000], train_loss: 0.44311607, train_accuracy: 0.9375, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  174/60000], train_loss: 0.32773897, train_accuracy: 0.9453, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  175/60000], train_loss: 0.39094809, train_accuracy: 0.9375, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  176/60000], train_loss: 0.29584515, train_accuracy: 0.9453, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  177/60000], train_loss: 0.51305449, train_accuracy: 0.8906, test_Accuracy: 0.9272\n",
            "Epoch: [ 0] [  178/60000], train_loss: 0.34737131, train_accuracy: 0.9688, test_Accuracy: 0.9262\n",
            "Epoch: [ 0] [  179/60000], train_loss: 0.61499274, train_accuracy: 0.9141, test_Accuracy: 0.9266\n",
            "Epoch: [ 0] [  180/60000], train_loss: 0.53111887, train_accuracy: 0.9062, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  181/60000], train_loss: 0.43405491, train_accuracy: 0.9062, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  182/60000], train_loss: 0.36718959, train_accuracy: 0.9141, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  183/60000], train_loss: 0.47861367, train_accuracy: 0.8984, test_Accuracy: 0.9262\n",
            "Epoch: [ 0] [  184/60000], train_loss: 0.50698483, train_accuracy: 0.8906, test_Accuracy: 0.9251\n",
            "Epoch: [ 0] [  185/60000], train_loss: 0.43769038, train_accuracy: 0.8906, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  186/60000], train_loss: 0.39031261, train_accuracy: 0.9062, test_Accuracy: 0.9253\n",
            "Epoch: [ 0] [  187/60000], train_loss: 0.50576913, train_accuracy: 0.8906, test_Accuracy: 0.9261\n",
            "Epoch: [ 0] [  188/60000], train_loss: 0.41805387, train_accuracy: 0.9297, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  189/60000], train_loss: 0.48837546, train_accuracy: 0.9141, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  190/60000], train_loss: 0.36172694, train_accuracy: 0.9141, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  191/60000], train_loss: 0.37830198, train_accuracy: 0.9297, test_Accuracy: 0.9277\n",
            "Epoch: [ 0] [  192/60000], train_loss: 0.34644836, train_accuracy: 0.9062, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  193/60000], train_loss: 0.45010838, train_accuracy: 0.9453, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  194/60000], train_loss: 0.41046447, train_accuracy: 0.9219, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  195/60000], train_loss: 0.26003215, train_accuracy: 0.9531, test_Accuracy: 0.9273\n",
            "Epoch: [ 0] [  196/60000], train_loss: 0.44518059, train_accuracy: 0.9141, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  197/60000], train_loss: 0.28139836, train_accuracy: 0.9453, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  198/60000], train_loss: 0.40388727, train_accuracy: 0.9219, test_Accuracy: 0.9269\n",
            "Epoch: [ 0] [  199/60000], train_loss: 0.41760334, train_accuracy: 0.8828, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  200/60000], train_loss: 0.46925160, train_accuracy: 0.9062, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  201/60000], train_loss: 0.24604365, train_accuracy: 0.9453, test_Accuracy: 0.9282\n",
            "Epoch: [ 0] [  202/60000], train_loss: 0.38824573, train_accuracy: 0.9219, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [  203/60000], train_loss: 0.46669322, train_accuracy: 0.9219, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  204/60000], train_loss: 0.38756037, train_accuracy: 0.9062, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [  205/60000], train_loss: 0.38382313, train_accuracy: 0.9375, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  206/60000], train_loss: 0.39009595, train_accuracy: 0.9141, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  207/60000], train_loss: 0.45264861, train_accuracy: 0.9141, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  208/60000], train_loss: 0.43235010, train_accuracy: 0.9141, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  209/60000], train_loss: 0.30116045, train_accuracy: 0.9375, test_Accuracy: 0.9277\n",
            "Epoch: [ 0] [  210/60000], train_loss: 0.36925256, train_accuracy: 0.8984, test_Accuracy: 0.9298\n",
            "Epoch: [ 0] [  211/60000], train_loss: 0.28326213, train_accuracy: 0.9531, test_Accuracy: 0.9309\n",
            "Epoch: [ 0] [  212/60000], train_loss: 0.42047420, train_accuracy: 0.9219, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  213/60000], train_loss: 0.41979209, train_accuracy: 0.9375, test_Accuracy: 0.9317\n",
            "Epoch: [ 0] [  214/60000], train_loss: 0.35139412, train_accuracy: 0.8984, test_Accuracy: 0.9318\n",
            "Epoch: [ 0] [  215/60000], train_loss: 0.36341944, train_accuracy: 0.9375, test_Accuracy: 0.9320\n",
            "Epoch: [ 0] [  216/60000], train_loss: 0.29820910, train_accuracy: 0.9531, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  217/60000], train_loss: 0.49610597, train_accuracy: 0.9297, test_Accuracy: 0.9325\n",
            "Epoch: [ 0] [  218/60000], train_loss: 0.43962306, train_accuracy: 0.9219, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  219/60000], train_loss: 0.25726792, train_accuracy: 0.9531, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  220/60000], train_loss: 0.31190062, train_accuracy: 0.9531, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  221/60000], train_loss: 0.35325962, train_accuracy: 0.9297, test_Accuracy: 0.9319\n",
            "Epoch: [ 0] [  222/60000], train_loss: 0.23402153, train_accuracy: 0.9688, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [  223/60000], train_loss: 0.23226635, train_accuracy: 0.9688, test_Accuracy: 0.9300\n",
            "Epoch: [ 0] [  224/60000], train_loss: 0.34199202, train_accuracy: 0.9297, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  225/60000], train_loss: 0.49962872, train_accuracy: 0.8984, test_Accuracy: 0.9297\n",
            "Epoch: [ 0] [  226/60000], train_loss: 0.61672825, train_accuracy: 0.8984, test_Accuracy: 0.9297\n",
            "Epoch: [ 0] [  227/60000], train_loss: 0.44465241, train_accuracy: 0.8672, test_Accuracy: 0.9307\n",
            "Epoch: [ 0] [  228/60000], train_loss: 0.35892573, train_accuracy: 0.9141, test_Accuracy: 0.9310\n",
            "Epoch: [ 0] [  229/60000], train_loss: 0.27361363, train_accuracy: 0.9531, test_Accuracy: 0.9319\n",
            "Epoch: [ 0] [  230/60000], train_loss: 0.23103611, train_accuracy: 0.9453, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  231/60000], train_loss: 0.27031660, train_accuracy: 0.9375, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  232/60000], train_loss: 0.28854734, train_accuracy: 0.9453, test_Accuracy: 0.9334\n",
            "Epoch: [ 0] [  233/60000], train_loss: 0.45625168, train_accuracy: 0.8984, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  234/60000], train_loss: 0.42420200, train_accuracy: 0.8750, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  235/60000], train_loss: 0.37491906, train_accuracy: 0.9375, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  236/60000], train_loss: 0.38687634, train_accuracy: 0.9375, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  237/60000], train_loss: 0.41688180, train_accuracy: 0.9297, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  238/60000], train_loss: 0.28083336, train_accuracy: 0.9531, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  239/60000], train_loss: 0.34706604, train_accuracy: 0.9375, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [  240/60000], train_loss: 0.31255859, train_accuracy: 0.9297, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  241/60000], train_loss: 0.39904287, train_accuracy: 0.9375, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  242/60000], train_loss: 0.48087811, train_accuracy: 0.8750, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  243/60000], train_loss: 0.36969605, train_accuracy: 0.8984, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  244/60000], train_loss: 0.35603896, train_accuracy: 0.9141, test_Accuracy: 0.9350\n",
            "Epoch: [ 0] [  245/60000], train_loss: 0.43372202, train_accuracy: 0.9062, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  246/60000], train_loss: 0.37341082, train_accuracy: 0.9453, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  247/60000], train_loss: 0.31421119, train_accuracy: 0.9609, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  248/60000], train_loss: 0.36433053, train_accuracy: 0.9297, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  249/60000], train_loss: 0.49046528, train_accuracy: 0.9141, test_Accuracy: 0.9342\n",
            "Epoch: [ 0] [  250/60000], train_loss: 0.33951378, train_accuracy: 0.9297, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  251/60000], train_loss: 0.39065850, train_accuracy: 0.9297, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  252/60000], train_loss: 0.29178274, train_accuracy: 0.9297, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  253/60000], train_loss: 0.40494284, train_accuracy: 0.9375, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  254/60000], train_loss: 0.29048896, train_accuracy: 0.9375, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  255/60000], train_loss: 0.35056797, train_accuracy: 0.9297, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  256/60000], train_loss: 0.31870854, train_accuracy: 0.9219, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  257/60000], train_loss: 0.29317266, train_accuracy: 0.9531, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  258/60000], train_loss: 0.52484423, train_accuracy: 0.8672, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  259/60000], train_loss: 0.23342076, train_accuracy: 0.9609, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  260/60000], train_loss: 0.28800207, train_accuracy: 0.9531, test_Accuracy: 0.9348\n",
            "Epoch: [ 0] [  261/60000], train_loss: 0.39846358, train_accuracy: 0.8984, test_Accuracy: 0.9348\n",
            "Epoch: [ 0] [  262/60000], train_loss: 0.34166235, train_accuracy: 0.9531, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  263/60000], train_loss: 0.24474281, train_accuracy: 0.9844, test_Accuracy: 0.9356\n",
            "Epoch: [ 0] [  264/60000], train_loss: 0.43083221, train_accuracy: 0.9062, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  265/60000], train_loss: 0.28578436, train_accuracy: 0.9375, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  266/60000], train_loss: 0.25688392, train_accuracy: 0.9609, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  267/60000], train_loss: 0.39058226, train_accuracy: 0.9141, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  268/60000], train_loss: 0.31973821, train_accuracy: 0.9453, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  269/60000], train_loss: 0.52196085, train_accuracy: 0.8984, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  270/60000], train_loss: 0.33484539, train_accuracy: 0.9297, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  271/60000], train_loss: 0.38536900, train_accuracy: 0.9297, test_Accuracy: 0.9381\n",
            "Epoch: [ 0] [  272/60000], train_loss: 0.39785159, train_accuracy: 0.9141, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  273/60000], train_loss: 0.29979134, train_accuracy: 0.9375, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  274/60000], train_loss: 0.30465603, train_accuracy: 0.9453, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  275/60000], train_loss: 0.41502911, train_accuracy: 0.9375, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  276/60000], train_loss: 0.48096097, train_accuracy: 0.8984, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  277/60000], train_loss: 0.48235965, train_accuracy: 0.9219, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  278/60000], train_loss: 0.26971686, train_accuracy: 0.9531, test_Accuracy: 0.9389\n",
            "Epoch: [ 0] [  279/60000], train_loss: 0.40431660, train_accuracy: 0.9062, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  280/60000], train_loss: 0.40029120, train_accuracy: 0.9219, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  281/60000], train_loss: 0.30042255, train_accuracy: 0.9609, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  282/60000], train_loss: 0.45616397, train_accuracy: 0.9297, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  283/60000], train_loss: 0.27161980, train_accuracy: 0.9766, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  284/60000], train_loss: 0.33750102, train_accuracy: 0.9141, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  285/60000], train_loss: 0.31179136, train_accuracy: 0.9531, test_Accuracy: 0.9393\n",
            "Epoch: [ 0] [  286/60000], train_loss: 0.34456033, train_accuracy: 0.9609, test_Accuracy: 0.9393\n",
            "Epoch: [ 0] [  287/60000], train_loss: 0.22036389, train_accuracy: 0.9453, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  288/60000], train_loss: 0.35047936, train_accuracy: 0.9219, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  289/60000], train_loss: 0.27457237, train_accuracy: 0.9766, test_Accuracy: 0.9389\n",
            "Epoch: [ 0] [  290/60000], train_loss: 0.30124843, train_accuracy: 0.9453, test_Accuracy: 0.9382\n",
            "Epoch: [ 0] [  291/60000], train_loss: 0.28636286, train_accuracy: 0.9453, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  292/60000], train_loss: 0.36121303, train_accuracy: 0.9531, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  293/60000], train_loss: 0.32873008, train_accuracy: 0.8828, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  294/60000], train_loss: 0.22312108, train_accuracy: 0.9453, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  295/60000], train_loss: 0.37414658, train_accuracy: 0.9375, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  296/60000], train_loss: 0.32751530, train_accuracy: 0.9453, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  297/60000], train_loss: 0.31108975, train_accuracy: 0.9297, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  298/60000], train_loss: 0.23297599, train_accuracy: 0.9453, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  299/60000], train_loss: 0.31029469, train_accuracy: 0.9219, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  300/60000], train_loss: 0.31329083, train_accuracy: 0.9297, test_Accuracy: 0.9392\n",
            "Epoch: [ 0] [  301/60000], train_loss: 0.24853215, train_accuracy: 0.9219, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  302/60000], train_loss: 0.22591032, train_accuracy: 0.9453, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  303/60000], train_loss: 0.25426933, train_accuracy: 0.9453, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  304/60000], train_loss: 0.35637307, train_accuracy: 0.9531, test_Accuracy: 0.9392\n",
            "Epoch: [ 0] [  305/60000], train_loss: 0.25533837, train_accuracy: 0.9688, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  306/60000], train_loss: 0.25926027, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  307/60000], train_loss: 0.37058005, train_accuracy: 0.9375, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  308/60000], train_loss: 0.27567673, train_accuracy: 0.9766, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  309/60000], train_loss: 0.38361865, train_accuracy: 0.9219, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  310/60000], train_loss: 0.29036081, train_accuracy: 0.9141, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  311/60000], train_loss: 0.20982274, train_accuracy: 0.9609, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  312/60000], train_loss: 0.27997756, train_accuracy: 0.9453, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  313/60000], train_loss: 0.41543239, train_accuracy: 0.9062, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  314/60000], train_loss: 0.36942473, train_accuracy: 0.9453, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  315/60000], train_loss: 0.35516363, train_accuracy: 0.9062, test_Accuracy: 0.9409\n",
            "Epoch: [ 0] [  316/60000], train_loss: 0.31920192, train_accuracy: 0.9453, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  317/60000], train_loss: 0.24815133, train_accuracy: 0.9297, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  318/60000], train_loss: 0.33395296, train_accuracy: 0.9297, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  319/60000], train_loss: 0.36906481, train_accuracy: 0.9375, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  320/60000], train_loss: 0.28071332, train_accuracy: 0.9375, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  321/60000], train_loss: 0.23581666, train_accuracy: 0.9453, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  322/60000], train_loss: 0.30580378, train_accuracy: 0.9531, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  323/60000], train_loss: 0.35490143, train_accuracy: 0.9141, test_Accuracy: 0.9425\n",
            "Epoch: [ 0] [  324/60000], train_loss: 0.30645078, train_accuracy: 0.9453, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  325/60000], train_loss: 0.26149708, train_accuracy: 0.9375, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  326/60000], train_loss: 0.28791827, train_accuracy: 0.9531, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  327/60000], train_loss: 0.33254367, train_accuracy: 0.9531, test_Accuracy: 0.9432\n",
            "Epoch: [ 0] [  328/60000], train_loss: 0.38332698, train_accuracy: 0.9219, test_Accuracy: 0.9436\n",
            "Epoch: [ 0] [  329/60000], train_loss: 0.38180166, train_accuracy: 0.9297, test_Accuracy: 0.9431\n",
            "Epoch: [ 0] [  330/60000], train_loss: 0.22439262, train_accuracy: 0.9531, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  331/60000], train_loss: 0.30751032, train_accuracy: 0.9219, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  332/60000], train_loss: 0.30944204, train_accuracy: 0.9531, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  333/60000], train_loss: 0.30959719, train_accuracy: 0.9141, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  334/60000], train_loss: 0.27226767, train_accuracy: 0.9531, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  335/60000], train_loss: 0.34086013, train_accuracy: 0.9219, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  336/60000], train_loss: 0.38175339, train_accuracy: 0.9141, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  337/60000], train_loss: 0.46664128, train_accuracy: 0.9062, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  338/60000], train_loss: 0.22293954, train_accuracy: 0.9531, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  339/60000], train_loss: 0.16386077, train_accuracy: 0.9844, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  340/60000], train_loss: 0.26349360, train_accuracy: 0.9453, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  341/60000], train_loss: 0.23597218, train_accuracy: 0.9609, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  342/60000], train_loss: 0.28541261, train_accuracy: 0.9531, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  343/60000], train_loss: 0.29230338, train_accuracy: 0.9609, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  344/60000], train_loss: 0.22164217, train_accuracy: 0.9609, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  345/60000], train_loss: 0.38480020, train_accuracy: 0.9375, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  346/60000], train_loss: 0.51231974, train_accuracy: 0.8594, test_Accuracy: 0.9443\n",
            "Epoch: [ 0] [  347/60000], train_loss: 0.17407647, train_accuracy: 0.9609, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  348/60000], train_loss: 0.34693962, train_accuracy: 0.9531, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  349/60000], train_loss: 0.36093783, train_accuracy: 0.9297, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  350/60000], train_loss: 0.31568345, train_accuracy: 0.9531, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  351/60000], train_loss: 0.41061401, train_accuracy: 0.9219, test_Accuracy: 0.9430\n",
            "Epoch: [ 0] [  352/60000], train_loss: 0.27719223, train_accuracy: 0.9688, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  353/60000], train_loss: 0.34774280, train_accuracy: 0.9375, test_Accuracy: 0.9423\n",
            "Epoch: [ 0] [  354/60000], train_loss: 0.32278425, train_accuracy: 0.9453, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  355/60000], train_loss: 0.27429658, train_accuracy: 0.9219, test_Accuracy: 0.9425\n",
            "Epoch: [ 0] [  356/60000], train_loss: 0.37861001, train_accuracy: 0.9453, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  357/60000], train_loss: 0.38632110, train_accuracy: 0.8906, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  358/60000], train_loss: 0.28870067, train_accuracy: 0.9297, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  359/60000], train_loss: 0.35810170, train_accuracy: 0.9219, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  360/60000], train_loss: 0.27874678, train_accuracy: 0.9531, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  361/60000], train_loss: 0.38752443, train_accuracy: 0.9453, test_Accuracy: 0.9430\n",
            "Epoch: [ 0] [  362/60000], train_loss: 0.22396812, train_accuracy: 0.9453, test_Accuracy: 0.9443\n",
            "Epoch: [ 0] [  363/60000], train_loss: 0.34037566, train_accuracy: 0.9141, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  364/60000], train_loss: 0.31904328, train_accuracy: 0.9453, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  365/60000], train_loss: 0.25540757, train_accuracy: 0.9609, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  366/60000], train_loss: 0.45949399, train_accuracy: 0.9219, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  367/60000], train_loss: 0.36229765, train_accuracy: 0.9453, test_Accuracy: 0.9453\n",
            "Epoch: [ 0] [  368/60000], train_loss: 0.27541572, train_accuracy: 0.9688, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  369/60000], train_loss: 0.36863244, train_accuracy: 0.9375, test_Accuracy: 0.9449\n",
            "Epoch: [ 0] [  370/60000], train_loss: 0.29841632, train_accuracy: 0.9453, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  371/60000], train_loss: 0.34933078, train_accuracy: 0.9375, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  372/60000], train_loss: 0.29509905, train_accuracy: 0.9609, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  373/60000], train_loss: 0.23730069, train_accuracy: 0.9531, test_Accuracy: 0.9453\n",
            "Epoch: [ 0] [  374/60000], train_loss: 0.41923419, train_accuracy: 0.9297, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  375/60000], train_loss: 0.32645372, train_accuracy: 0.9219, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  376/60000], train_loss: 0.32201901, train_accuracy: 0.9375, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  377/60000], train_loss: 0.34532925, train_accuracy: 0.9062, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  378/60000], train_loss: 0.28266025, train_accuracy: 0.9453, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  379/60000], train_loss: 0.24547888, train_accuracy: 0.9531, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  380/60000], train_loss: 0.28814507, train_accuracy: 0.9375, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  381/60000], train_loss: 0.27466166, train_accuracy: 0.9375, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  382/60000], train_loss: 0.26873937, train_accuracy: 0.9531, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  383/60000], train_loss: 0.41452935, train_accuracy: 0.9219, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  384/60000], train_loss: 0.40376040, train_accuracy: 0.9453, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  385/60000], train_loss: 0.30609843, train_accuracy: 0.9375, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  386/60000], train_loss: 0.26881546, train_accuracy: 0.9453, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  387/60000], train_loss: 0.31994939, train_accuracy: 0.9375, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  388/60000], train_loss: 0.36982185, train_accuracy: 0.9453, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  389/60000], train_loss: 0.38350421, train_accuracy: 0.9531, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  390/60000], train_loss: 0.35675055, train_accuracy: 0.9297, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  391/60000], train_loss: 0.42384994, train_accuracy: 0.9453, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  392/60000], train_loss: 0.27671492, train_accuracy: 0.9453, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  393/60000], train_loss: 0.35592896, train_accuracy: 0.9453, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  394/60000], train_loss: 0.40386045, train_accuracy: 0.9219, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  395/60000], train_loss: 0.41389301, train_accuracy: 0.8906, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  396/60000], train_loss: 0.28406352, train_accuracy: 0.9453, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  397/60000], train_loss: 0.23687389, train_accuracy: 0.9688, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  398/60000], train_loss: 0.19938441, train_accuracy: 0.9609, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  399/60000], train_loss: 0.29991812, train_accuracy: 0.9609, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  400/60000], train_loss: 0.16607127, train_accuracy: 0.9609, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  401/60000], train_loss: 0.20920846, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  402/60000], train_loss: 0.27051675, train_accuracy: 0.9688, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  403/60000], train_loss: 0.32704800, train_accuracy: 0.9297, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  404/60000], train_loss: 0.29756141, train_accuracy: 0.9531, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  405/60000], train_loss: 0.32724053, train_accuracy: 0.9453, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  406/60000], train_loss: 0.21942946, train_accuracy: 0.9766, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  407/60000], train_loss: 0.26365745, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  408/60000], train_loss: 0.28829011, train_accuracy: 0.9297, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  409/60000], train_loss: 0.23686901, train_accuracy: 0.9688, test_Accuracy: 0.9498\n",
            "Epoch: [ 0] [  410/60000], train_loss: 0.30052415, train_accuracy: 0.9688, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  411/60000], train_loss: 0.21667334, train_accuracy: 0.9609, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  412/60000], train_loss: 0.24236490, train_accuracy: 0.9297, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  413/60000], train_loss: 0.28846890, train_accuracy: 0.9219, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  414/60000], train_loss: 0.24234024, train_accuracy: 0.9453, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  415/60000], train_loss: 0.15571317, train_accuracy: 0.9609, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  416/60000], train_loss: 0.10845132, train_accuracy: 0.9766, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  417/60000], train_loss: 0.38253468, train_accuracy: 0.8906, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  418/60000], train_loss: 0.29531714, train_accuracy: 0.9297, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  419/60000], train_loss: 0.23784523, train_accuracy: 0.9688, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  420/60000], train_loss: 0.41253871, train_accuracy: 0.9062, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  421/60000], train_loss: 0.18778723, train_accuracy: 0.9609, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  422/60000], train_loss: 0.28520632, train_accuracy: 0.9375, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  423/60000], train_loss: 0.27164543, train_accuracy: 0.9297, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  424/60000], train_loss: 0.35342231, train_accuracy: 0.9062, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  425/60000], train_loss: 0.39315802, train_accuracy: 0.9219, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  426/60000], train_loss: 0.14712545, train_accuracy: 0.9688, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  427/60000], train_loss: 0.34307268, train_accuracy: 0.9219, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  428/60000], train_loss: 0.20731825, train_accuracy: 0.9844, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  429/60000], train_loss: 0.31154841, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  430/60000], train_loss: 0.24867725, train_accuracy: 0.9609, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  431/60000], train_loss: 0.22243086, train_accuracy: 0.9531, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  432/60000], train_loss: 0.25276047, train_accuracy: 0.9688, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  433/60000], train_loss: 0.18903524, train_accuracy: 0.9688, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  434/60000], train_loss: 0.28767872, train_accuracy: 0.9531, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  435/60000], train_loss: 0.29897404, train_accuracy: 0.9375, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  436/60000], train_loss: 0.23030138, train_accuracy: 0.9609, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  437/60000], train_loss: 0.30832654, train_accuracy: 0.9219, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  438/60000], train_loss: 0.25314587, train_accuracy: 0.9375, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  439/60000], train_loss: 0.28544110, train_accuracy: 0.9453, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  440/60000], train_loss: 0.22967723, train_accuracy: 0.9688, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  441/60000], train_loss: 0.23850268, train_accuracy: 0.9844, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  442/60000], train_loss: 0.20280242, train_accuracy: 0.9766, test_Accuracy: 0.9502\n",
            "Epoch: [ 0] [  443/60000], train_loss: 0.27342659, train_accuracy: 0.9609, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  444/60000], train_loss: 0.19780299, train_accuracy: 0.9609, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  445/60000], train_loss: 0.27442342, train_accuracy: 0.9375, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  446/60000], train_loss: 0.19917375, train_accuracy: 0.9766, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  447/60000], train_loss: 0.21757439, train_accuracy: 0.9844, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  448/60000], train_loss: 0.32426727, train_accuracy: 0.9297, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  449/60000], train_loss: 0.21910605, train_accuracy: 0.9453, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  450/60000], train_loss: 0.29253989, train_accuracy: 0.9297, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  451/60000], train_loss: 0.22173022, train_accuracy: 0.9844, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  452/60000], train_loss: 0.25948587, train_accuracy: 0.9219, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  453/60000], train_loss: 0.25233525, train_accuracy: 0.9531, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  454/60000], train_loss: 0.19772232, train_accuracy: 0.9609, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  455/60000], train_loss: 0.46299696, train_accuracy: 0.8984, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  456/60000], train_loss: 0.13301122, train_accuracy: 0.9688, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  457/60000], train_loss: 0.23188634, train_accuracy: 0.9844, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  458/60000], train_loss: 0.13434353, train_accuracy: 0.9688, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  459/60000], train_loss: 0.27310720, train_accuracy: 0.9531, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  460/60000], train_loss: 0.40462071, train_accuracy: 0.9375, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  461/60000], train_loss: 0.27198100, train_accuracy: 0.9453, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  462/60000], train_loss: 0.28657177, train_accuracy: 0.9375, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  463/60000], train_loss: 0.31851238, train_accuracy: 0.9141, test_Accuracy: 0.9499\n",
            "Epoch: [ 0] [  464/60000], train_loss: 0.19880049, train_accuracy: 0.9844, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  465/60000], train_loss: 0.36815315, train_accuracy: 0.9453, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  466/60000], train_loss: 0.32752997, train_accuracy: 0.9375, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  467/60000], train_loss: 0.30554301, train_accuracy: 0.9453, test_Accuracy: 0.9498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DQidXEdjypV"
      },
      "source": [
        "<h1>Relu Function With He Initialization, Dropout Test Accuracy : 94.98%</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGHvfaUtjsh_"
      },
      "source": [
        "### Lab 10-4: Batch Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv-EwehnlGVP"
      },
      "source": [
        "데이터의 distribution이 네트워크를 지나가면서 변형이 되는데, 이를 internal covariate shift라고 한다. batch normalization은 이를 막기 위한 방법이다.\n",
        "<br><br>\n",
        "레이어의 Input으로 들어오는 distribution을 계속 Normalization함으로써, 이 distribution을 일정하게 유지시킨다. 이후 학습이 되는 파라미터들을 이용해서 새로운 값을 만든 뒤, 이를 레이어의 Input으로 다시 넣어준다.\n",
        "<br><br><br>\n",
        "Batch Normalization을 쓰는 경우, Gradient Descent 함수의 수정이 필요하다. <br>기존의 \n",
        "```python\n",
        "return tape.gradient(loss, model.variables)\n",
        "```\n",
        "를 아래와 같이 바꿔주어야 한다.\n",
        "```python\n",
        "return tape.gradient(loss, model.trainable_variables)\n",
        "```\n",
        "마찬가지로, Eager mode로 실제 학습을 수행하는 main 함수에서도 아래와 같은 코드 변경이 필요하다.\n",
        "<br>기존:\n",
        "```python\n",
        "optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "```\n",
        "신규: \n",
        "```python\n",
        "optimizer.apply_gradients(grads_and_vars=zip(grads, network.trainable_variables))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhyjF81_jB4I"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def load_mnist():\n",
        "  (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  train_data = np.expand_dims(train_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "  test_data = np.expand_dims(test_data, axis=-1) #(N, 28, 28) -> (N, 28, 28, 1)\n",
        "\n",
        "  train_data, test_data = normalize(train_data, test_data) # 범위는 0~255 -> 0~1\n",
        "\n",
        "  train_labels = to_categorical(train_labels, 10)\n",
        "  test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "def normalize(train_data, test_data):\n",
        "  train_data = train_data.astype(np.float32) / 255.0\n",
        "  test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "  return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UQCIFSsmRCP"
      },
      "source": [
        "# shape를 펼쳐주는 함수\n",
        "# 다차원 배열을 1차원으로 만드는 레이어를 추가한다고 보면 된다.\n",
        "def flatten():\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "# Dense Layer(Flip Connected Layer) 사용, 케라스 레이어에 Dense 추가\n",
        "def dense(channel, weight_init):\n",
        "  # units = output으로 나가는 채널 갯수, use_bias = bias 사용 여부\n",
        "  return tf.keras.layers.Dense(units=channel, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "# Relu Activation Function\n",
        "def relu():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "# 이 예제에서는 dropout이 불필요하므로, batch_normalization으로 변경.\n",
        "def batch_norm():\n",
        "  return tf.keras.layers.BatchNormalization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q70rv2SOmhfg"
      },
      "source": [
        "# Class type의 모델.\n",
        "class create_model(tf.keras.Model):\n",
        "  def __init__(self, label_dim):\n",
        "    super(create_model, self).__init__()\n",
        "\n",
        "    # he initialization\n",
        "    weight_init = tf.keras.initializers.he_uniform()\n",
        "    self.model = tf.keras.Sequential()\n",
        "\n",
        "    self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "    for i in range(2):\n",
        "      self.model.add(dense(256, weight_init)) # flip-connected function * 2\n",
        "      self.model.add(batch_norm())\n",
        "      self.model.add(relu())\n",
        "\n",
        "    self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        " \n",
        "  def call(self, x, training=None, mask=None):\n",
        "    x = self.model(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt-RZzszmvLM"
      },
      "source": [
        "# loss 값 구하는 함수.\n",
        "def loss_fn(model, images, labels):\n",
        "  logits = model(images, training=True) # training이 True이면 dropout을 사용한다. (일부 노드로 학습한다.)\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)) # softmax로 loss 구함.\n",
        "  return loss\n",
        "\n",
        "# 정확도 측정 함수.\n",
        "def accuracy_fn(model, images, labels):\n",
        "  logits = model(images, training=False) # training이 False이면 dropout을 사용하지 않는다. (모든 노드를 써서 테스트한다.)\n",
        "  prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32)) # prediction은 Boolean 이기 때문에, 이를 숫자값으로 변경.\n",
        "  return accuracy\n",
        "\n",
        "# Gradient Descent 함수.\n",
        "def grad(model, images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model, images, labels)\n",
        "  #return tape.gradient(loss, model.variables)\n",
        "  return tape.gradient(loss, model.trainable_variables) #Batch Normalization 추가 시 이 부분의 변경이 필요하다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWgT4hyUnrFB"
      },
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128 # 이미지를 한 번에 학습시킬 갯수.\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x)\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=batch_size).\\\n",
        "  batch(batch_size, drop_remainder=True)\n",
        "  #repeat() #이를 계속 반복.\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "  shuffle(buffer_size=100000).\\\n",
        "  prefetch(buffer_size=len(test_x)).\\\n",
        "  batch(len(test_x))\n",
        "  #repeat()\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3us_twCnuLo",
        "outputId": "bf6c08f9-07cc-47bf-82e4-5153c7c2d573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model(label_dim)\n",
        "\n",
        "# 여기선 체크포인트 구현은 생략했다. (핵심도 아니고, 귀찮고, 코랩 쓰고 있다보니.......)\n",
        "start_epoch = 0\n",
        "start_iteration = 0\n",
        "\n",
        "for epoch in range(start_epoch, training_epochs):\n",
        "  for idx, (train_input, train_label) in enumerate(train_dataset): #epoch, iteration 2개에 대해 반복 수행.\n",
        "    # gradient 구한 후 적용, 네트워크를 학습시킨다.\n",
        "    grads = grad(network, train_input, train_label)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, network.trainable_variables))\n",
        "\n",
        "    # loss, 정확도를 구한다.\n",
        "    train_loss = loss_fn(network, train_input, train_label)\n",
        "    train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "    # test dataset을 불러오고, 정확도를 구한다.\n",
        "    for test_input, test_label in test_dataset:\n",
        "      test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    # 그 결과값을 출력한다.\n",
        "    print(\"Epoch: [%2d] [%5d/%5d], train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" %(epoch, idx, training_iterations, train_loss, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 0] [    0/60000], train_loss: 1.63932097, train_accuracy: 0.2031, test_Accuracy: 0.2124\n",
            "Epoch: [ 0] [    1/60000], train_loss: 1.41592872, train_accuracy: 0.3516, test_Accuracy: 0.3225\n",
            "Epoch: [ 0] [    2/60000], train_loss: 1.24864984, train_accuracy: 0.5312, test_Accuracy: 0.4074\n",
            "Epoch: [ 0] [    3/60000], train_loss: 1.14556110, train_accuracy: 0.5156, test_Accuracy: 0.4779\n",
            "Epoch: [ 0] [    4/60000], train_loss: 1.00390577, train_accuracy: 0.5312, test_Accuracy: 0.5273\n",
            "Epoch: [ 0] [    5/60000], train_loss: 0.81152678, train_accuracy: 0.5469, test_Accuracy: 0.5713\n",
            "Epoch: [ 0] [    6/60000], train_loss: 0.72763312, train_accuracy: 0.6875, test_Accuracy: 0.5980\n",
            "Epoch: [ 0] [    7/60000], train_loss: 0.69771606, train_accuracy: 0.6250, test_Accuracy: 0.6238\n",
            "Epoch: [ 0] [    8/60000], train_loss: 0.71162271, train_accuracy: 0.6797, test_Accuracy: 0.6453\n",
            "Epoch: [ 0] [    9/60000], train_loss: 0.62007040, train_accuracy: 0.6250, test_Accuracy: 0.6592\n",
            "Epoch: [ 0] [   10/60000], train_loss: 0.53935635, train_accuracy: 0.6641, test_Accuracy: 0.6760\n",
            "Epoch: [ 0] [   11/60000], train_loss: 0.51322216, train_accuracy: 0.6953, test_Accuracy: 0.6871\n",
            "Epoch: [ 0] [   12/60000], train_loss: 0.43203259, train_accuracy: 0.7031, test_Accuracy: 0.6985\n",
            "Epoch: [ 0] [   13/60000], train_loss: 0.41609675, train_accuracy: 0.7422, test_Accuracy: 0.7044\n",
            "Epoch: [ 0] [   14/60000], train_loss: 0.47541627, train_accuracy: 0.7266, test_Accuracy: 0.7149\n",
            "Epoch: [ 0] [   15/60000], train_loss: 0.51336902, train_accuracy: 0.7344, test_Accuracy: 0.7250\n",
            "Epoch: [ 0] [   16/60000], train_loss: 0.47881725, train_accuracy: 0.7344, test_Accuracy: 0.7363\n",
            "Epoch: [ 0] [   17/60000], train_loss: 0.42398858, train_accuracy: 0.7422, test_Accuracy: 0.7486\n",
            "Epoch: [ 0] [   18/60000], train_loss: 0.39113998, train_accuracy: 0.7812, test_Accuracy: 0.7613\n",
            "Epoch: [ 0] [   19/60000], train_loss: 0.36415356, train_accuracy: 0.7812, test_Accuracy: 0.7724\n",
            "Epoch: [ 0] [   20/60000], train_loss: 0.47075671, train_accuracy: 0.7500, test_Accuracy: 0.7856\n",
            "Epoch: [ 0] [   21/60000], train_loss: 0.37022763, train_accuracy: 0.8047, test_Accuracy: 0.7980\n",
            "Epoch: [ 0] [   22/60000], train_loss: 0.36668947, train_accuracy: 0.7578, test_Accuracy: 0.8121\n",
            "Epoch: [ 0] [   23/60000], train_loss: 0.39013827, train_accuracy: 0.8125, test_Accuracy: 0.8238\n",
            "Epoch: [ 0] [   24/60000], train_loss: 0.35844409, train_accuracy: 0.8828, test_Accuracy: 0.8338\n",
            "Epoch: [ 0] [   25/60000], train_loss: 0.37128484, train_accuracy: 0.8516, test_Accuracy: 0.8435\n",
            "Epoch: [ 0] [   26/60000], train_loss: 0.30406573, train_accuracy: 0.8594, test_Accuracy: 0.8525\n",
            "Epoch: [ 0] [   27/60000], train_loss: 0.40537006, train_accuracy: 0.7969, test_Accuracy: 0.8587\n",
            "Epoch: [ 0] [   28/60000], train_loss: 0.35849309, train_accuracy: 0.8984, test_Accuracy: 0.8662\n",
            "Epoch: [ 0] [   29/60000], train_loss: 0.41781056, train_accuracy: 0.8750, test_Accuracy: 0.8716\n",
            "Epoch: [ 0] [   30/60000], train_loss: 0.27654114, train_accuracy: 0.9062, test_Accuracy: 0.8772\n",
            "Epoch: [ 0] [   31/60000], train_loss: 0.34194487, train_accuracy: 0.8828, test_Accuracy: 0.8818\n",
            "Epoch: [ 0] [   32/60000], train_loss: 0.24007386, train_accuracy: 0.9297, test_Accuracy: 0.8855\n",
            "Epoch: [ 0] [   33/60000], train_loss: 0.18064645, train_accuracy: 0.9297, test_Accuracy: 0.8879\n",
            "Epoch: [ 0] [   34/60000], train_loss: 0.34390795, train_accuracy: 0.8906, test_Accuracy: 0.8924\n",
            "Epoch: [ 0] [   35/60000], train_loss: 0.21803433, train_accuracy: 0.9141, test_Accuracy: 0.8968\n",
            "Epoch: [ 0] [   36/60000], train_loss: 0.30154395, train_accuracy: 0.9062, test_Accuracy: 0.9007\n",
            "Epoch: [ 0] [   37/60000], train_loss: 0.37312490, train_accuracy: 0.8828, test_Accuracy: 0.9038\n",
            "Epoch: [ 0] [   38/60000], train_loss: 0.32616600, train_accuracy: 0.8984, test_Accuracy: 0.9063\n",
            "Epoch: [ 0] [   39/60000], train_loss: 0.27931565, train_accuracy: 0.9062, test_Accuracy: 0.9075\n",
            "Epoch: [ 0] [   40/60000], train_loss: 0.32705909, train_accuracy: 0.9141, test_Accuracy: 0.9081\n",
            "Epoch: [ 0] [   41/60000], train_loss: 0.33367556, train_accuracy: 0.9141, test_Accuracy: 0.9101\n",
            "Epoch: [ 0] [   42/60000], train_loss: 0.36916000, train_accuracy: 0.8906, test_Accuracy: 0.9128\n",
            "Epoch: [ 0] [   43/60000], train_loss: 0.28647211, train_accuracy: 0.9297, test_Accuracy: 0.9151\n",
            "Epoch: [ 0] [   44/60000], train_loss: 0.46277180, train_accuracy: 0.8359, test_Accuracy: 0.9165\n",
            "Epoch: [ 0] [   45/60000], train_loss: 0.29830843, train_accuracy: 0.9062, test_Accuracy: 0.9175\n",
            "Epoch: [ 0] [   46/60000], train_loss: 0.31846243, train_accuracy: 0.9141, test_Accuracy: 0.9189\n",
            "Epoch: [ 0] [   47/60000], train_loss: 0.29940763, train_accuracy: 0.9141, test_Accuracy: 0.9193\n",
            "Epoch: [ 0] [   48/60000], train_loss: 0.17190309, train_accuracy: 0.9375, test_Accuracy: 0.9194\n",
            "Epoch: [ 0] [   49/60000], train_loss: 0.34205478, train_accuracy: 0.8750, test_Accuracy: 0.9198\n",
            "Epoch: [ 0] [   50/60000], train_loss: 0.27666771, train_accuracy: 0.9141, test_Accuracy: 0.9196\n",
            "Epoch: [ 0] [   51/60000], train_loss: 0.32294023, train_accuracy: 0.8828, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [   52/60000], train_loss: 0.26491690, train_accuracy: 0.8906, test_Accuracy: 0.9202\n",
            "Epoch: [ 0] [   53/60000], train_loss: 0.20216899, train_accuracy: 0.9297, test_Accuracy: 0.9208\n",
            "Epoch: [ 0] [   54/60000], train_loss: 0.19326696, train_accuracy: 0.9375, test_Accuracy: 0.9215\n",
            "Epoch: [ 0] [   55/60000], train_loss: 0.38714433, train_accuracy: 0.8672, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [   56/60000], train_loss: 0.25795719, train_accuracy: 0.9297, test_Accuracy: 0.9225\n",
            "Epoch: [ 0] [   57/60000], train_loss: 0.23509382, train_accuracy: 0.9375, test_Accuracy: 0.9241\n",
            "Epoch: [ 0] [   58/60000], train_loss: 0.31156486, train_accuracy: 0.9141, test_Accuracy: 0.9246\n",
            "Epoch: [ 0] [   59/60000], train_loss: 0.35588193, train_accuracy: 0.8828, test_Accuracy: 0.9254\n",
            "Epoch: [ 0] [   60/60000], train_loss: 0.16315424, train_accuracy: 0.9375, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [   61/60000], train_loss: 0.30728975, train_accuracy: 0.9141, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [   62/60000], train_loss: 0.21526577, train_accuracy: 0.9297, test_Accuracy: 0.9300\n",
            "Epoch: [ 0] [   63/60000], train_loss: 0.20793471, train_accuracy: 0.9375, test_Accuracy: 0.9317\n",
            "Epoch: [ 0] [   64/60000], train_loss: 0.31131211, train_accuracy: 0.8984, test_Accuracy: 0.9317\n",
            "Epoch: [ 0] [   65/60000], train_loss: 0.28318280, train_accuracy: 0.9375, test_Accuracy: 0.9326\n",
            "Epoch: [ 0] [   66/60000], train_loss: 0.21291235, train_accuracy: 0.9531, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [   67/60000], train_loss: 0.14758675, train_accuracy: 0.9609, test_Accuracy: 0.9324\n",
            "Epoch: [ 0] [   68/60000], train_loss: 0.22220455, train_accuracy: 0.9297, test_Accuracy: 0.9323\n",
            "Epoch: [ 0] [   69/60000], train_loss: 0.23823273, train_accuracy: 0.9141, test_Accuracy: 0.9314\n",
            "Epoch: [ 0] [   70/60000], train_loss: 0.19724002, train_accuracy: 0.9375, test_Accuracy: 0.9308\n",
            "Epoch: [ 0] [   71/60000], train_loss: 0.19133358, train_accuracy: 0.9297, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [   72/60000], train_loss: 0.12920374, train_accuracy: 0.9688, test_Accuracy: 0.9304\n",
            "Epoch: [ 0] [   73/60000], train_loss: 0.13444202, train_accuracy: 0.9453, test_Accuracy: 0.9297\n",
            "Epoch: [ 0] [   74/60000], train_loss: 0.22263807, train_accuracy: 0.9141, test_Accuracy: 0.9297\n",
            "Epoch: [ 0] [   75/60000], train_loss: 0.18846539, train_accuracy: 0.9453, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [   76/60000], train_loss: 0.18535081, train_accuracy: 0.9297, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [   77/60000], train_loss: 0.19341019, train_accuracy: 0.9297, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [   78/60000], train_loss: 0.21828222, train_accuracy: 0.9375, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [   79/60000], train_loss: 0.19576234, train_accuracy: 0.9531, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [   80/60000], train_loss: 0.19134420, train_accuracy: 0.9297, test_Accuracy: 0.9292\n",
            "Epoch: [ 0] [   81/60000], train_loss: 0.14200628, train_accuracy: 0.9297, test_Accuracy: 0.9303\n",
            "Epoch: [ 0] [   82/60000], train_loss: 0.12961239, train_accuracy: 0.9609, test_Accuracy: 0.9312\n",
            "Epoch: [ 0] [   83/60000], train_loss: 0.11878583, train_accuracy: 0.9609, test_Accuracy: 0.9320\n",
            "Epoch: [ 0] [   84/60000], train_loss: 0.22679555, train_accuracy: 0.9141, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [   85/60000], train_loss: 0.11902091, train_accuracy: 0.9766, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [   86/60000], train_loss: 0.14742105, train_accuracy: 0.9609, test_Accuracy: 0.9342\n",
            "Epoch: [ 0] [   87/60000], train_loss: 0.15301767, train_accuracy: 0.9453, test_Accuracy: 0.9348\n",
            "Epoch: [ 0] [   88/60000], train_loss: 0.21934159, train_accuracy: 0.9453, test_Accuracy: 0.9352\n",
            "Epoch: [ 0] [   89/60000], train_loss: 0.26085714, train_accuracy: 0.9297, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [   90/60000], train_loss: 0.20885459, train_accuracy: 0.9453, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [   91/60000], train_loss: 0.21509036, train_accuracy: 0.9609, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [   92/60000], train_loss: 0.12839855, train_accuracy: 0.9609, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [   93/60000], train_loss: 0.11835876, train_accuracy: 0.9766, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [   94/60000], train_loss: 0.20072363, train_accuracy: 0.9609, test_Accuracy: 0.9406\n",
            "Epoch: [ 0] [   95/60000], train_loss: 0.16239057, train_accuracy: 0.9688, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [   96/60000], train_loss: 0.26818001, train_accuracy: 0.9375, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [   97/60000], train_loss: 0.16333926, train_accuracy: 0.9609, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [   98/60000], train_loss: 0.25911599, train_accuracy: 0.9219, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [   99/60000], train_loss: 0.13261746, train_accuracy: 0.9688, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  100/60000], train_loss: 0.11443458, train_accuracy: 0.9688, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  101/60000], train_loss: 0.12647514, train_accuracy: 0.9844, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  102/60000], train_loss: 0.20203179, train_accuracy: 0.9453, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  103/60000], train_loss: 0.35284787, train_accuracy: 0.8828, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  104/60000], train_loss: 0.23392332, train_accuracy: 0.9297, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  105/60000], train_loss: 0.23624222, train_accuracy: 0.8984, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  106/60000], train_loss: 0.19403432, train_accuracy: 0.9453, test_Accuracy: 0.9418\n",
            "Epoch: [ 0] [  107/60000], train_loss: 0.19830042, train_accuracy: 0.9609, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  108/60000], train_loss: 0.18188407, train_accuracy: 0.9297, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  109/60000], train_loss: 0.29668626, train_accuracy: 0.9141, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  110/60000], train_loss: 0.19219632, train_accuracy: 0.9453, test_Accuracy: 0.9423\n",
            "Epoch: [ 0] [  111/60000], train_loss: 0.22504877, train_accuracy: 0.9062, test_Accuracy: 0.9432\n",
            "Epoch: [ 0] [  112/60000], train_loss: 0.18314424, train_accuracy: 0.9297, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  113/60000], train_loss: 0.14036119, train_accuracy: 0.9766, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  114/60000], train_loss: 0.15667018, train_accuracy: 0.9688, test_Accuracy: 0.9449\n",
            "Epoch: [ 0] [  115/60000], train_loss: 0.13699248, train_accuracy: 0.9609, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  116/60000], train_loss: 0.22287922, train_accuracy: 0.9219, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  117/60000], train_loss: 0.25541154, train_accuracy: 0.9062, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  118/60000], train_loss: 0.15845174, train_accuracy: 0.9688, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  119/60000], train_loss: 0.22754009, train_accuracy: 0.9375, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  120/60000], train_loss: 0.14910111, train_accuracy: 0.9688, test_Accuracy: 0.9431\n",
            "Epoch: [ 0] [  121/60000], train_loss: 0.19082743, train_accuracy: 0.9688, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  122/60000], train_loss: 0.14827831, train_accuracy: 0.9688, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  123/60000], train_loss: 0.24080426, train_accuracy: 0.9219, test_Accuracy: 0.9436\n",
            "Epoch: [ 0] [  124/60000], train_loss: 0.17661533, train_accuracy: 0.9609, test_Accuracy: 0.9443\n",
            "Epoch: [ 0] [  125/60000], train_loss: 0.14202233, train_accuracy: 0.9453, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  126/60000], train_loss: 0.21023352, train_accuracy: 0.9375, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  127/60000], train_loss: 0.13051568, train_accuracy: 0.9609, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  128/60000], train_loss: 0.19357035, train_accuracy: 0.9531, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  129/60000], train_loss: 0.20642088, train_accuracy: 0.9375, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  130/60000], train_loss: 0.22429104, train_accuracy: 0.9531, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  131/60000], train_loss: 0.25215381, train_accuracy: 0.9297, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  132/60000], train_loss: 0.21393704, train_accuracy: 0.9375, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  133/60000], train_loss: 0.18832609, train_accuracy: 0.9375, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  134/60000], train_loss: 0.13449995, train_accuracy: 0.9609, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  135/60000], train_loss: 0.19511876, train_accuracy: 0.9531, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  136/60000], train_loss: 0.16063266, train_accuracy: 0.9531, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  137/60000], train_loss: 0.25419468, train_accuracy: 0.9375, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  138/60000], train_loss: 0.17339022, train_accuracy: 0.9453, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  139/60000], train_loss: 0.14713961, train_accuracy: 0.9609, test_Accuracy: 0.9502\n",
            "Epoch: [ 0] [  140/60000], train_loss: 0.20847140, train_accuracy: 0.9219, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  141/60000], train_loss: 0.17669529, train_accuracy: 0.9453, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  142/60000], train_loss: 0.14827631, train_accuracy: 0.9609, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  143/60000], train_loss: 0.16119859, train_accuracy: 0.9453, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  144/60000], train_loss: 0.07000010, train_accuracy: 0.9844, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  145/60000], train_loss: 0.17393406, train_accuracy: 0.9375, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  146/60000], train_loss: 0.16134578, train_accuracy: 0.9609, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  147/60000], train_loss: 0.13529345, train_accuracy: 0.9453, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  148/60000], train_loss: 0.14779755, train_accuracy: 0.9453, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  149/60000], train_loss: 0.18500051, train_accuracy: 0.9375, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  150/60000], train_loss: 0.17650472, train_accuracy: 0.9297, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  151/60000], train_loss: 0.15246463, train_accuracy: 0.9141, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  152/60000], train_loss: 0.11332656, train_accuracy: 0.9688, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  153/60000], train_loss: 0.19420353, train_accuracy: 0.9375, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  154/60000], train_loss: 0.13438453, train_accuracy: 0.9609, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  155/60000], train_loss: 0.18437082, train_accuracy: 0.9375, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  156/60000], train_loss: 0.22816698, train_accuracy: 0.9062, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  157/60000], train_loss: 0.18340488, train_accuracy: 0.9375, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  158/60000], train_loss: 0.17508823, train_accuracy: 0.9375, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  159/60000], train_loss: 0.24616922, train_accuracy: 0.8906, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  160/60000], train_loss: 0.19614740, train_accuracy: 0.9219, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  161/60000], train_loss: 0.25064394, train_accuracy: 0.9375, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  162/60000], train_loss: 0.13534561, train_accuracy: 0.9688, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  163/60000], train_loss: 0.12409175, train_accuracy: 0.9688, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  164/60000], train_loss: 0.09392604, train_accuracy: 0.9688, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  165/60000], train_loss: 0.16542409, train_accuracy: 0.9531, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  166/60000], train_loss: 0.17165826, train_accuracy: 0.9609, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  167/60000], train_loss: 0.17382440, train_accuracy: 0.9531, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  168/60000], train_loss: 0.22558747, train_accuracy: 0.9297, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  169/60000], train_loss: 0.16512221, train_accuracy: 0.9297, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  170/60000], train_loss: 0.14941466, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  171/60000], train_loss: 0.13536593, train_accuracy: 0.9766, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  172/60000], train_loss: 0.09627477, train_accuracy: 0.9844, test_Accuracy: 0.9526\n",
            "Epoch: [ 0] [  173/60000], train_loss: 0.09928334, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  174/60000], train_loss: 0.18008837, train_accuracy: 0.9766, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  175/60000], train_loss: 0.20328799, train_accuracy: 0.9297, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  176/60000], train_loss: 0.12515599, train_accuracy: 0.9609, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  177/60000], train_loss: 0.22900307, train_accuracy: 0.9297, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  178/60000], train_loss: 0.16430733, train_accuracy: 0.9531, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  179/60000], train_loss: 0.17307779, train_accuracy: 0.9453, test_Accuracy: 0.9556\n",
            "Epoch: [ 0] [  180/60000], train_loss: 0.21964355, train_accuracy: 0.9375, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  181/60000], train_loss: 0.21544175, train_accuracy: 0.9453, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  182/60000], train_loss: 0.09356425, train_accuracy: 0.9766, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  183/60000], train_loss: 0.17757575, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  184/60000], train_loss: 0.10046510, train_accuracy: 0.9844, test_Accuracy: 0.9556\n",
            "Epoch: [ 0] [  185/60000], train_loss: 0.16194025, train_accuracy: 0.9531, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  186/60000], train_loss: 0.19061078, train_accuracy: 0.9453, test_Accuracy: 0.9557\n",
            "Epoch: [ 0] [  187/60000], train_loss: 0.10905914, train_accuracy: 0.9609, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  188/60000], train_loss: 0.14785764, train_accuracy: 0.9375, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  189/60000], train_loss: 0.16985852, train_accuracy: 0.9375, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  190/60000], train_loss: 0.17441401, train_accuracy: 0.9375, test_Accuracy: 0.9570\n",
            "Epoch: [ 0] [  191/60000], train_loss: 0.13173026, train_accuracy: 0.9531, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  192/60000], train_loss: 0.08806099, train_accuracy: 0.9844, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  193/60000], train_loss: 0.18498614, train_accuracy: 0.9219, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  194/60000], train_loss: 0.11515109, train_accuracy: 0.9766, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  195/60000], train_loss: 0.12034235, train_accuracy: 0.9766, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  196/60000], train_loss: 0.07717584, train_accuracy: 0.9844, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  197/60000], train_loss: 0.08867814, train_accuracy: 0.9688, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  198/60000], train_loss: 0.10613112, train_accuracy: 0.9531, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  199/60000], train_loss: 0.13929370, train_accuracy: 0.9531, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  200/60000], train_loss: 0.20599446, train_accuracy: 0.9531, test_Accuracy: 0.9572\n",
            "Epoch: [ 0] [  201/60000], train_loss: 0.14234346, train_accuracy: 0.9766, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  202/60000], train_loss: 0.08245337, train_accuracy: 0.9922, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  203/60000], train_loss: 0.11406103, train_accuracy: 0.9766, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  204/60000], train_loss: 0.17074804, train_accuracy: 0.9453, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  205/60000], train_loss: 0.04328927, train_accuracy: 1.0000, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  206/60000], train_loss: 0.13194217, train_accuracy: 0.9609, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  207/60000], train_loss: 0.10096926, train_accuracy: 0.9844, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  208/60000], train_loss: 0.10365701, train_accuracy: 0.9688, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  209/60000], train_loss: 0.11380221, train_accuracy: 0.9609, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  210/60000], train_loss: 0.13841608, train_accuracy: 0.9453, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  211/60000], train_loss: 0.08550866, train_accuracy: 0.9766, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  212/60000], train_loss: 0.18336882, train_accuracy: 0.9609, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  213/60000], train_loss: 0.13149807, train_accuracy: 0.9609, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  214/60000], train_loss: 0.17680933, train_accuracy: 0.9531, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  215/60000], train_loss: 0.13178521, train_accuracy: 0.9609, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  216/60000], train_loss: 0.11967394, train_accuracy: 0.9531, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  217/60000], train_loss: 0.15575370, train_accuracy: 0.9609, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  218/60000], train_loss: 0.06733280, train_accuracy: 0.9766, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  219/60000], train_loss: 0.06955662, train_accuracy: 0.9844, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  220/60000], train_loss: 0.17241018, train_accuracy: 0.9375, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  221/60000], train_loss: 0.15556470, train_accuracy: 0.9531, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  222/60000], train_loss: 0.12945038, train_accuracy: 0.9688, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  223/60000], train_loss: 0.10141703, train_accuracy: 0.9688, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  224/60000], train_loss: 0.14427379, train_accuracy: 0.9375, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  225/60000], train_loss: 0.13087732, train_accuracy: 0.9609, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  226/60000], train_loss: 0.18685800, train_accuracy: 0.9297, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  227/60000], train_loss: 0.08138502, train_accuracy: 0.9766, test_Accuracy: 0.9579\n",
            "Epoch: [ 0] [  228/60000], train_loss: 0.09705898, train_accuracy: 0.9766, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  229/60000], train_loss: 0.13877711, train_accuracy: 0.9688, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  230/60000], train_loss: 0.09503111, train_accuracy: 0.9766, test_Accuracy: 0.9573\n",
            "Epoch: [ 0] [  231/60000], train_loss: 0.16849594, train_accuracy: 0.9141, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  232/60000], train_loss: 0.12305833, train_accuracy: 0.9453, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  233/60000], train_loss: 0.15623160, train_accuracy: 0.9375, test_Accuracy: 0.9572\n",
            "Epoch: [ 0] [  234/60000], train_loss: 0.14813206, train_accuracy: 0.9531, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  235/60000], train_loss: 0.07400030, train_accuracy: 0.9688, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  236/60000], train_loss: 0.08843228, train_accuracy: 0.9844, test_Accuracy: 0.9567\n",
            "Epoch: [ 0] [  237/60000], train_loss: 0.12889476, train_accuracy: 0.9609, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  238/60000], train_loss: 0.11531073, train_accuracy: 0.9453, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  239/60000], train_loss: 0.17057070, train_accuracy: 0.9531, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  240/60000], train_loss: 0.06850518, train_accuracy: 0.9766, test_Accuracy: 0.9565\n",
            "Epoch: [ 0] [  241/60000], train_loss: 0.12750079, train_accuracy: 0.9688, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  242/60000], train_loss: 0.10558703, train_accuracy: 0.9531, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  243/60000], train_loss: 0.14087111, train_accuracy: 0.9297, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  244/60000], train_loss: 0.12017111, train_accuracy: 0.9844, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  245/60000], train_loss: 0.10508808, train_accuracy: 0.9766, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  246/60000], train_loss: 0.15914923, train_accuracy: 0.9688, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  247/60000], train_loss: 0.17258686, train_accuracy: 0.9688, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  248/60000], train_loss: 0.15183961, train_accuracy: 0.9297, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  249/60000], train_loss: 0.17661664, train_accuracy: 0.9453, test_Accuracy: 0.9594\n",
            "Epoch: [ 0] [  250/60000], train_loss: 0.12422861, train_accuracy: 0.9844, test_Accuracy: 0.9594\n",
            "Epoch: [ 0] [  251/60000], train_loss: 0.11904635, train_accuracy: 0.9688, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  252/60000], train_loss: 0.11498848, train_accuracy: 0.9531, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  253/60000], train_loss: 0.11491954, train_accuracy: 0.9609, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  254/60000], train_loss: 0.17240241, train_accuracy: 0.9688, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  255/60000], train_loss: 0.09324583, train_accuracy: 0.9688, test_Accuracy: 0.9617\n",
            "Epoch: [ 0] [  256/60000], train_loss: 0.15001684, train_accuracy: 0.9375, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  257/60000], train_loss: 0.20848152, train_accuracy: 0.9375, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  258/60000], train_loss: 0.06877096, train_accuracy: 0.9922, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  259/60000], train_loss: 0.14388074, train_accuracy: 0.9375, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  260/60000], train_loss: 0.06826738, train_accuracy: 0.9844, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  261/60000], train_loss: 0.09278367, train_accuracy: 0.9688, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  262/60000], train_loss: 0.10265075, train_accuracy: 0.9766, test_Accuracy: 0.9628\n",
            "Epoch: [ 0] [  263/60000], train_loss: 0.10733594, train_accuracy: 0.9688, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  264/60000], train_loss: 0.08316994, train_accuracy: 0.9688, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  265/60000], train_loss: 0.13372508, train_accuracy: 0.9531, test_Accuracy: 0.9637\n",
            "Epoch: [ 0] [  266/60000], train_loss: 0.13020438, train_accuracy: 0.9531, test_Accuracy: 0.9636\n",
            "Epoch: [ 0] [  267/60000], train_loss: 0.10264143, train_accuracy: 0.9844, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  268/60000], train_loss: 0.14821751, train_accuracy: 0.9688, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  269/60000], train_loss: 0.12283487, train_accuracy: 0.9453, test_Accuracy: 0.9645\n",
            "Epoch: [ 0] [  270/60000], train_loss: 0.10860293, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  271/60000], train_loss: 0.08679004, train_accuracy: 0.9688, test_Accuracy: 0.9653\n",
            "Epoch: [ 0] [  272/60000], train_loss: 0.14480786, train_accuracy: 0.9609, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  273/60000], train_loss: 0.12965398, train_accuracy: 0.9688, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  274/60000], train_loss: 0.09014396, train_accuracy: 0.9922, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  275/60000], train_loss: 0.09263979, train_accuracy: 0.9766, test_Accuracy: 0.9650\n",
            "Epoch: [ 0] [  276/60000], train_loss: 0.07847388, train_accuracy: 0.9688, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  277/60000], train_loss: 0.08540652, train_accuracy: 0.9766, test_Accuracy: 0.9658\n",
            "Epoch: [ 0] [  278/60000], train_loss: 0.12527916, train_accuracy: 0.9609, test_Accuracy: 0.9660\n",
            "Epoch: [ 0] [  279/60000], train_loss: 0.10366927, train_accuracy: 0.9609, test_Accuracy: 0.9663\n",
            "Epoch: [ 0] [  280/60000], train_loss: 0.14977065, train_accuracy: 0.9609, test_Accuracy: 0.9664\n",
            "Epoch: [ 0] [  281/60000], train_loss: 0.19241670, train_accuracy: 0.9375, test_Accuracy: 0.9661\n",
            "Epoch: [ 0] [  282/60000], train_loss: 0.03018820, train_accuracy: 1.0000, test_Accuracy: 0.9663\n",
            "Epoch: [ 0] [  283/60000], train_loss: 0.10344220, train_accuracy: 0.9531, test_Accuracy: 0.9667\n",
            "Epoch: [ 0] [  284/60000], train_loss: 0.15361190, train_accuracy: 0.9688, test_Accuracy: 0.9661\n",
            "Epoch: [ 0] [  285/60000], train_loss: 0.06850706, train_accuracy: 0.9766, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  286/60000], train_loss: 0.04523698, train_accuracy: 0.9922, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  287/60000], train_loss: 0.09481642, train_accuracy: 0.9844, test_Accuracy: 0.9644\n",
            "Epoch: [ 0] [  288/60000], train_loss: 0.13130167, train_accuracy: 0.9688, test_Accuracy: 0.9638\n",
            "Epoch: [ 0] [  289/60000], train_loss: 0.18065882, train_accuracy: 0.9375, test_Accuracy: 0.9638\n",
            "Epoch: [ 0] [  290/60000], train_loss: 0.17373806, train_accuracy: 0.9688, test_Accuracy: 0.9646\n",
            "Epoch: [ 0] [  291/60000], train_loss: 0.16439304, train_accuracy: 0.9297, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  292/60000], train_loss: 0.16157952, train_accuracy: 0.9609, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  293/60000], train_loss: 0.17354973, train_accuracy: 0.9609, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  294/60000], train_loss: 0.09935994, train_accuracy: 0.9688, test_Accuracy: 0.9658\n",
            "Epoch: [ 0] [  295/60000], train_loss: 0.15729980, train_accuracy: 0.9531, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  296/60000], train_loss: 0.11198787, train_accuracy: 0.9531, test_Accuracy: 0.9650\n",
            "Epoch: [ 0] [  297/60000], train_loss: 0.09390454, train_accuracy: 0.9766, test_Accuracy: 0.9652\n",
            "Epoch: [ 0] [  298/60000], train_loss: 0.08285648, train_accuracy: 0.9766, test_Accuracy: 0.9650\n",
            "Epoch: [ 0] [  299/60000], train_loss: 0.11357826, train_accuracy: 0.9531, test_Accuracy: 0.9643\n",
            "Epoch: [ 0] [  300/60000], train_loss: 0.14053124, train_accuracy: 0.9766, test_Accuracy: 0.9643\n",
            "Epoch: [ 0] [  301/60000], train_loss: 0.17899114, train_accuracy: 0.9453, test_Accuracy: 0.9634\n",
            "Epoch: [ 0] [  302/60000], train_loss: 0.09244511, train_accuracy: 0.9844, test_Accuracy: 0.9630\n",
            "Epoch: [ 0] [  303/60000], train_loss: 0.08936379, train_accuracy: 0.9766, test_Accuracy: 0.9627\n",
            "Epoch: [ 0] [  304/60000], train_loss: 0.11060089, train_accuracy: 0.9766, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  305/60000], train_loss: 0.10143976, train_accuracy: 0.9688, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  306/60000], train_loss: 0.11521126, train_accuracy: 0.9609, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  307/60000], train_loss: 0.06479937, train_accuracy: 0.9922, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  308/60000], train_loss: 0.17253193, train_accuracy: 0.9531, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  309/60000], train_loss: 0.05485097, train_accuracy: 0.9922, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  310/60000], train_loss: 0.07134329, train_accuracy: 0.9844, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  311/60000], train_loss: 0.11644474, train_accuracy: 0.9609, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  312/60000], train_loss: 0.12278153, train_accuracy: 0.9609, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  313/60000], train_loss: 0.15800521, train_accuracy: 0.9609, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  314/60000], train_loss: 0.12710151, train_accuracy: 0.9453, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  315/60000], train_loss: 0.09543309, train_accuracy: 0.9766, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  316/60000], train_loss: 0.14926374, train_accuracy: 0.9531, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  317/60000], train_loss: 0.08525202, train_accuracy: 0.9766, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  318/60000], train_loss: 0.07482987, train_accuracy: 0.9922, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  319/60000], train_loss: 0.16029054, train_accuracy: 0.9453, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  320/60000], train_loss: 0.11055381, train_accuracy: 0.9609, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  321/60000], train_loss: 0.12399326, train_accuracy: 0.9531, test_Accuracy: 0.9637\n",
            "Epoch: [ 0] [  322/60000], train_loss: 0.06972803, train_accuracy: 0.9922, test_Accuracy: 0.9641\n",
            "Epoch: [ 0] [  323/60000], train_loss: 0.13026187, train_accuracy: 0.9688, test_Accuracy: 0.9644\n",
            "Epoch: [ 0] [  324/60000], train_loss: 0.09947181, train_accuracy: 0.9766, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  325/60000], train_loss: 0.20139349, train_accuracy: 0.9297, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  326/60000], train_loss: 0.06034043, train_accuracy: 0.9844, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  327/60000], train_loss: 0.07387801, train_accuracy: 0.9766, test_Accuracy: 0.9643\n",
            "Epoch: [ 0] [  328/60000], train_loss: 0.09330475, train_accuracy: 0.9844, test_Accuracy: 0.9643\n",
            "Epoch: [ 0] [  329/60000], train_loss: 0.08878174, train_accuracy: 0.9688, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  330/60000], train_loss: 0.07848606, train_accuracy: 0.9766, test_Accuracy: 0.9650\n",
            "Epoch: [ 0] [  331/60000], train_loss: 0.15066211, train_accuracy: 0.9766, test_Accuracy: 0.9645\n",
            "Epoch: [ 0] [  332/60000], train_loss: 0.07675099, train_accuracy: 0.9688, test_Accuracy: 0.9652\n",
            "Epoch: [ 0] [  333/60000], train_loss: 0.15845250, train_accuracy: 0.9453, test_Accuracy: 0.9646\n",
            "Epoch: [ 0] [  334/60000], train_loss: 0.15089789, train_accuracy: 0.9453, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  335/60000], train_loss: 0.07093938, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  336/60000], train_loss: 0.16243792, train_accuracy: 0.9531, test_Accuracy: 0.9655\n",
            "Epoch: [ 0] [  337/60000], train_loss: 0.05690166, train_accuracy: 0.9844, test_Accuracy: 0.9652\n",
            "Epoch: [ 0] [  338/60000], train_loss: 0.07941265, train_accuracy: 0.9844, test_Accuracy: 0.9648\n",
            "Epoch: [ 0] [  339/60000], train_loss: 0.13598001, train_accuracy: 0.9609, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  340/60000], train_loss: 0.08443231, train_accuracy: 0.9609, test_Accuracy: 0.9647\n",
            "Epoch: [ 0] [  341/60000], train_loss: 0.12743713, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  342/60000], train_loss: 0.19392067, train_accuracy: 0.9453, test_Accuracy: 0.9655\n",
            "Epoch: [ 0] [  343/60000], train_loss: 0.11975149, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  344/60000], train_loss: 0.06007336, train_accuracy: 0.9844, test_Accuracy: 0.9647\n",
            "Epoch: [ 0] [  345/60000], train_loss: 0.14576544, train_accuracy: 0.9609, test_Accuracy: 0.9649\n",
            "Epoch: [ 0] [  346/60000], train_loss: 0.14699049, train_accuracy: 0.9453, test_Accuracy: 0.9655\n",
            "Epoch: [ 0] [  347/60000], train_loss: 0.07239903, train_accuracy: 0.9922, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  348/60000], train_loss: 0.20033577, train_accuracy: 0.9453, test_Accuracy: 0.9661\n",
            "Epoch: [ 0] [  349/60000], train_loss: 0.15425535, train_accuracy: 0.9531, test_Accuracy: 0.9660\n",
            "Epoch: [ 0] [  350/60000], train_loss: 0.08081687, train_accuracy: 0.9766, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  351/60000], train_loss: 0.23297894, train_accuracy: 0.9375, test_Accuracy: 0.9655\n",
            "Epoch: [ 0] [  352/60000], train_loss: 0.09799744, train_accuracy: 0.9688, test_Accuracy: 0.9664\n",
            "Epoch: [ 0] [  353/60000], train_loss: 0.11995979, train_accuracy: 0.9844, test_Accuracy: 0.9664\n",
            "Epoch: [ 0] [  354/60000], train_loss: 0.11051349, train_accuracy: 0.9688, test_Accuracy: 0.9668\n",
            "Epoch: [ 0] [  355/60000], train_loss: 0.10373110, train_accuracy: 0.9531, test_Accuracy: 0.9666\n",
            "Epoch: [ 0] [  356/60000], train_loss: 0.06495805, train_accuracy: 0.9922, test_Accuracy: 0.9669\n",
            "Epoch: [ 0] [  357/60000], train_loss: 0.10015322, train_accuracy: 0.9844, test_Accuracy: 0.9665\n",
            "Epoch: [ 0] [  358/60000], train_loss: 0.11421578, train_accuracy: 0.9766, test_Accuracy: 0.9658\n",
            "Epoch: [ 0] [  359/60000], train_loss: 0.09068158, train_accuracy: 0.9766, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  360/60000], train_loss: 0.12341708, train_accuracy: 0.9531, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  361/60000], train_loss: 0.20036228, train_accuracy: 0.9453, test_Accuracy: 0.9663\n",
            "Epoch: [ 0] [  362/60000], train_loss: 0.13000472, train_accuracy: 0.9531, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  363/60000], train_loss: 0.04947665, train_accuracy: 0.9844, test_Accuracy: 0.9655\n",
            "Epoch: [ 0] [  364/60000], train_loss: 0.07298448, train_accuracy: 0.9766, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  365/60000], train_loss: 0.11466624, train_accuracy: 0.9844, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  366/60000], train_loss: 0.06479125, train_accuracy: 0.9766, test_Accuracy: 0.9657\n",
            "Epoch: [ 0] [  367/60000], train_loss: 0.05887146, train_accuracy: 0.9844, test_Accuracy: 0.9653\n",
            "Epoch: [ 0] [  368/60000], train_loss: 0.15624614, train_accuracy: 0.9453, test_Accuracy: 0.9654\n",
            "Epoch: [ 0] [  369/60000], train_loss: 0.10361303, train_accuracy: 0.9844, test_Accuracy: 0.9660\n",
            "Epoch: [ 0] [  370/60000], train_loss: 0.12308285, train_accuracy: 0.9844, test_Accuracy: 0.9669\n",
            "Epoch: [ 0] [  371/60000], train_loss: 0.04331367, train_accuracy: 1.0000, test_Accuracy: 0.9675\n",
            "Epoch: [ 0] [  372/60000], train_loss: 0.08478200, train_accuracy: 0.9844, test_Accuracy: 0.9669\n",
            "Epoch: [ 0] [  373/60000], train_loss: 0.13333875, train_accuracy: 0.9453, test_Accuracy: 0.9671\n",
            "Epoch: [ 0] [  374/60000], train_loss: 0.07705653, train_accuracy: 0.9766, test_Accuracy: 0.9674\n",
            "Epoch: [ 0] [  375/60000], train_loss: 0.06675893, train_accuracy: 0.9844, test_Accuracy: 0.9681\n",
            "Epoch: [ 0] [  376/60000], train_loss: 0.15309401, train_accuracy: 0.9453, test_Accuracy: 0.9682\n",
            "Epoch: [ 0] [  377/60000], train_loss: 0.10828177, train_accuracy: 0.9609, test_Accuracy: 0.9689\n",
            "Epoch: [ 0] [  378/60000], train_loss: 0.10691044, train_accuracy: 0.9531, test_Accuracy: 0.9691\n",
            "Epoch: [ 0] [  379/60000], train_loss: 0.08680714, train_accuracy: 0.9609, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  380/60000], train_loss: 0.11733555, train_accuracy: 0.9688, test_Accuracy: 0.9711\n",
            "Epoch: [ 0] [  381/60000], train_loss: 0.08880116, train_accuracy: 0.9844, test_Accuracy: 0.9709\n",
            "Epoch: [ 0] [  382/60000], train_loss: 0.07700353, train_accuracy: 0.9766, test_Accuracy: 0.9708\n",
            "Epoch: [ 0] [  383/60000], train_loss: 0.08003537, train_accuracy: 0.9688, test_Accuracy: 0.9701\n",
            "Epoch: [ 0] [  384/60000], train_loss: 0.08739966, train_accuracy: 0.9609, test_Accuracy: 0.9705\n",
            "Epoch: [ 0] [  385/60000], train_loss: 0.09620382, train_accuracy: 0.9766, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  386/60000], train_loss: 0.17637938, train_accuracy: 0.9297, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  387/60000], train_loss: 0.14369206, train_accuracy: 0.9531, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  388/60000], train_loss: 0.06569763, train_accuracy: 0.9844, test_Accuracy: 0.9706\n",
            "Epoch: [ 0] [  389/60000], train_loss: 0.05252642, train_accuracy: 0.9844, test_Accuracy: 0.9703\n",
            "Epoch: [ 0] [  390/60000], train_loss: 0.16467620, train_accuracy: 0.9688, test_Accuracy: 0.9701\n",
            "Epoch: [ 0] [  391/60000], train_loss: 0.12210456, train_accuracy: 0.9609, test_Accuracy: 0.9703\n",
            "Epoch: [ 0] [  392/60000], train_loss: 0.06389686, train_accuracy: 0.9844, test_Accuracy: 0.9702\n",
            "Epoch: [ 0] [  393/60000], train_loss: 0.13547958, train_accuracy: 0.9688, test_Accuracy: 0.9698\n",
            "Epoch: [ 0] [  394/60000], train_loss: 0.05725191, train_accuracy: 0.9922, test_Accuracy: 0.9695\n",
            "Epoch: [ 0] [  395/60000], train_loss: 0.13014160, train_accuracy: 0.9688, test_Accuracy: 0.9689\n",
            "Epoch: [ 0] [  396/60000], train_loss: 0.07352056, train_accuracy: 0.9922, test_Accuracy: 0.9687\n",
            "Epoch: [ 0] [  397/60000], train_loss: 0.09038402, train_accuracy: 0.9688, test_Accuracy: 0.9676\n",
            "Epoch: [ 0] [  398/60000], train_loss: 0.06667603, train_accuracy: 1.0000, test_Accuracy: 0.9673\n",
            "Epoch: [ 0] [  399/60000], train_loss: 0.08456774, train_accuracy: 0.9688, test_Accuracy: 0.9672\n",
            "Epoch: [ 0] [  400/60000], train_loss: 0.10217346, train_accuracy: 0.9766, test_Accuracy: 0.9669\n",
            "Epoch: [ 0] [  401/60000], train_loss: 0.09219181, train_accuracy: 0.9688, test_Accuracy: 0.9659\n",
            "Epoch: [ 0] [  402/60000], train_loss: 0.06745197, train_accuracy: 0.9844, test_Accuracy: 0.9661\n",
            "Epoch: [ 0] [  403/60000], train_loss: 0.06230212, train_accuracy: 0.9844, test_Accuracy: 0.9653\n",
            "Epoch: [ 0] [  404/60000], train_loss: 0.07589297, train_accuracy: 0.9688, test_Accuracy: 0.9656\n",
            "Epoch: [ 0] [  405/60000], train_loss: 0.04031172, train_accuracy: 0.9922, test_Accuracy: 0.9662\n",
            "Epoch: [ 0] [  406/60000], train_loss: 0.17364769, train_accuracy: 0.9375, test_Accuracy: 0.9673\n",
            "Epoch: [ 0] [  407/60000], train_loss: 0.07811368, train_accuracy: 0.9688, test_Accuracy: 0.9681\n",
            "Epoch: [ 0] [  408/60000], train_loss: 0.06212809, train_accuracy: 0.9531, test_Accuracy: 0.9691\n",
            "Epoch: [ 0] [  409/60000], train_loss: 0.15466671, train_accuracy: 0.9688, test_Accuracy: 0.9682\n",
            "Epoch: [ 0] [  410/60000], train_loss: 0.06436057, train_accuracy: 0.9922, test_Accuracy: 0.9685\n",
            "Epoch: [ 0] [  411/60000], train_loss: 0.07959714, train_accuracy: 0.9688, test_Accuracy: 0.9683\n",
            "Epoch: [ 0] [  412/60000], train_loss: 0.11298716, train_accuracy: 0.9766, test_Accuracy: 0.9683\n",
            "Epoch: [ 0] [  413/60000], train_loss: 0.08578739, train_accuracy: 0.9844, test_Accuracy: 0.9683\n",
            "Epoch: [ 0] [  414/60000], train_loss: 0.06104507, train_accuracy: 0.9688, test_Accuracy: 0.9680\n",
            "Epoch: [ 0] [  415/60000], train_loss: 0.12251472, train_accuracy: 0.9609, test_Accuracy: 0.9689\n",
            "Epoch: [ 0] [  416/60000], train_loss: 0.05752059, train_accuracy: 0.9922, test_Accuracy: 0.9692\n",
            "Epoch: [ 0] [  417/60000], train_loss: 0.03701138, train_accuracy: 0.9922, test_Accuracy: 0.9691\n",
            "Epoch: [ 0] [  418/60000], train_loss: 0.07487486, train_accuracy: 0.9766, test_Accuracy: 0.9690\n",
            "Epoch: [ 0] [  419/60000], train_loss: 0.04132441, train_accuracy: 0.9922, test_Accuracy: 0.9693\n",
            "Epoch: [ 0] [  420/60000], train_loss: 0.07947985, train_accuracy: 0.9766, test_Accuracy: 0.9692\n",
            "Epoch: [ 0] [  421/60000], train_loss: 0.12086697, train_accuracy: 0.9766, test_Accuracy: 0.9697\n",
            "Epoch: [ 0] [  422/60000], train_loss: 0.05459402, train_accuracy: 0.9844, test_Accuracy: 0.9696\n",
            "Epoch: [ 0] [  423/60000], train_loss: 0.10233621, train_accuracy: 0.9688, test_Accuracy: 0.9697\n",
            "Epoch: [ 0] [  424/60000], train_loss: 0.05226119, train_accuracy: 0.9922, test_Accuracy: 0.9703\n",
            "Epoch: [ 0] [  425/60000], train_loss: 0.08226326, train_accuracy: 0.9688, test_Accuracy: 0.9708\n",
            "Epoch: [ 0] [  426/60000], train_loss: 0.06654492, train_accuracy: 0.9766, test_Accuracy: 0.9705\n",
            "Epoch: [ 0] [  427/60000], train_loss: 0.09890430, train_accuracy: 0.9766, test_Accuracy: 0.9712\n",
            "Epoch: [ 0] [  428/60000], train_loss: 0.09725434, train_accuracy: 0.9766, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  429/60000], train_loss: 0.10164043, train_accuracy: 0.9688, test_Accuracy: 0.9697\n",
            "Epoch: [ 0] [  430/60000], train_loss: 0.10255047, train_accuracy: 0.9688, test_Accuracy: 0.9700\n",
            "Epoch: [ 0] [  431/60000], train_loss: 0.09261677, train_accuracy: 0.9609, test_Accuracy: 0.9704\n",
            "Epoch: [ 0] [  432/60000], train_loss: 0.05809283, train_accuracy: 0.9844, test_Accuracy: 0.9699\n",
            "Epoch: [ 0] [  433/60000], train_loss: 0.08200396, train_accuracy: 0.9766, test_Accuracy: 0.9700\n",
            "Epoch: [ 0] [  434/60000], train_loss: 0.12884739, train_accuracy: 0.9688, test_Accuracy: 0.9701\n",
            "Epoch: [ 0] [  435/60000], train_loss: 0.04733746, train_accuracy: 0.9844, test_Accuracy: 0.9696\n",
            "Epoch: [ 0] [  436/60000], train_loss: 0.08581720, train_accuracy: 0.9688, test_Accuracy: 0.9711\n",
            "Epoch: [ 0] [  437/60000], train_loss: 0.12991609, train_accuracy: 0.9609, test_Accuracy: 0.9714\n",
            "Epoch: [ 0] [  438/60000], train_loss: 0.07152064, train_accuracy: 0.9688, test_Accuracy: 0.9717\n",
            "Epoch: [ 0] [  439/60000], train_loss: 0.08109754, train_accuracy: 0.9609, test_Accuracy: 0.9713\n",
            "Epoch: [ 0] [  440/60000], train_loss: 0.10640214, train_accuracy: 0.9766, test_Accuracy: 0.9712\n",
            "Epoch: [ 0] [  441/60000], train_loss: 0.08533243, train_accuracy: 0.9844, test_Accuracy: 0.9706\n",
            "Epoch: [ 0] [  442/60000], train_loss: 0.08630227, train_accuracy: 0.9609, test_Accuracy: 0.9712\n",
            "Epoch: [ 0] [  443/60000], train_loss: 0.14294609, train_accuracy: 0.9531, test_Accuracy: 0.9717\n",
            "Epoch: [ 0] [  444/60000], train_loss: 0.06527589, train_accuracy: 0.9844, test_Accuracy: 0.9719\n",
            "Epoch: [ 0] [  445/60000], train_loss: 0.19269179, train_accuracy: 0.9375, test_Accuracy: 0.9717\n",
            "Epoch: [ 0] [  446/60000], train_loss: 0.10238435, train_accuracy: 0.9688, test_Accuracy: 0.9713\n",
            "Epoch: [ 0] [  447/60000], train_loss: 0.06180141, train_accuracy: 0.9766, test_Accuracy: 0.9710\n",
            "Epoch: [ 0] [  448/60000], train_loss: 0.07775564, train_accuracy: 0.9844, test_Accuracy: 0.9708\n",
            "Epoch: [ 0] [  449/60000], train_loss: 0.04565699, train_accuracy: 1.0000, test_Accuracy: 0.9702\n",
            "Epoch: [ 0] [  450/60000], train_loss: 0.09027607, train_accuracy: 0.9844, test_Accuracy: 0.9703\n",
            "Epoch: [ 0] [  451/60000], train_loss: 0.10607378, train_accuracy: 0.9609, test_Accuracy: 0.9704\n",
            "Epoch: [ 0] [  452/60000], train_loss: 0.03365783, train_accuracy: 0.9922, test_Accuracy: 0.9696\n",
            "Epoch: [ 0] [  453/60000], train_loss: 0.07822181, train_accuracy: 0.9609, test_Accuracy: 0.9703\n",
            "Epoch: [ 0] [  454/60000], train_loss: 0.06701562, train_accuracy: 0.9688, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  455/60000], train_loss: 0.06511877, train_accuracy: 0.9766, test_Accuracy: 0.9706\n",
            "Epoch: [ 0] [  456/60000], train_loss: 0.09257136, train_accuracy: 0.9688, test_Accuracy: 0.9705\n",
            "Epoch: [ 0] [  457/60000], train_loss: 0.09541226, train_accuracy: 0.9688, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  458/60000], train_loss: 0.07091561, train_accuracy: 0.9766, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  459/60000], train_loss: 0.05996253, train_accuracy: 0.9766, test_Accuracy: 0.9710\n",
            "Epoch: [ 0] [  460/60000], train_loss: 0.12174451, train_accuracy: 0.9609, test_Accuracy: 0.9710\n",
            "Epoch: [ 0] [  461/60000], train_loss: 0.11857227, train_accuracy: 0.9688, test_Accuracy: 0.9712\n",
            "Epoch: [ 0] [  462/60000], train_loss: 0.11635432, train_accuracy: 0.9609, test_Accuracy: 0.9715\n",
            "Epoch: [ 0] [  463/60000], train_loss: 0.14750096, train_accuracy: 0.9453, test_Accuracy: 0.9716\n",
            "Epoch: [ 0] [  464/60000], train_loss: 0.07294570, train_accuracy: 0.9844, test_Accuracy: 0.9711\n",
            "Epoch: [ 0] [  465/60000], train_loss: 0.06859151, train_accuracy: 0.9844, test_Accuracy: 0.9708\n",
            "Epoch: [ 0] [  466/60000], train_loss: 0.06300050, train_accuracy: 0.9766, test_Accuracy: 0.9707\n",
            "Epoch: [ 0] [  467/60000], train_loss: 0.06382363, train_accuracy: 0.9609, test_Accuracy: 0.9702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNpoGAb8p3Ih"
      },
      "source": [
        "<h1>Relu Function With He Initialization, Batch Normalization Test Accuracy : 97.02%</h1>"
      ]
    }
  ]
}